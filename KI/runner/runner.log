[2025-12-26T20:13:09+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:00<00:02,  1.18it/s]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:02<00:02,  1.44s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:03<00:01,  1.35s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run25
[2025-12-26T20:24:34+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:18,  6.32s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:13<00:13,  6.76s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:18<00:05,  5.97s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  4.85s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.39s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
[2025-12-26T21:26:50+00:00] ERROR rc=143 consec_fails=1
[2025-12-26T21:27:20+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12354
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:03<00:10,  3.61s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:08<00:08,  4.21s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:11<00:03,  3.93s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.67s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.78s/it]
MODE: random
ADAPTER: /workspace/adapters/qlora_run26
[2025-12-26T21:37:39+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
[2025-12-26T21:37:39+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 158, in main
    tok, model = load_model_with_adapter(adapter)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 94, in load_model_with_adapter
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5432, in _load_pretrained_model
    caching_allocator_warmup(model, expanded_device_map, hf_quantizer)
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 6105, in caching_allocator_warmup
    _ = torch.empty(byte_count // factor, dtype=torch.float16, device=device, requires_grad=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.30 GiB. GPU 0 has a total capacity of 15.48 GiB of which 2.91 GiB is free. Including non-PyTorch memory, this process has 128.00 MiB memory in use. Process 23098 has 12.43 GiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T21:37:46+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.70s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:03<00:03,  1.65s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:04<00:01,  1.65s/it]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.81s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.39s/it]
Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:04<00:12,  4.23s/it]Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:04,  2.44s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:01,  1.78s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.48s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.86s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T21:40:21+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py:1566: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.55s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:06<00:06,  3.39s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:10<00:03,  3.81s/it]Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.43s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.06s/it]
[2025-12-26T21:40:46+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:03,  1.25s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:02<00:02,  1.12s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:03<00:01,  1.08s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.07it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.01s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
LOSSES: {'A': 2.3237020559608936, 'B': 2.503185110166669, 'C': 3.085676234215498}
CHOICE: A
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 27 | choice = A | mode = loss
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:06,  2.06s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.29s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.35s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.09s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.16s/it]
Map:   0%|                                                                                                               | 0/27999 [00:00<?, ? examples/s]Map:   2%|██▏                                                                                                | 632/27999 [00:00<00:04, 6290.61 examples/s]Map:   5%|████▉                                                                                             | 1393/27999 [00:00<00:04, 5452.69 examples/s]Map:   7%|███████                                                                                           | 2000/27999 [00:00<00:04, 5663.77 examples/s]Map:  10%|█████████▍                                                                                        | 2699/27999 [00:00<00:04, 6136.35 examples/s]Map:  12%|███████████▋                                                                                      | 3357/27999 [00:00<00:03, 6282.65 examples/s]Map:  14%|█████████████▉                                                                                    | 3996/27999 [00:00<00:03, 6310.44 examples/s]Map:  18%|█████████████████▏                                                                                | 4911/27999 [00:00<00:03, 6221.66 examples/s]Map:  21%|████████████████████▏                                                                             | 5776/27999 [00:00<00:03, 6044.92 examples/s]Map:  24%|███████████████████████▏                                                                          | 6634/27999 [00:01<00:03, 5929.20 examples/s]Map:  27%|██████████████████████████▎                                                                       | 7510/27999 [00:01<00:03, 5896.86 examples/s]Map:  30%|█████████████████████████████▌                                                                    | 8433/27999 [00:01<00:03, 5976.45 examples/s]Map:  33%|████████████████████████████████▌                                                                 | 9300/27999 [00:01<00:03, 5876.19 examples/s]Map:  36%|██████████████████████████████████▊                                                               | 9963/27999 [00:01<00:02, 6046.79 examples/s]Map:  39%|█████████████████████████████████████▋                                                           | 10861/27999 [00:01<00:02, 6023.57 examples/s]Map:  42%|█████████████████████████████████████████                                                        | 11859/27999 [00:01<00:02, 6221.26 examples/s]Map:  45%|████████████████████████████████████████████                                                     | 12734/27999 [00:02<00:02, 6093.42 examples/s]Map:  49%|███████████████████████████████████████████████▌                                                 | 13716/27999 [00:02<00:02, 6097.79 examples/s]Map:  51%|█████████████████████████████████████████████████▊                                               | 14394/27999 [00:02<00:02, 6197.44 examples/s]Map:  54%|████████████████████████████████████████████████████▏                                            | 15068/27999 [00:02<00:02, 6324.79 examples/s]Map:  56%|██████████████████████████████████████████████████████▍                                          | 15717/27999 [00:02<00:01, 6363.49 examples/s]Map:  59%|█████████████████████████████████████████████████████████▌                                       | 16612/27999 [00:02<00:01, 6054.11 examples/s]Map:  62%|███████████████████████████████████████████████████████████▋                                     | 17230/27999 [00:02<00:01, 6080.67 examples/s]Map:  64%|██████████████████████████████████████████████████████████████                                   | 17921/27999 [00:02<00:01, 6295.60 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████                                | 18780/27999 [00:03<00:01, 6085.52 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████                             | 19642/27999 [00:03<00:01, 5969.16 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▎                          | 20284/27999 [00:03<00:01, 5410.16 examples/s]Map:  75%|████████████████████████████████████████████████████████████████████████▋                        | 20972/27999 [00:03<00:01, 5754.38 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▉                      | 21646/27999 [00:03<00:01, 5325.93 examples/s]Map:  79%|█████████████████████████████████████████████████████████████████████████████                    | 22249/27999 [00:03<00:01, 4897.61 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▊                  | 22760/27999 [00:03<00:01, 3994.04 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████▌                | 23247/27999 [00:04<00:01, 3437.39 examples/s]Map:  85%|██████████████████████████████████████████████████████████████████████████████████               | 23672/27999 [00:04<00:01, 3598.84 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▋             | 24166/27999 [00:04<00:01, 3500.31 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▊           | 24759/27999 [00:04<00:00, 4039.61 examples/s]Map:  91%|███████████████████████████████████████████████████████████████████████████████████████▊         | 25361/27999 [00:05<00:01, 2188.89 examples/s]Map:  92%|█████████████████████████████████████████████████████████████████████████████████████████▏       | 25753/27999 [00:05<00:01, 1887.52 examples/s]Map:  93%|██████████████████████████████████████████████████████████████████████████████████████████▏      | 26042/27999 [00:05<00:01, 1591.42 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████▏     | 26332/27999 [00:05<00:01, 1389.90 examples/s]Map:  95%|████████████████████████████████████████████████████████████████████████████████████████████▌    | 26718/27999 [00:06<00:00, 1511.29 examples/s]Map:  97%|█████████████████████████████████████████████████████████████████████████████████████████████▊   | 27080/27999 [00:06<00:00, 1807.29 examples/s]Map:  98%|██████████████████████████████████████████████████████████████████████████████████████████████▋  | 27341/27999 [00:06<00:00, 1297.73 examples/s]Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████▍ | 27537/27999 [00:07<00:00, 1036.05 examples/s]Map:  99%|███████████████████████████████████████████████████████████████████████████████████████████████▉ | 27694/27999 [00:07<00:00, 1036.10 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:07<00:00, 1077.68 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:07<00:00, 3757.10 examples/s]
TRAIN: cycle27  choice=A  data=/workspace/clean_data_norm/latest/A/science.txt  prev=/workspace/adapters/qlora_run26  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:05<16:59,  5.12s/it]  1%|█▏                                                                                                                   | 2/200 [00:09<15:39,  4.75s/it]  2%|█▊                                                                                                                   | 3/200 [00:14<15:04,  4.59s/it]Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 179, in main
    choice, losses = choose_by_loss(tok, model)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 139, in choose_by_loss
    losses[k] = avg_loss_per_token(tok, model, texts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 116, in avg_loss_per_token
    out = model(**enc, labels=enc["input_ids"])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 463, in forward
    logits = self.lm_head(hidden_states[:, slice_indices, :])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 170, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 360, in pre_forward
    set_module_tensor_to_device(
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py", line 343, in set_module_tensor_to_device
    new_value = value.to(device, non_blocking=non_blocking)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 365.75 MiB is free. Including non-PyTorch memory, this process has 1.66 GiB memory in use. Process 23423 has 8.32 GiB memory in use. Process 23454 has 5.12 GiB memory in use. Of the allocated memory 1.49 GiB is allocated by PyTorch, and 15.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T21:42:21+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
  2%|██▎                                                                                                                  | 4/200 [00:17<13:56,  4.27s/it]  2%|██▉                                                                                                                  | 5/200 [00:21<13:34,  4.18s/it]`torch_dtype` is deprecated! Use `dtype` instead!
  3%|███▌                                                                                                                 | 6/200 [00:25<13:14,  4.09s/it]Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:20,  6.98s/it]  4%|████                                                                                                                 | 7/200 [00:37<20:54,  6.50s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:12<00:11,  5.95s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:14<00:04,  4.30s/it]  4%|████▋                                                                                                                | 8/200 [00:43<20:24,  6.38s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.72s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.62s/it]
  4%|█████▎                                                                                                               | 9/200 [00:51<22:09,  6.96s/it]MODE: loss
ADAPTER: /workspace/adapters/qlora_run26
  5%|█████▊                                                                                                              | 10/200 [00:59<23:24,  7.39s/it]  6%|██████▍                                                                                                             | 11/200 [01:06<22:42,  7.21s/it]  6%|██████▉                                                                                                             | 12/200 [01:13<22:11,  7.08s/it]  6%|███████▌                                                                                                            | 13/200 [01:17<19:10,  6.15s/it]  7%|████████                                                                                                            | 14/200 [01:21<17:02,  5.50s/it]  8%|████████▋                                                                                                           | 15/200 [01:25<15:29,  5.03s/it]  8%|█████████▎                                                                                                          | 16/200 [01:29<14:32,  4.74s/it]  8%|█████████▊                                                                                                          | 17/200 [01:33<14:04,  4.62s/it]  9%|██████████▍                                                                                                         | 18/200 [01:38<13:47,  4.55s/it] 10%|███████████                                                                                                         | 19/200 [01:42<13:25,  4.45s/it] 10%|███████████▌                                                                                                        | 20/200 [01:46<12:59,  4.33s/it]                                                                                                                                                          {'loss': 0.1422, 'grad_norm': 2.34959077835083, 'learning_rate': 0.000181, 'epoch': 0.01}
 10%|███████████▌                                                                                                        | 20/200 [01:46<12:59,  4.33s/it] 10%|████████████▏                                                                                                       | 21/200 [01:50<12:27,  4.18s/it] 11%|████████████▊                                                                                                       | 22/200 [01:54<12:44,  4.30s/it] 12%|█████████████▎                                                                                                      | 23/200 [01:58<12:25,  4.21s/it] 12%|█████████████▉                                                                                                      | 24/200 [02:03<12:27,  4.25s/it] 12%|██████████████▌                                                                                                     | 25/200 [02:07<12:20,  4.23s/it] 13%|███████████████                                                                                                     | 26/200 [02:11<11:52,  4.10s/it] 14%|███████████████▋                                                                                                    | 27/200 [02:15<11:38,  4.04s/it] 14%|████████████████▏                                                                                                   | 28/200 [02:19<11:37,  4.05s/it] 14%|████████████████▊                                                                                                   | 29/200 [02:23<11:34,  4.06s/it] 15%|█████████████████▍                                                                                                  | 30/200 [02:27<11:54,  4.20s/it] 16%|█████████████████▉                                                                                                  | 31/200 [02:32<11:51,  4.21s/it] 16%|██████████████████▌                                                                                                 | 32/200 [02:36<11:50,  4.23s/it] 16%|███████████████████▏                                                                                                | 33/200 [02:40<11:39,  4.19s/it] 17%|███████████████████▋                                                                                                | 34/200 [02:44<11:35,  4.19s/it] 18%|████████████████████▎                                                                                               | 35/200 [02:48<11:08,  4.05s/it] 18%|████████████████████▉                                                                                               | 36/200 [02:52<11:15,  4.12s/it] 18%|█████████████████████▍                                                                                              | 37/200 [03:02<15:53,  5.85s/it] 19%|██████████████████████                                                                                              | 38/200 [03:11<18:32,  6.87s/it] 20%|██████████████████████▌                                                                                             | 39/200 [03:25<24:17,  9.05s/it] 20%|███████████████████████▏                                                                                            | 40/200 [03:42<29:52, 11.20s/it]                                                                                                                                                          {'loss': 0.1819, 'grad_norm': 3.0274698734283447, 'learning_rate': 0.000161, 'epoch': 0.01}
 20%|███████████████████████▏                                                                                            | 40/200 [03:42<29:52, 11.20s/it] 20%|███████████████████████▊                                                                                            | 41/200 [03:54<30:19, 11.44s/it] 21%|████████████████████████▎                                                                                           | 42/200 [04:03<28:09, 10.69s/it] 22%|████████████████████████▉                                                                                           | 43/200 [04:11<26:27, 10.11s/it] 22%|█████████████████████████▌                                                                                          | 44/200 [04:27<30:48, 11.85s/it] 22%|██████████████████████████                                                                                          | 45/200 [04:41<32:22, 12.53s/it] 23%|██████████████████████████▋                                                                                         | 46/200 [04:54<32:39, 12.72s/it] 24%|███████████████████████████▎                                                                                        | 47/200 [05:07<32:20, 12.68s/it] 24%|███████████████████████████▊                                                                                        | 48/200 [05:18<30:33, 12.06s/it] 24%|████████████████████████████▍                                                                                       | 49/200 [05:31<31:08, 12.37s/it] 25%|█████████████████████████████                                                                                       | 50/200 [05:39<27:31, 11.01s/it] 26%|█████████████████████████████▌                                                                                      | 51/200 [05:48<26:24, 10.64s/it] 26%|██████████████████████████████▏                                                                                     | 52/200 [05:59<26:14, 10.64s/it] 26%|██████████████████████████████▋                                                                                     | 53/200 [06:11<26:53, 10.98s/it] 27%|███████████████████████████████▎                                                                                    | 54/200 [06:20<25:38, 10.54s/it] 28%|███████████████████████████████▉                                                                                    | 55/200 [06:36<29:25, 12.17s/it] 28%|████████████████████████████████▍                                                                                   | 56/200 [06:43<25:16, 10.53s/it] 28%|█████████████████████████████████                                                                                   | 57/200 [06:47<20:13,  8.49s/it] 29%|█████████████████████████████████▋                                                                                  | 58/200 [06:51<16:56,  7.16s/it] 30%|██████████████████████████████████▏                                                                                 | 59/200 [06:55<14:27,  6.15s/it] 30%|██████████████████████████████████▊                                                                                 | 60/200 [06:59<12:47,  5.49s/it]                                                                                                                                                          {'loss': 0.2062, 'grad_norm': 4.096454620361328, 'learning_rate': 0.000141, 'epoch': 0.02}
 30%|██████████████████████████████████▊                                                                                 | 60/200 [06:59<12:47,  5.49s/it] 30%|███████████████████████████████████▍                                                                                | 61/200 [07:03<12:01,  5.19s/it] 31%|███████████████████████████████████▉                                                                                | 62/200 [07:07<11:15,  4.90s/it] 32%|████████████████████████████████████▌                                                                               | 63/200 [07:11<10:37,  4.65s/it] 32%|█████████████████████████████████████                                                                               | 64/200 [07:15<10:13,  4.51s/it] 32%|█████████████████████████████████████▋                                                                              | 65/200 [07:20<10:01,  4.46s/it] 33%|██████████████████████████████████████▎                                                                             | 66/200 [07:24<09:50,  4.41s/it] 34%|██████████████████████████████████████▊                                                                             | 67/200 [07:29<09:46,  4.41s/it] 34%|███████████████████████████████████████▍                                                                            | 68/200 [07:33<09:33,  4.35s/it] 34%|████████████████████████████████████████                                                                            | 69/200 [07:37<09:34,  4.39s/it] 35%|████████████████████████████████████████▌                                                                           | 70/200 [07:41<09:18,  4.30s/it] 36%|█████████████████████████████████████████▏                                                                          | 71/200 [07:46<09:15,  4.31s/it] 36%|█████████████████████████████████████████▊                                                                          | 72/200 [07:50<09:07,  4.28s/it] 36%|██████████████████████████████████████████▎                                                                         | 73/200 [07:54<09:07,  4.31s/it] 37%|██████████████████████████████████████████▉                                                                         | 74/200 [07:58<08:51,  4.22s/it] 38%|███████████████████████████████████████████▌                                                                        | 75/200 [08:03<08:50,  4.25s/it] 38%|████████████████████████████████████████████                                                                        | 76/200 [08:06<08:29,  4.11s/it] 38%|████████████████████████████████████████████▋                                                                       | 77/200 [08:11<08:39,  4.23s/it] 39%|█████████████████████████████████████████████▏                                                                      | 78/200 [08:15<08:31,  4.19s/it] 40%|█████████████████████████████████████████████▊                                                                      | 79/200 [08:19<08:22,  4.15s/it] 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [08:23<08:06,  4.06s/it]                                                                                                                                                          {'loss': 0.2406, 'grad_norm': 3.954939603805542, 'learning_rate': 0.000121, 'epoch': 0.02}
 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [08:23<08:06,  4.06s/it] 40%|██████████████████████████████████████████████▉                                                                     | 81/200 [08:34<12:00,  6.05s/it] 41%|███████████████████████████████████████████████▌                                                                    | 82/200 [08:46<15:48,  8.04s/it] 42%|████████████████████████████████████████████████▏                                                                   | 83/200 [08:57<17:10,  8.81s/it] 42%|████████████████████████████████████████████████▋                                                                   | 84/200 [09:10<19:30, 10.09s/it] 42%|█████████████████████████████████████████████████▎                                                                  | 85/200 [09:23<20:48, 10.85s/it] 43%|█████████████████████████████████████████████████▉                                                                  | 86/200 [09:35<21:16, 11.20s/it] 44%|██████████████████████████████████████████████████▍                                                                 | 87/200 [09:44<20:21, 10.81s/it] 44%|███████████████████████████████████████████████████                                                                 | 88/200 [09:57<21:11, 11.35s/it] 44%|███████████████████████████████████████████████████▌                                                                | 89/200 [10:06<19:44, 10.67s/it] 45%|████████████████████████████████████████████████████▏                                                               | 90/200 [10:17<19:33, 10.67s/it] 46%|████████████████████████████████████████████████████▊                                                               | 91/200 [10:27<19:23, 10.68s/it] 46%|█████████████████████████████████████████████████████▎                                                              | 92/200 [10:40<20:06, 11.17s/it] 46%|█████████████████████████████████████████████████████▉                                                              | 93/200 [10:49<18:54, 10.60s/it] 47%|██████████████████████████████████████████████████████▌                                                             | 94/200 [10:57<17:19,  9.80s/it] 48%|███████████████████████████████████████████████████████                                                             | 95/200 [11:07<17:00,  9.72s/it] 48%|███████████████████████████████████████████████████████▋                                                            | 96/200 [11:16<16:30,  9.52s/it] 48%|████████████████████████████████████████████████████████▎                                                           | 97/200 [11:22<14:47,  8.62s/it] 49%|████████████████████████████████████████████████████████▊                                                           | 98/200 [11:32<15:30,  9.12s/it] 50%|█████████████████████████████████████████████████████████▍                                                          | 99/200 [11:45<17:12, 10.22s/it] 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [11:53<15:49,  9.49s/it]                                                                                                                                                          {'loss': 0.3093, 'grad_norm': 6.546380043029785, 'learning_rate': 0.000101, 'epoch': 0.03}
 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [11:53<15:49,  9.49s/it] 50%|██████████████████████████████████████████████████████████                                                         | 101/200 [12:02<15:12,  9.22s/it] 51%|██████████████████████████████████████████████████████████▋                                                        | 102/200 [12:12<15:33,  9.52s/it] 52%|███████████████████████████████████████████████████████████▏                                                       | 103/200 [12:25<17:16, 10.68s/it] 52%|███████████████████████████████████████████████████████████▊                                                       | 104/200 [12:30<14:28,  9.04s/it] 52%|████████████████████████████████████████████████████████████▍                                                      | 105/200 [12:34<11:54,  7.52s/it] 53%|████████████████████████████████████████████████████████████▉                                                      | 106/200 [12:39<10:22,  6.63s/it] 54%|█████████████████████████████████████████████████████████████▌                                                     | 107/200 [12:43<09:02,  5.84s/it] 54%|██████████████████████████████████████████████████████████████                                                     | 108/200 [12:47<08:08,  5.31s/it] 55%|██████████████████████████████████████████████████████████████▋                                                    | 109/200 [12:51<07:35,  5.00s/it] 55%|███████████████████████████████████████████████████████████████▎                                                   | 110/200 [12:55<07:04,  4.72s/it] 56%|███████████████████████████████████████████████████████████████▊                                                   | 111/200 [13:00<06:53,  4.65s/it] 56%|████████████████████████████████████████████████████████████████▍                                                  | 112/200 [13:04<06:45,  4.61s/it] 56%|████████████████████████████████████████████████████████████████▉                                                  | 113/200 [13:09<06:29,  4.48s/it] 57%|█████████████████████████████████████████████████████████████████▌                                                 | 114/200 [13:13<06:22,  4.45s/it] 57%|██████████████████████████████████████████████████████████████████▏                                                | 115/200 [13:17<06:13,  4.40s/it] 58%|██████████████████████████████████████████████████████████████████▋                                                | 116/200 [13:22<06:09,  4.40s/it] 58%|███████████████████████████████████████████████████████████████████▎                                               | 117/200 [13:26<06:01,  4.35s/it] 59%|███████████████████████████████████████████████████████████████████▊                                               | 118/200 [13:30<05:40,  4.15s/it] 60%|████████████████████████████████████████████████████████████████████▍                                              | 119/200 [13:33<05:32,  4.10s/it] 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [13:38<05:30,  4.13s/it]                                                                                                                                                          {'loss': 0.4051, 'grad_norm': 6.355848789215088, 'learning_rate': 8.1e-05, 'epoch': 0.03}
 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [13:38<05:30,  4.13s/it] 60%|█████████████████████████████████████████████████████████████████████▌                                             | 121/200 [13:42<05:28,  4.16s/it] 61%|██████████████████████████████████████████████████████████████████████▏                                            | 122/200 [13:46<05:22,  4.13s/it] 62%|██████████████████████████████████████████████████████████████████████▋                                            | 123/200 [13:50<05:17,  4.12s/it] 62%|███████████████████████████████████████████████████████████████████████▎                                           | 124/200 [13:54<05:17,  4.17s/it] 62%|███████████████████████████████████████████████████████████████████████▉                                           | 125/200 [13:59<05:20,  4.28s/it] 63%|████████████████████████████████████████████████████████████████████████▍                                          | 126/200 [14:03<05:12,  4.22s/it] 64%|█████████████████████████████████████████████████████████████████████████                                          | 127/200 [14:07<05:01,  4.13s/it] 64%|█████████████████████████████████████████████████████████████████████████▌                                         | 128/200 [14:11<05:01,  4.18s/it] 64%|██████████████████████████████████████████████████████████████████████████▏                                        | 129/200 [14:20<06:39,  5.63s/it] 65%|██████████████████████████████████████████████████████████████████████████▊                                        | 130/200 [14:33<08:59,  7.71s/it] 66%|███████████████████████████████████████████████████████████████████████████▎                                       | 131/200 [14:43<09:44,  8.46s/it] 66%|███████████████████████████████████████████████████████████████████████████▉                                       | 132/200 [14:52<09:48,  8.66s/it] 66%|████████████████████████████████████████████████████████████████████████████▍                                      | 133/200 [15:03<10:18,  9.23s/it] 67%|█████████████████████████████████████████████████████████████████████████████                                      | 134/200 [15:14<10:46,  9.80s/it] 68%|█████████████████████████████████████████████████████████████████████████████▋                                     | 135/200 [15:25<11:04, 10.22s/it] 68%|██████████████████████████████████████████████████████████████████████████████▏                                    | 136/200 [15:36<11:08, 10.45s/it] 68%|██████████████████████████████████████████████████████████████████████████████▊                                    | 137/200 [15:49<11:51, 11.30s/it] 69%|███████████████████████████████████████████████████████████████████████████████▎                                   | 138/200 [15:58<10:56, 10.59s/it] 70%|███████████████████████████████████████████████████████████████████████████████▉                                   | 139/200 [16:12<11:42, 11.52s/it] 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [16:22<11:14, 11.24s/it]                                                                                                                                                          {'loss': 0.6036, 'grad_norm': 5.513219833374023, 'learning_rate': 6.1e-05, 'epoch': 0.04}
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [16:22<11:14, 11.24s/it] 70%|█████████████████████████████████████████████████████████████████████████████████                                  | 141/200 [16:37<11:59, 12.19s/it] 71%|█████████████████████████████████████████████████████████████████████████████████▋                                 | 142/200 [16:48<11:22, 11.77s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▏                                | 143/200 [16:58<10:42, 11.27s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▊                                | 144/200 [17:05<09:16,  9.94s/it] 72%|███████████████████████████████████████████████████████████████████████████████████▍                               | 145/200 [17:19<10:19, 11.27s/it] 73%|███████████████████████████████████████████████████████████████████████████████████▉                               | 146/200 [17:30<09:59, 11.10s/it] 74%|████████████████████████████████████████████████████████████████████████████████████▌                              | 147/200 [17:43<10:28, 11.85s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████                              | 148/200 [17:54<10:04, 11.63s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████▋                             | 149/200 [18:07<10:06, 11.88s/it] 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 150/200 [18:21<10:20, 12.41s/it] 76%|██████████████████████████████████████████████████████████████████████████████████████▊                            | 151/200 [18:28<09:02, 11.08s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▍                           | 152/200 [18:38<08:34, 10.73s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▉                           | 153/200 [18:42<06:50,  8.73s/it] 77%|████████████████████████████████████████████████████████████████████████████████████████▌                          | 154/200 [18:46<05:35,  7.28s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▏                         | 155/200 [18:50<04:40,  6.24s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▋                         | 156/200 [18:54<04:08,  5.66s/it] 78%|██████████████████████████████████████████████████████████████████████████████████████████▎                        | 157/200 [18:59<03:45,  5.25s/it] 79%|██████████████████████████████████████████████████████████████████████████████████████████▊                        | 158/200 [19:03<03:28,  4.97s/it] 80%|███████████████████████████████████████████████████████████████████████████████████████████▍                       | 159/200 [19:08<03:18,  4.83s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [19:12<03:10,  4.76s/it]                                                                                                                                                          {'loss': 0.8309, 'grad_norm': 7.495924472808838, 'learning_rate': 4.1e-05, 'epoch': 0.05}
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [19:12<03:10,  4.76s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████▌                      | 161/200 [19:16<02:56,  4.54s/it] 81%|█████████████████████████████████████████████████████████████████████████████████████████████▏                     | 162/200 [19:20<02:48,  4.43s/it] 82%|█████████████████████████████████████████████████████████████████████████████████████████████▋                     | 163/200 [19:25<02:41,  4.36s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▎                    | 164/200 [19:29<02:35,  4.33s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▉                    | 165/200 [19:33<02:28,  4.24s/it] 83%|███████████████████████████████████████████████████████████████████████████████████████████████▍                   | 166/200 [19:37<02:24,  4.26s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████                   | 167/200 [19:42<02:20,  4.27s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 168/200 [19:46<02:18,  4.32s/it] 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 169/200 [19:50<02:14,  4.34s/it] 85%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 170/200 [19:55<02:09,  4.33s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                | 171/200 [19:59<02:06,  4.37s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                | 172/200 [20:03<02:00,  4.32s/it] 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 173/200 [20:08<01:56,  4.31s/it] 87%|████████████████████████████████████████████████████████████████████████████████████████████████████               | 174/200 [20:12<01:54,  4.41s/it] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 175/200 [20:16<01:48,  4.33s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 176/200 [20:21<01:44,  4.36s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 177/200 [20:33<02:30,  6.56s/it] 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 178/200 [20:45<03:03,  8.34s/it] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 179/200 [20:55<03:08,  8.99s/it] 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [21:07<03:13,  9.69s/it]                                                                                                                                                          {'loss': 1.3192, 'grad_norm': 5.946681976318359, 'learning_rate': 2.1e-05, 'epoch': 0.05}
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [21:07<03:13,  9.69s/it] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████           | 181/200 [21:18<03:14, 10.26s/it] 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 182/200 [21:26<02:50,  9.50s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 183/200 [21:39<02:58, 10.47s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 184/200 [21:47<02:37,  9.83s/it] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 185/200 [21:51<02:02,  8.17s/it] 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 186/200 [21:55<01:36,  6.92s/it] 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 187/200 [22:00<01:18,  6.07s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 188/200 [22:04<01:05,  5.45s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 189/200 [22:08<00:55,  5.05s/it] 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 190/200 [22:12<00:48,  4.88s/it] 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 191/200 [22:16<00:41,  4.62s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 192/200 [22:21<00:36,  4.56s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 193/200 [22:25<00:31,  4.45s/it] 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 194/200 [22:29<00:26,  4.39s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 195/200 [22:33<00:21,  4.31s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 196/200 [22:37<00:17,  4.28s/it] 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 197/200 [22:41<00:12,  4.11s/it] 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 198/200 [22:50<00:11,  5.54s/it]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 199/200 [22:54<00:05,  5.12s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [22:58<00:00,  4.89s/it]                                                                                                                                                          {'loss': 2.2013, 'grad_norm': 6.330290794372559, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [22:58<00:00,  4.89s/it]                                                                                                                                                          {'train_runtime': 1380.9097, 'train_samples_per_second': 1.159, 'train_steps_per_second': 0.145, 'train_loss': 0.644025729894638, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [23:00<00:00,  4.89s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [23:00<00:00,  6.90s/it]
saved: /workspace/adapters/qlora_run27
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:12<00:37, 12.39s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:26<00:26, 13.19s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:57<00:21, 21.29s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:57<00:19, 19.04s/it]
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 151, in main
    base2 = load_bnb_model()
            ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 748, in _load_state_dict_into_meta_model
    param = param[...]
            ~~~~~^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 343.75 MiB is free. Including non-PyTorch memory, this process has 9.84 GiB memory in use. Process 23454 has 5.12 GiB memory in use. Process 23542 has 168.00 MiB memory in use. Of the allocated memory 9.38 GiB is allocated by PyTorch, and 310.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-26T22:06:14+00:00] ERROR rc=1 consec_fails=1
[2025-12-26T22:06:45+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12356
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:19,  6.40s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:13<00:13,  6.80s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:19<00:06,  6.63s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  5.94s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.20s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:07:59+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:07:59+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 158, in main
    tok, model = load_model_with_adapter(adapter)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 94, in load_model_with_adapter
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5432, in _load_pretrained_model
    caching_allocator_warmup(model, expanded_device_map, hf_quantizer)
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 6105, in caching_allocator_warmup
    _ = torch.empty(byte_count // factor, dtype=torch.float16, device=device, requires_grad=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.30 GiB. GPU 0 has a total capacity of 15.48 GiB of which 2.91 GiB is free. Including non-PyTorch memory, this process has 128.00 MiB memory in use. Process 23807 has 12.43 GiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:08:06+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:04,  1.57s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:03<00:03,  1.56s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:04<00:01,  1.53s/it]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.60s/it]
Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:03,  1.16s/it]Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:01<00:01,  1.29it/s]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:02<00:00,  1.50it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.67it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.48it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:10:33+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py:1566: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:03<00:10,  3.48s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:07<00:08,  4.02s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:11<00:03,  3.88s/it]Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:10:59+00:00] ERROR rc=1 consec_fails=1
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.40s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.20s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
[2025-12-26T22:11:29+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12357
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:03,  1.33s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:02<00:02,  1.19s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:03<00:01,  1.15s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.14s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.16s/it]
Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 179, in main
    choice, losses = choose_by_loss(tok, model)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 139, in choose_by_loss
    losses[k] = avg_loss_per_token(tok, model, texts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 116, in avg_loss_per_token
    out = model(**enc, labels=enc["input_ids"])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 463, in forward
    logits = self.lm_head(hidden_states[:, slice_indices, :])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 170, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 360, in pre_forward
    set_module_tensor_to_device(
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py", line 343, in set_module_tensor_to_device
    new_value = value.to(device, non_blocking=non_blocking)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 677.75 MiB is free. Process 23940 has 2.75 GiB memory in use. Including non-PyTorch memory, this process has 10.91 GiB memory in use. Process 24067 has 1.14 GiB memory in use. Of the allocated memory 10.64 GiB is allocated by PyTorch, and 110.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:11:40+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: random
ADAPTER: /workspace/adapters/qlora_run27
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:04,  1.38s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:02<00:02,  1.09s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:02<00:00,  1.13it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.31it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.15it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
LOSSES: {'A': 2.4285958744585514, 'B': 2.605314848944545, 'C': 3.2203608863055706}
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = B | mode = random
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.90s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.15s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.26s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.04s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.08s/it]
Map:   0%|                                                                                                               | 0/28107 [00:00<?, ? examples/s]Map:   2%|█▋                                                                                                 | 465/28107 [00:00<00:06, 4573.79 examples/s]Map:   4%|███▍                                                                                              | 1000/28107 [00:00<00:07, 3859.38 examples/s]Map:   5%|████▉                                                                                             | 1413/28107 [00:00<00:10, 2496.22 examples/s]Map:   6%|██████▏                                                                                           | 1785/28107 [00:00<00:13, 2020.53 examples/s]Map:   7%|███████▏                                                                                          | 2046/28107 [00:01<00:16, 1610.82 examples/s]Map:   9%|████████▉                                                                                         | 2561/28107 [00:01<00:11, 2261.99 examples/s]Map:  10%|██████████▏                                                                                       | 2906/28107 [00:01<00:10, 2505.99 examples/s]Map:  12%|███████████▎                                                                                      | 3243/28107 [00:01<00:14, 1759.81 examples/s]Map:  12%|████████████▏                                                                                     | 3511/28107 [00:01<00:19, 1250.23 examples/s]Map:  13%|█████████████▏                                                                                    | 3794/28107 [00:02<00:17, 1373.97 examples/s]Map:  14%|█████████████▉                                                                                    | 4000/28107 [00:02<00:19, 1268.73 examples/s]Map:  15%|██████████████▌                                                                                   | 4168/28107 [00:02<00:18, 1261.55 examples/s]Map:  16%|███████████████▏                                                                                  | 4359/28107 [00:02<00:18, 1260.73 examples/s]Map:  17%|████████████████▊                                                                                 | 4839/28107 [00:02<00:12, 1930.61 examples/s]Map:  18%|█████████████████▊                                                                                | 5103/28107 [00:02<00:11, 2080.85 examples/s]Map:  20%|███████████████████▊                                                                              | 5682/28107 [00:02<00:07, 2944.37 examples/s]Map:  22%|█████████████████████                                                                             | 6046/28107 [00:03<00:08, 2511.38 examples/s]Map:  23%|██████████████████████▎                                                                           | 6390/28107 [00:03<00:12, 1739.96 examples/s]Map:  24%|███████████████████████▏                                                                          | 6633/28107 [00:03<00:14, 1476.25 examples/s]Map:  24%|███████████████████████▉                                                                          | 6852/28107 [00:03<00:14, 1470.22 examples/s]Map:  25%|████████████████████████▋                                                                         | 7097/28107 [00:04<00:17, 1211.83 examples/s]Map:  26%|█████████████████████████▎                                                                        | 7256/28107 [00:04<00:17, 1175.23 examples/s]Map:  28%|███████████████████████████▍                                                                      | 7861/28107 [00:04<00:10, 2008.83 examples/s]Map:  29%|████████████████████████████▋                                                                     | 8223/28107 [00:04<00:08, 2324.79 examples/s]Map:  31%|██████████████████████████████                                                                    | 8615/28107 [00:04<00:11, 1745.79 examples/s]Map:  32%|██████████████████████████████▉                                                                   | 8870/28107 [00:05<00:13, 1399.64 examples/s]Map:  32%|███████████████████████████████▋                                                                  | 9082/28107 [00:05<00:17, 1100.25 examples/s]Map:  35%|█████████████████████████████████▉                                                                | 9720/28107 [00:05<00:10, 1823.76 examples/s]Map:  37%|████████████████████████████████████                                                             | 10435/28107 [00:05<00:06, 2695.85 examples/s]Map:  40%|██████████████████████████████████████▍                                                          | 11139/28107 [00:05<00:04, 3517.99 examples/s]Map:  42%|████████████████████████████████████████▊                                                        | 11827/28107 [00:05<00:03, 4231.24 examples/s]Map:  45%|███████████████████████████████████████████▋                                                     | 12641/28107 [00:05<00:03, 5138.69 examples/s]Map:  48%|██████████████████████████████████████████████▌                                                  | 13497/28107 [00:06<00:02, 5992.63 examples/s]Map:  51%|█████████████████████████████████████████████████▊                                               | 14422/28107 [00:06<00:01, 6844.11 examples/s]Map:  54%|████████████████████████████████████████████████████▌                                            | 15231/28107 [00:06<00:01, 7182.00 examples/s]Map:  58%|███████████████████████████████████████████████████████▉                                         | 16220/28107 [00:06<00:01, 6963.67 examples/s]Map:  60%|██████████████████████████████████████████████████████████▌                                      | 16972/28107 [00:06<00:01, 7106.72 examples/s]Map:  64%|██████████████████████████████████████████████████████████████▏                                  | 18018/28107 [00:06<00:01, 7053.70 examples/s]Map:  68%|█████████████████████████████████████████████████████████████████▌                               | 18984/28107 [00:06<00:01, 7713.47 examples/s]Map:  72%|█████████████████████████████████████████████████████████████████████▎                           | 20101/28107 [00:06<00:01, 7614.13 examples/s]Map:  75%|████████████████████████████████████████████████████████████████████████▌                        | 21021/28107 [00:07<00:00, 8008.09 examples/s]Map:  78%|███████████████████████████████████████████████████████████████████████████▌                     | 21907/28107 [00:07<00:00, 7259.26 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▉                  | 22862/28107 [00:07<00:00, 6164.67 examples/s]Map:  84%|█████████████████████████████████████████████████████████████████████████████████▊               | 23706/28107 [00:07<00:00, 6662.30 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████            | 24632/28107 [00:07<00:00, 7280.35 examples/s]Map:  91%|███████████████████████████████████████████████████████████████████████████████████████▊         | 25460/28107 [00:07<00:00, 7527.66 examples/s]Map:  95%|████████████████████████████████████████████████████████████████████████████████████████████     | 26670/28107 [00:07<00:00, 7709.71 examples/s]Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████▌ | 27676/28107 [00:07<00:00, 8296.57 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:08<00:00, 3502.67 examples/s]
TRAIN: cycle28  choice=B  data=/workspace/clean_data_norm/latest/B/dialog.txt  prev=/workspace/adapters/qlora_run27  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:04<16:28,  4.97s/it]  1%|█▏                                                                                                                   | 2/200 [00:08<14:30,  4.40s/it]Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 179, in main
    choice, losses = choose_by_loss(tok, model)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 139, in choose_by_loss
    losses[k] = avg_loss_per_token(tok, model, texts)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 116, in avg_loss_per_token
    out = model(**enc, labels=enc["input_ids"])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 463, in forward
    logits = self.lm_head(hidden_states[:, slice_indices, :])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 29.75 MiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Process 24178 has 7.66 GiB memory in use. Process 24207 has 5.12 GiB memory in use. Of the allocated memory 2.49 GiB is allocated by PyTorch, and 11.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4071, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py", line 2848, in backward
    self.scaler.scale(loss).backward(**kwargs)
  File "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 13.75 MiB is free. Process 24119 has 2.66 GiB memory in use. Including non-PyTorch memory, this process has 7.67 GiB memory in use. Process 24207 has 5.12 GiB memory in use. Of the allocated memory 7.16 GiB is allocated by PyTorch, and 357.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  1%|█▏                                                                                                                   | 2/200 [00:12<20:34,  6.24s/it]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:13:15+00:00] ERROR rc=1 consec_fails=1
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-26T22:13:15+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:07<00:21,  7.12s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:13<00:12,  6.43s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:16<00:05,  5.14s/it][2025-12-26T22:13:45+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12358
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:23<00:00,  5.95s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:23<00:00,  5.97s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:07<00:23,  7.84s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:16<00:16,  8.21s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:29<00:10, 10.58s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:50<00:00, 14.71s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:50<00:00, 12.69s/it]
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: random
ADAPTER: /workspace/adapters/qlora_run27
LOSSES: {'A': 2.4285958744585514, 'B': 2.605314848944545, 'C': 3.2203608863055706}
CHOICE: C
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = C | mode = random
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:25<01:17, 25.88s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:52<00:52, 26.41s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [01:20<00:27, 27.05s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:44<00:00, 25.73s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:44<00:00, 26.04s/it]
Map:   0%|                                                                                                               | 0/18000 [00:00<?, ? examples/s]Map:   0%|                                                                                                      | 15/18000 [00:00<03:26, 86.91 examples/s]Map:   0%|▍                                                                                                    | 71/18000 [00:00<01:26, 207.49 examples/s]Map:   1%|▌                                                                                                   | 109/18000 [00:00<01:09, 257.61 examples/s]Map:   1%|█                                                                                                   | 183/18000 [00:00<00:59, 301.33 examples/s]Map:   1%|█▎                                                                                                  | 240/18000 [00:00<01:00, 294.38 examples/s]Map:   2%|█▋                                                                                                  | 313/18000 [00:01<00:55, 319.53 examples/s]Map:   2%|██                                                                                                  | 365/18000 [00:01<00:58, 300.06 examples/s]Map:   2%|██▏                                                                                                 | 401/18000 [00:01<01:00, 292.06 examples/s]Map:   2%|██▍                                                                                                 | 438/18000 [00:01<01:03, 277.52 examples/s]Map:   3%|██▋                                                                                                 | 490/18000 [00:01<01:04, 271.83 examples/s]Map:   3%|██▉                                                                                                 | 526/18000 [00:01<01:13, 239.37 examples/s]Map:   3%|███                                                                                                 | 553/18000 [00:02<01:11, 244.80 examples/s]Map:   3%|███▎                                                                                                | 588/18000 [00:02<01:07, 258.39 examples/s]Map:   3%|███▍                                                                                                | 627/18000 [00:02<01:10, 246.11 examples/s]Map:   4%|███▊                                                                                                | 695/18000 [00:02<01:01, 279.79 examples/s]Map:   4%|████                                                                                                | 724/18000 [00:02<01:01, 280.43 examples/s]Map:   4%|████▎                                                                                               | 784/18000 [00:02<01:00, 285.18 examples/s]Map:   5%|█████▏                                                                                              | 924/18000 [00:02<00:33, 511.08 examples/s]Map:   6%|█████▌                                                                                             | 1000/18000 [00:03<00:50, 339.48 examples/s]Map:   6%|█████▊                                                                                             | 1057/18000 [00:03<01:00, 281.11 examples/s]Map:   6%|██████                                                                                             | 1100/18000 [00:03<00:58, 288.92 examples/s]Map:   7%|██████▋                                                                                            | 1213/18000 [00:03<00:43, 390.01 examples/s]Map:   7%|███████                                                                                            | 1284/18000 [00:04<00:44, 372.06 examples/s]Map:   8%|███████▋                                                                                           | 1390/18000 [00:04<00:44, 376.60 examples/s]Map:   8%|████████                                                                                           | 1455/18000 [00:04<00:39, 420.20 examples/s]Map:   9%|████████▋                                                                                          | 1570/18000 [00:04<00:34, 469.48 examples/s]Map:   9%|████████▉                                                                                          | 1636/18000 [00:04<00:32, 503.60 examples/s]Map:   9%|█████████▎                                                                                         | 1697/18000 [00:04<00:31, 523.69 examples/s]Map:  10%|█████████▋                                                                                         | 1764/18000 [00:05<00:36, 445.32 examples/s]Map:  10%|█████████▉                                                                                         | 1814/18000 [00:05<00:41, 386.20 examples/s]Map:  10%|██████████▎                                                                                        | 1867/18000 [00:05<00:38, 414.56 examples/s]Map:  11%|██████████▌                                                                                        | 1926/18000 [00:05<00:43, 371.81 examples/s]Map:  11%|██████████▉                                                                                        | 1978/18000 [00:05<00:48, 332.64 examples/s]Map:  11%|███████████▏                                                                                       | 2031/18000 [00:06<01:08, 234.41 examples/s]Map:  11%|███████████▎                                                                                       | 2061/18000 [00:06<01:05, 244.18 examples/s]Map:  12%|███████████▋                                                                                       | 2131/18000 [00:06<00:53, 298.32 examples/s]Map:  13%|████████████▉                                                                                      | 2363/18000 [00:06<00:25, 620.18 examples/s]Map:  14%|█████████████▍                                                                                     | 2440/18000 [00:06<00:28, 542.70 examples/s]Map:  14%|█████████████▉                                                                                     | 2543/18000 [00:07<00:28, 534.02 examples/s]Map:  15%|██████████████▌                                                                                    | 2637/18000 [00:07<00:27, 557.13 examples/s]Map:  15%|██████████████▉                                                                                    | 2723/18000 [00:07<00:32, 477.35 examples/s]Map:  15%|███████████████▎                                                                                   | 2777/18000 [00:07<00:31, 487.61 examples/s]Map:  16%|███████████████▋                                                                                   | 2860/18000 [00:07<00:27, 556.11 examples/s]Map:  17%|████████████████▍                                                                                  | 2997/18000 [00:07<00:22, 666.41 examples/s]Map:  17%|█████████████████                                                                                  | 3102/18000 [00:08<00:30, 481.62 examples/s]Map:  18%|█████████████████▋                                                                                 | 3207/18000 [00:08<00:29, 494.52 examples/s]Map:  18%|██████████████████▏                                                                                | 3301/18000 [00:08<00:30, 487.24 examples/s]Map:  19%|██████████████████▉                                                                                | 3432/18000 [00:08<00:27, 537.17 examples/s]Map:  20%|███████████████████▎                                                                               | 3517/18000 [00:08<00:24, 591.19 examples/s]Map:  20%|███████████████████▋                                                                               | 3583/18000 [00:08<00:23, 603.57 examples/s]Map:  21%|████████████████████▍                                                                              | 3714/18000 [00:09<00:22, 622.68 examples/s]Map:  21%|████████████████████▊                                                                              | 3781/18000 [00:09<00:22, 631.64 examples/s]Map:  21%|█████████████████████▏                                                                             | 3863/18000 [00:09<00:25, 551.68 examples/s]Map:  22%|█████████████████████▋                                                                             | 3933/18000 [00:09<00:24, 582.25 examples/s]Map:  22%|██████████████████████                                                                             | 4000/18000 [00:09<00:30, 466.00 examples/s]Map:  23%|██████████████████████▍                                                                            | 4083/18000 [00:09<00:27, 515.34 examples/s]Map:  23%|██████████████████████▉                                                                            | 4176/18000 [00:10<00:25, 547.03 examples/s]Map:  24%|███████████████████████▎                                                                           | 4248/18000 [00:10<00:23, 584.05 examples/s]Map:  24%|███████████████████████▊                                                                           | 4329/18000 [00:10<00:21, 635.64 examples/s]Map:  25%|████████████████████████▍                                                                          | 4448/18000 [00:10<00:21, 621.79 examples/s]Map:  25%|████████████████████████▊                                                                          | 4521/18000 [00:10<00:30, 441.38 examples/s]Map:  26%|█████████████████████████▋                                                                         | 4662/18000 [00:10<00:25, 525.55 examples/s]Map:  26%|██████████████████████████                                                                         | 4729/18000 [00:11<00:24, 547.29 examples/s]Map:  27%|██████████████████████████▌                                                                        | 4823/18000 [00:11<00:25, 525.18 examples/s]Map:  27%|██████████████████████████▉                                                                        | 4904/18000 [00:11<00:26, 486.26 examples/s]Map:  28%|███████████████████████████▍                                                                       | 4979/18000 [00:11<00:29, 440.52 examples/s]Map:  28%|███████████████████████████▋                                                                       | 5030/18000 [00:12<00:49, 259.94 examples/s]Map:  28%|███████████████████████████▉                                                                       | 5070/18000 [00:12<00:51, 253.29 examples/s]Map:  28%|████████████████████████████▏                                                                      | 5116/18000 [00:12<00:52, 247.22 examples/s]Map:  29%|████████████████████████████▎                                                                      | 5154/18000 [00:12<00:48, 266.73 examples/s]Map:  29%|████████████████████████████▉                                                                      | 5259/18000 [00:12<00:36, 346.06 examples/s]Map:  30%|█████████████████████████████▍                                                                     | 5341/18000 [00:12<00:29, 430.33 examples/s]Map:  31%|██████████████████████████████▍                                                                    | 5524/18000 [00:13<00:20, 594.50 examples/s]Map:  31%|██████████████████████████████▊                                                                    | 5595/18000 [00:13<00:20, 616.63 examples/s]Map:  32%|███████████████████████████████▎                                                                   | 5693/18000 [00:13<00:17, 693.28 examples/s]Map:  32%|███████████████████████████████▊                                                                   | 5776/18000 [00:13<00:16, 724.88 examples/s]Map:  33%|████████████████████████████████▍                                                                  | 5904/18000 [00:13<00:15, 761.28 examples/s]Map:  33%|█████████████████████████████████                                                                  | 6000/18000 [00:13<00:18, 643.88 examples/s]Map:  34%|█████████████████████████████████▋                                                                 | 6119/18000 [00:13<00:15, 760.02 examples/s]Map:  35%|██████████████████████████████████▊                                                                | 6332/18000 [00:14<00:11, 995.06 examples/s]Map:  36%|███████████████████████████████████▋                                                               | 6484/18000 [00:14<00:15, 760.20 examples/s]Map:  37%|████████████████████████████████████▏                                                              | 6573/18000 [00:14<00:17, 662.03 examples/s]Map:  37%|████████████████████████████████████▋                                                              | 6667/18000 [00:14<00:18, 601.42 examples/s]Map:  37%|█████████████████████████████████████                                                              | 6742/18000 [00:14<00:21, 532.39 examples/s]Map:  38%|█████████████████████████████████████▍                                                             | 6801/18000 [00:15<00:24, 460.16 examples/s]Map:  38%|██████████████████████████████████████                                                             | 6930/18000 [00:15<00:21, 515.85 examples/s]Map:  39%|██████████████████████████████████████▌                                                            | 7000/18000 [00:15<00:24, 445.45 examples/s]Map:  39%|██████████████████████████████████████▉                                                            | 7073/18000 [00:15<00:24, 441.25 examples/s]Map:  40%|███████████████████████████████████████▋                                                           | 7208/18000 [00:15<00:21, 513.18 examples/s]Map:  41%|████████████████████████████████████████▏                                                          | 7298/18000 [00:16<00:18, 580.32 examples/s]Map:  41%|████████████████████████████████████████▌                                                          | 7378/18000 [00:16<00:17, 622.63 examples/s]Map:  41%|████████████████████████████████████████▉                                                          | 7446/18000 [00:16<00:16, 629.25 examples/s]Map:  42%|█████████████████████████████████████████▍                                                         | 7540/18000 [00:16<00:18, 576.19 examples/s]Map:  42%|█████████████████████████████████████████▊                                                         | 7608/18000 [00:16<00:21, 491.47 examples/s]Map:  43%|██████████████████████████████████████████▎                                                        | 7693/18000 [00:16<00:20, 512.40 examples/s]Map:  43%|██████████████████████████████████████████▊                                                        | 7776/18000 [00:16<00:17, 577.51 examples/s]Map:  44%|███████████████████████████████████████████▋                                                       | 7935/18000 [00:17<00:12, 808.99 examples/s]Map:  45%|████████████████████████████████████████████▍                                                      | 8089/18000 [00:17<00:11, 863.38 examples/s]Map:  46%|█████████████████████████████████████████████▏                                                     | 8206/18000 [00:17<00:10, 932.85 examples/s]Map:  46%|█████████████████████████████████████████████▋                                                     | 8315/18000 [00:17<00:14, 659.23 examples/s]Map:  47%|██████████████████████████████████████████████▎                                                    | 8431/18000 [00:17<00:17, 544.86 examples/s]Map:  47%|██████████████████████████████████████████████▊                                                    | 8506/18000 [00:18<00:19, 496.79 examples/s]Map:  48%|███████████████████████████████████████████████▏                                                   | 8573/18000 [00:18<00:18, 512.13 examples/s]Map:  48%|███████████████████████████████████████████████▌                                                   | 8649/18000 [00:18<00:22, 413.69 examples/s]Map:  48%|███████████████████████████████████████████████▉                                                   | 8713/18000 [00:18<00:27, 332.92 examples/s]Map:  49%|████████████████████████████████████████████████▋                                                  | 8858/18000 [00:18<00:20, 441.26 examples/s]Map:  50%|█████████████████████████████████████████████████                                                  | 8918/18000 [00:19<00:25, 354.47 examples/s]Map:  50%|█████████████████████████████████████████████████▌                                                 | 9000/18000 [00:19<00:27, 326.35 examples/s]Map:  50%|█████████████████████████████████████████████████▉                                                 | 9081/18000 [00:19<00:25, 344.90 examples/s]Map:  52%|███████████████████████████████████████████████████▌                                               | 9370/18000 [00:19<00:13, 631.42 examples/s]Map:  53%|████████████████████████████████████████████████████▏                                              | 9489/18000 [00:20<00:13, 622.56 examples/s]Map:  53%|████████████████████████████████████████████████████▊                                              | 9603/18000 [00:20<00:13, 607.90 examples/s]Map:  54%|█████████████████████████████████████████████████████▎                                             | 9704/18000 [00:20<00:14, 578.73 examples/s]Map:  54%|█████████████████████████████████████████████████████▊                                             | 9794/18000 [00:20<00:12, 632.86 examples/s]Map:  55%|██████████████████████████████████████████████████████▎                                            | 9882/18000 [00:20<00:11, 679.69 examples/s]Map:  56%|██████████████████████████████████████████████████████▍                                           | 10000/18000 [00:21<00:13, 602.94 examples/s]Map:  56%|██████████████████████████████████████████████████████▉                                           | 10098/18000 [00:21<00:15, 518.33 examples/s]Map:  57%|███████████████████████████████████████████████████████▍                                          | 10171/18000 [00:21<00:16, 472.46 examples/s]Map:  57%|███████████████████████████████████████████████████████▉                                          | 10276/18000 [00:21<00:15, 489.49 examples/s]Map:  57%|████████████████████████████████████████████████████████▏                                         | 10329/18000 [00:21<00:15, 495.98 examples/s]Map:  58%|████████████████████████████████████████████████████████▌                                         | 10391/18000 [00:21<00:14, 518.61 examples/s]Map:  58%|█████████████████████████████████████████████████████████▏                                        | 10505/18000 [00:21<00:11, 655.57 examples/s]Map:  59%|█████████████████████████████████████████████████████████▋                                        | 10605/18000 [00:22<00:12, 597.96 examples/s]Map:  59%|██████████████████████████████████████████████████████████▏                                       | 10678/18000 [00:22<00:11, 625.75 examples/s]Map:  60%|██████████████████████████████████████████████████████████▋                                       | 10776/18000 [00:22<00:11, 634.54 examples/s]Map:  61%|███████████████████████████████████████████████████████████▎                                      | 10892/18000 [00:22<00:11, 612.02 examples/s]Map:  61%|███████████████████████████████████████████████████████████▋                                      | 10965/18000 [00:22<00:14, 486.27 examples/s]Map:  61%|████████████████████████████████████████████████████████████▏                                     | 11044/18000 [00:23<00:17, 394.59 examples/s]Map:  62%|████████████████████████████████████████████████████████████▋                                     | 11136/18000 [00:23<00:15, 443.88 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▎                                    | 11253/18000 [00:23<00:11, 571.64 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▋                                    | 11327/18000 [00:23<00:12, 549.13 examples/s]Map:  63%|██████████████████████████████████████████████████████████████                                    | 11403/18000 [00:23<00:13, 492.40 examples/s]Map:  64%|██████████████████████████████████████████████████████████████▋                                   | 11519/18000 [00:23<00:12, 522.20 examples/s]Map:  64%|███████████████████████████████████████████████████████████████▏                                  | 11598/18000 [00:24<00:11, 572.12 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▋                                  | 11688/18000 [00:24<00:11, 529.00 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▎                                 | 11823/18000 [00:24<00:09, 631.87 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████▍                                | 12016/18000 [00:24<00:07, 814.23 examples/s]Map:  69%|██████████████████████████████████████████████████████████████████▌                              | 12351/18000 [00:24<00:05, 1116.76 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████▏                             | 12534/18000 [00:25<00:06, 897.63 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████▊                             | 12634/18000 [00:25<00:06, 783.73 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▍                            | 12756/18000 [00:25<00:08, 639.11 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▊                            | 12834/18000 [00:25<00:09, 571.12 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▏                           | 12900/18000 [00:25<00:10, 506.75 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▊                           | 12995/18000 [00:26<00:10, 497.06 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████                           | 13062/18000 [00:26<00:12, 394.38 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▍                          | 13131/18000 [00:26<00:12, 380.48 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▊                          | 13196/18000 [00:26<00:13, 366.01 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▏                         | 13268/18000 [00:27<00:12, 364.14 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▊                         | 13382/18000 [00:27<00:10, 423.46 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▏                        | 13446/18000 [00:27<00:11, 393.31 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▋                        | 13538/18000 [00:27<00:10, 412.93 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████▏                       | 13623/18000 [00:27<00:10, 416.30 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████▌                       | 13691/18000 [00:27<00:09, 462.17 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████▊                       | 13747/18000 [00:28<00:08, 480.52 examples/s]Map:  77%|███████████████████████████████████████████████████████████████████████████▎                      | 13830/18000 [00:28<00:09, 457.97 examples/s]Map:  77%|███████████████████████████████████████████████████████████████████████████▋                      | 13912/18000 [00:28<00:09, 440.97 examples/s]Map:  78%|████████████████████████████████████████████████████████████████████████████▏                     | 14000/18000 [00:28<00:10, 377.60 examples/s]Map:  78%|████████████████████████████████████████████████████████████████████████████▋                     | 14086/18000 [00:28<00:09, 393.20 examples/s]Map:  79%|█████████████████████████████████████████████████████████████████████████████▎                    | 14207/18000 [00:29<00:08, 455.89 examples/s]Map:  79%|█████████████████████████████████████████████████████████████████████████████▊                    | 14299/18000 [00:29<00:06, 535.62 examples/s]Map:  80%|██████████████████████████████████████████████████████████████████████████████▍                   | 14411/18000 [00:29<00:06, 544.21 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▉                   | 14508/18000 [00:29<00:07, 442.39 examples/s]Map:  81%|███████████████████████████████████████████████████████████████████████████████▎                  | 14571/18000 [00:30<00:09, 364.21 examples/s]Map:  81%|███████████████████████████████████████████████████████████████████████████████▊                  | 14655/18000 [00:30<00:08, 379.37 examples/s]Map:  82%|████████████████████████████████████████████████████████████████████████████████▏                 | 14724/18000 [00:30<00:07, 427.57 examples/s]Map:  82%|████████████████████████████████████████████████████████████████████████████████▋                 | 14809/18000 [00:30<00:07, 426.86 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████▉                 | 14872/18000 [00:30<00:07, 392.41 examples/s]Map:  83%|█████████████████████████████████████████████████████████████████████████████████▏                | 14917/18000 [00:30<00:09, 341.99 examples/s]Map:  83%|█████████████████████████████████████████████████████████████████████████████████▍                | 14961/18000 [00:31<00:08, 359.33 examples/s]Map:  83%|█████████████████████████████████████████████████████████████████████████████████▋                | 15000/18000 [00:31<00:08, 337.47 examples/s]Map:  84%|██████████████████████████████████████████████████████████████████████████████████                | 15077/18000 [00:31<00:06, 420.11 examples/s]Map:  84%|██████████████████████████████████████████████████████████████████████████████████▍               | 15138/18000 [00:31<00:06, 415.86 examples/s]Map:  84%|██████████████████████████████████████████████████████████████████████████████████▋               | 15190/18000 [00:31<00:06, 437.87 examples/s]Map:  85%|███████████████████████████████████████████████████████████████████████████████████▏              | 15279/18000 [00:31<00:05, 491.10 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▊              | 15404/18000 [00:31<00:04, 537.99 examples/s]Map:  86%|████████████████████████████████████████████████████████████████████████████████████▌             | 15526/18000 [00:32<00:03, 683.30 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▊           | 15920/18000 [00:32<00:01, 1308.37 examples/s]Map:  89%|███████████████████████████████████████████████████████████████████████████████████████▋          | 16095/18000 [00:32<00:02, 731.33 examples/s]Map:  90%|████████████████████████████████████████████████████████████████████████████████████████▌         | 16276/18000 [00:32<00:02, 728.36 examples/s]Map:  91%|█████████████████████████████████████████████████████████████████████████████████████████▏        | 16380/18000 [00:33<00:02, 772.87 examples/s]Map:  94%|██████████████████████████████████████████████████████████████████████████████████████████▉      | 16868/18000 [00:33<00:00, 1481.83 examples/s]Map:  95%|████████████████████████████████████████████████████████████████████████████████████████████▎    | 17135/18000 [00:33<00:00, 1437.07 examples/s]Map:  96%|██████████████████████████████████████████████████████████████████████████████████████████████▌   | 17360/18000 [00:33<00:00, 856.72 examples/s]Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████▌  | 17553/18000 [00:34<00:00, 790.64 examples/s]Map:  98%|████████████████████████████████████████████████████████████████████████████████████████████████▎ | 17695/18000 [00:34<00:00, 771.68 examples/s]Map:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████ | 17824/18000 [00:34<00:00, 660.12 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████▊| 17971/18000 [00:34<00:00, 640.91 examples/s]Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 18000/18000 [00:35<00:00, 513.96 examples/s]
TRAIN: cycle28  choice=C  data=/workspace/clean_data_norm/latest/C/philosophy.txt  prev=/workspace/adapters/qlora_run27  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py", line 555, in forward
    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=quant_state).to(inp_dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 401, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 315, in forward
    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 51.75 MiB is free. Process 24301 has 8.18 GiB memory in use. Process 24411 has 168.00 MiB memory in use. Including non-PyTorch memory, this process has 7.06 GiB memory in use. Of the allocated memory 6.64 GiB is allocated by PyTorch, and 271.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|                                                                                                                             | 0/200 [00:15<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-26T22:21:37+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:16<00:49, 16.51s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:35<00:36, 18.00s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:50<00:16, 16.65s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:04<00:00, 15.67s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:04<00:00, 16.19s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 158, in main
    tok, model = load_model_with_adapter(adapter)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 100, in load_model_with_adapter
    model = PeftModel.from_pretrained(model, adapter_dir)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 568, in from_pretrained
    load_result = model.load_adapter(
                  ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1430, in load_adapter
    dispatch_model(
  File "/usr/local/lib/python3.12/dist-packages/accelerate/big_modeling.py", line 383, in dispatch_model
    raise ValueError(
ValueError: We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: base_model.model.model.layers.27, base_model.model.model.norm, base_model.model.model.rotary_emb, base_model.model.lm_head.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:24:16+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:12<00:38, 12.93s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:27<00:27, 13.78s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:43<00:14, 14.76s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.26s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.18s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 158, in main
    tok, model = load_model_with_adapter(adapter)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 100, in load_model_with_adapter
    model = PeftModel.from_pretrained(model, adapter_dir)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 568, in from_pretrained
    load_result = model.load_adapter(
                  ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1430, in load_adapter
    dispatch_model(
  File "/usr/local/lib/python3.12/dist-packages/accelerate/big_modeling.py", line 383, in dispatch_model
    raise ValueError(
ValueError: We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: base_model.model.model.layers.27, base_model.model.model.norm, base_model.model.model.rotary_emb, base_model.model.lm_head.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:26:41+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:15<00:46, 15.48s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:30<00:29, 14.93s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:45<00:15, 15.27s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:57<00:00, 13.78s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:57<00:00, 14.30s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:28:50+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:19,  6.44s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:13<00:13,  6.54s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:19<00:06,  6.32s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:23<00:00,  5.61s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:23<00:00,  5.91s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:29:54+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:29:54+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/choose_source.py", line 211, in <module>
    main()
  File "/workspace/choose_source.py", line 158, in main
    tok, model = load_model_with_adapter(adapter)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/choose_source.py", line 94, in load_model_with_adapter
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 770, in _load_state_dict_into_meta_model
    _load_parameter_into_model(model, param_name, param.to(param_device))
                                                  ^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 12.88 MiB is free. Including non-PyTorch memory, this process has 3.02 GiB memory in use. Process 24760 has 12.43 GiB memory in use. Of the allocated memory 2.88 GiB is allocated by PyTorch, and 16.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:06,  2.19s/it]Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' returned non-zero exit status 1.
[2025-12-26T22:30:03+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:03<00:03,  1.91s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:05<00:01,  1.70s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.48s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.62s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:00<00:02,  1.35it/s]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:01<00:01,  1.44it/s]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:02<00:00,  1.52it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.64it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.57it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py:1566: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
LOSSES: {'A': 2.4285958744585514, 'B': 2.605314848944545, 'C': 3.2203608863055706}
CHOICE: A
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = A | mode = loss
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:05<00:16,  5.35s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:17<00:18,  9.33s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:30<00:11, 11.20s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:34<00:00,  8.14s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:34<00:00,  8.58s/it]
Map:   0%|                                                                                                               | 0/27999 [00:00<?, ? examples/s]Map:   0%|▎                                                                                                    | 81/27999 [00:00<00:39, 715.26 examples/s]Map:   1%|▉                                                                                                  | 267/27999 [00:00<00:20, 1351.06 examples/s]Map:   2%|█▋                                                                                                 | 460/27999 [00:00<00:24, 1103.35 examples/s]Map:   2%|██▎                                                                                                 | 633/27999 [00:00<00:27, 989.00 examples/s]Map:   3%|██▋                                                                                                 | 765/27999 [00:00<00:28, 950.43 examples/s]Map:   3%|███                                                                                                 | 873/27999 [00:00<00:27, 980.92 examples/s]Map:   4%|███▌                                                                                               | 990/27999 [00:00<00:26, 1023.86 examples/s]Map:   5%|████▍                                                                                             | 1268/27999 [00:01<00:18, 1426.64 examples/s]Map:   6%|█████▌                                                                                            | 1576/27999 [00:01<00:15, 1757.34 examples/s]Map:   7%|██████▍                                                                                           | 1824/27999 [00:01<00:17, 1536.64 examples/s]Map:   7%|███████▎                                                                                          | 2083/27999 [00:01<00:16, 1592.36 examples/s]Map:   9%|████████▊                                                                                         | 2528/27999 [00:01<00:11, 2233.95 examples/s]Map:  10%|█████████▋                                                                                        | 2779/27999 [00:01<00:13, 1844.60 examples/s]Map:  11%|██████████▌                                                                                       | 3000/27999 [00:02<00:14, 1726.36 examples/s]Map:  13%|████████████▉                                                                                     | 3705/27999 [00:02<00:08, 2889.53 examples/s]Map:  15%|██████████████▎                                                                                   | 4088/27999 [00:02<00:16, 1428.81 examples/s]Map:  16%|███████████████▉                                                                                  | 4554/27999 [00:02<00:15, 1547.61 examples/s]Map:  18%|█████████████████▎                                                                                | 4954/27999 [00:03<00:12, 1880.99 examples/s]Map:  19%|██████████████████▌                                                                               | 5316/27999 [00:03<00:14, 1520.12 examples/s]Map:  21%|████████████████████▋                                                                             | 5919/27999 [00:03<00:10, 2053.31 examples/s]Map:  22%|█████████████████████▊                                                                            | 6235/27999 [00:04<00:17, 1237.51 examples/s]Map:  23%|██████████████████████▌                                                                           | 6462/27999 [00:04<00:21, 1010.68 examples/s]Map:  24%|███████████████████████▍                                                                           | 6641/27999 [00:04<00:22, 942.30 examples/s]Map:  24%|████████████████████████                                                                           | 6805/27999 [00:05<00:29, 726.89 examples/s]Map:  25%|████████████████████████▍                                                                          | 6922/27999 [00:05<00:30, 699.09 examples/s]Map:  25%|████████████████████████▊                                                                          | 7018/27999 [00:05<00:35, 588.91 examples/s]Map:  25%|█████████████████████████▏                                                                         | 7139/27999 [00:05<00:33, 626.42 examples/s]Map:  26%|█████████████████████████▊                                                                         | 7295/27999 [00:06<00:27, 756.44 examples/s]Map:  26%|██████████████████████████▏                                                                        | 7405/27999 [00:06<00:31, 652.12 examples/s]Map:  27%|██████████████████████████▌                                                                        | 7503/27999 [00:06<00:33, 607.44 examples/s]Map:  27%|██████████████████████████▉                                                                        | 7620/27999 [00:06<00:33, 600.35 examples/s]Map:  28%|███████████████████████████▏                                                                       | 7706/27999 [00:06<00:36, 551.98 examples/s]Map:  28%|███████████████████████████▍                                                                       | 7771/27999 [00:06<00:35, 568.25 examples/s]Map:  28%|███████████████████████████▊                                                                       | 7881/27999 [00:07<00:35, 561.63 examples/s]Map:  29%|████████████████████████████▎                                                                      | 8000/27999 [00:07<00:41, 487.66 examples/s]Map:  29%|████████████████████████████▋                                                                      | 8105/27999 [00:07<00:36, 543.99 examples/s]Map:  30%|█████████████████████████████▌                                                                     | 8365/27999 [00:07<00:21, 911.90 examples/s]Map:  30%|██████████████████████████████                                                                     | 8509/27999 [00:08<00:29, 661.38 examples/s]Map:  31%|██████████████████████████████▍                                                                    | 8605/27999 [00:08<00:36, 537.84 examples/s]Map:  31%|██████████████████████████████▊                                                                    | 8702/27999 [00:08<00:36, 534.83 examples/s]Map:  31%|███████████████████████████████                                                                    | 8777/27999 [00:08<00:36, 524.46 examples/s]Map:  32%|███████████████████████████████▎                                                                   | 8842/27999 [00:09<00:49, 383.49 examples/s]Map:  32%|███████████████████████████████▍                                                                   | 8895/27999 [00:09<01:00, 313.27 examples/s]Map:  32%|███████████████████████████████▋                                                                   | 8962/27999 [00:09<01:08, 279.12 examples/s]Map:  32%|███████████████████████████████▊                                                                   | 9000/27999 [00:09<01:13, 258.45 examples/s]Map:  33%|████████████████████████████████▏                                                                  | 9117/27999 [00:10<00:54, 347.16 examples/s]Map:  33%|████████████████████████████████▍                                                                  | 9178/27999 [00:10<00:48, 387.30 examples/s]Map:  33%|████████████████████████████████▊                                                                  | 9263/27999 [00:10<00:43, 431.61 examples/s]Map:  33%|█████████████████████████████████▏                                                                 | 9369/27999 [00:10<00:40, 463.20 examples/s]Map:  34%|█████████████████████████████████▎                                                                 | 9423/27999 [00:10<00:39, 475.77 examples/s]Map:  34%|█████████████████████████████████▌                                                                 | 9476/27999 [00:10<00:49, 372.41 examples/s]Map:  34%|█████████████████████████████████▋                                                                 | 9535/27999 [00:11<00:54, 339.33 examples/s]Map:  34%|█████████████████████████████████▊                                                                 | 9576/27999 [00:11<01:00, 305.52 examples/s]Map:  34%|██████████████████████████████████                                                                 | 9621/27999 [00:11<01:05, 281.16 examples/s]Map:  35%|██████████████████████████████████▏                                                                | 9672/27999 [00:11<01:08, 266.68 examples/s]Map:  35%|██████████████████████████████████▍                                                                | 9754/27999 [00:11<00:57, 316.91 examples/s]Map:  35%|██████████████████████████████████▋                                                                | 9803/27999 [00:11<00:52, 347.63 examples/s]Map:  35%|██████████████████████████████████▉                                                                | 9880/27999 [00:12<00:50, 360.92 examples/s]Map:  36%|███████████████████████████████████▏                                                               | 9948/27999 [00:12<00:42, 422.84 examples/s]Map:  36%|███████████████████████████████████                                                               | 10000/27999 [00:12<00:44, 405.25 examples/s]Map:  36%|███████████████████████████████████▎                                                              | 10093/27999 [00:12<00:34, 514.50 examples/s]Map:  36%|███████████████████████████████████▋                                                              | 10212/27999 [00:12<00:26, 671.76 examples/s]Map:  37%|████████████████████████████████████▏                                                             | 10340/27999 [00:12<00:26, 658.88 examples/s]Map:  37%|████████████████████████████████████▍                                                             | 10412/27999 [00:12<00:26, 670.39 examples/s]Map:  37%|████████████████████████████████████▋                                                             | 10495/27999 [00:13<00:27, 637.17 examples/s]Map:  38%|████████████████████████████████████▉                                                             | 10565/27999 [00:13<00:33, 527.97 examples/s]Map:  38%|█████████████████████████████████████▎                                                            | 10667/27999 [00:13<00:33, 520.97 examples/s]Map:  38%|█████████████████████████████████████▌                                                            | 10723/27999 [00:13<00:32, 528.45 examples/s]Map:  39%|█████████████████████████████████████▊                                                            | 10806/27999 [00:13<00:35, 487.52 examples/s]Map:  39%|██████████████████████████████████████▏                                                           | 10895/27999 [00:13<00:36, 472.64 examples/s]Map:  39%|██████████████████████████████████████▎                                                           | 10961/27999 [00:14<00:33, 508.22 examples/s]Map:  39%|██████████████████████████████████████▌                                                           | 11022/27999 [00:14<00:33, 509.11 examples/s]Map:  40%|███████████████████████████████████████▎                                                         | 11331/27999 [00:14<00:15, 1103.47 examples/s]Map:  41%|████████████████████████████████████████▏                                                         | 11473/27999 [00:14<00:16, 988.94 examples/s]Map:  42%|████████████████████████████████████████▉                                                         | 11685/27999 [00:14<00:22, 740.65 examples/s]Map:  42%|█████████████████████████████████████████▎                                                        | 11804/27999 [00:15<00:21, 751.22 examples/s]Map:  43%|█████████████████████████████████████████▊                                                        | 11941/27999 [00:15<00:23, 680.51 examples/s]Map:  43%|██████████████████████████████████████████▏                                                       | 12057/27999 [00:15<00:27, 570.93 examples/s]Map:  43%|██████████████████████████████████████████▌                                                       | 12163/27999 [00:15<00:28, 559.17 examples/s]Map:  44%|██████████████████████████████████████████▊                                                       | 12248/27999 [00:15<00:30, 523.59 examples/s]Map:  44%|███████████████████████████████████████████▎                                                      | 12384/27999 [00:16<00:25, 610.46 examples/s]Map:  44%|███████████████████████████████████████████▌                                                      | 12459/27999 [00:16<00:31, 490.76 examples/s]Map:  45%|███████████████████████████████████████████▊                                                      | 12516/27999 [00:16<00:34, 442.63 examples/s]Map:  45%|███████████████████████████████████████████▉                                                      | 12565/27999 [00:16<00:40, 384.64 examples/s]Map:  45%|████████████████████████████████████████████▏                                                     | 12616/27999 [00:16<00:44, 347.22 examples/s]Map:  45%|████████████████████████████████████████████▍                                                     | 12680/27999 [00:17<00:45, 338.73 examples/s]Map:  45%|████████████████████████████████████████████▌                                                     | 12723/27999 [00:17<00:44, 345.48 examples/s]Map:  46%|████████████████████████████████████████████▋                                                     | 12772/27999 [00:17<00:48, 312.09 examples/s]Map:  46%|████████████████████████████████████████████▊                                                     | 12806/27999 [00:17<00:55, 274.16 examples/s]Map:  46%|█████████████████████████████████████████████                                                     | 12858/27999 [00:17<00:57, 263.17 examples/s]Map:  46%|█████████████████████████████████████████████▏                                                    | 12912/27999 [00:18<00:56, 265.06 examples/s]Map:  46%|█████████████████████████████████████████████▍                                                    | 12988/27999 [00:18<00:44, 333.99 examples/s]Map:  47%|█████████████████████████████████████████████▋                                                    | 13043/27999 [00:18<00:51, 290.74 examples/s]Map:  47%|██████████████████████████████████████████████                                                    | 13165/27999 [00:18<00:38, 386.23 examples/s]Map:  47%|██████████████████████████████████████████████▍                                                   | 13278/27999 [00:18<00:33, 440.79 examples/s]Map:  48%|██████████████████████████████████████████████▊                                                   | 13357/27999 [00:19<00:34, 427.02 examples/s]Map:  48%|███████████████████████████████████████████████                                                   | 13429/27999 [00:19<00:30, 478.54 examples/s]Map:  48%|███████████████████████████████████████████████▍                                                  | 13556/27999 [00:19<00:27, 530.88 examples/s]Map:  49%|███████████████████████████████████████████████▊                                                  | 13678/27999 [00:19<00:25, 557.41 examples/s]Map:  49%|████████████████████████████████████████████████                                                  | 13739/27999 [00:19<00:25, 566.84 examples/s]Map:  49%|████████████████████████████████████████████████▍                                                 | 13828/27999 [00:19<00:22, 634.89 examples/s]Map:  50%|████████████████████████████████████████████████▊                                                 | 13935/27999 [00:19<00:23, 596.39 examples/s]Map:  50%|█████████████████████████████████████████████████                                                 | 14000/27999 [00:20<00:28, 495.28 examples/s]Map:  50%|█████████████████████████████████████████████████▎                                                | 14101/27999 [00:20<00:27, 505.69 examples/s]Map:  51%|█████████████████████████████████████████████████▋                                                | 14196/27999 [00:20<00:23, 590.79 examples/s]Map:  51%|█████████████████████████████████████████████████▉                                                | 14283/27999 [00:20<00:25, 535.51 examples/s]Map:  51%|██████████████████████████████████████████████████▍                                               | 14400/27999 [00:20<00:24, 552.02 examples/s]Map:  52%|██████████████████████████████████████████████████▋                                               | 14488/27999 [00:21<00:26, 515.93 examples/s]Map:  52%|██████████████████████████████████████████████████▉                                               | 14545/27999 [00:21<00:25, 524.83 examples/s]Map:  52%|███████████████████████████████████████████████████▏                                              | 14630/27999 [00:21<00:22, 592.71 examples/s]Map:  54%|███████████████████████████████████████████████████▉                                             | 15000/27999 [00:21<00:12, 1056.87 examples/s]Map:  55%|█████████████████████████████████████████████████████▏                                           | 15339/27999 [00:21<00:08, 1419.78 examples/s]Map:  56%|██████████████████████████████████████████████████████▎                                          | 15667/27999 [00:21<00:06, 1820.71 examples/s]Map:  57%|██████████████████████████████████████████████████████▉                                          | 15866/27999 [00:21<00:07, 1664.85 examples/s]Map:  58%|███████████████████████████████████████████████████████▉                                         | 16157/27999 [00:22<00:06, 1748.47 examples/s]Map:  59%|█████████████████████████████████████████████████████████▏                                       | 16505/27999 [00:22<00:06, 1747.65 examples/s]Map:  60%|█████████████████████████████████████████████████████████▉                                       | 16719/27999 [00:22<00:06, 1828.15 examples/s]Map:  61%|███████████████████████████████████████████████████████████                                      | 17063/27999 [00:22<00:06, 1636.44 examples/s]Map:  62%|████████████████████████████████████████████████████████████▎                                    | 17414/27999 [00:22<00:05, 2003.91 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▎                                   | 17711/27999 [00:22<00:05, 1817.83 examples/s]Map:  64%|██████████████████████████████████████████████████████████████▏                                  | 17958/27999 [00:23<00:08, 1208.15 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▍                                  | 18123/27999 [00:23<00:11, 874.22 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▉                                  | 18257/27999 [00:23<00:13, 741.68 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▎                                 | 18360/27999 [00:24<00:13, 689.00 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▌                                 | 18446/27999 [00:24<00:15, 624.18 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▉                                 | 18547/27999 [00:24<00:17, 526.91 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████▎                                | 18664/27999 [00:24<00:17, 540.20 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████▌                                | 18730/27999 [00:24<00:16, 556.59 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████▊                                | 18810/27999 [00:25<00:15, 598.14 examples/s]Map:  68%|██████████████████████████████████████████████████████████████████▎                               | 18933/27999 [00:25<00:12, 724.55 examples/s]Map:  68%|██████████████████████████████████████████████████████████████████▌                               | 19020/27999 [00:25<00:17, 527.12 examples/s]Map:  68%|██████████████████████████████████████████████████████████████████▉                               | 19121/27999 [00:25<00:15, 564.04 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████▏                              | 19192/27999 [00:25<00:14, 591.14 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████▍                              | 19281/27999 [00:25<00:14, 590.25 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████▉                              | 19397/27999 [00:26<00:14, 588.22 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████                              | 19461/27999 [00:26<00:14, 597.39 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████▍                             | 19550/27999 [00:26<00:12, 661.17 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████▊                             | 19648/27999 [00:26<00:12, 663.61 examples/s]Map:  70%|█████████████████████████████████████████████████████████████████████                             | 19737/27999 [00:26<00:14, 578.97 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▎                            | 19820/27999 [00:26<00:15, 521.81 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▋                            | 19920/27999 [00:27<00:17, 474.25 examples/s]Map:  71%|██████████████████████████████████████████████████████████████████████                            | 20000/27999 [00:27<00:18, 431.14 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▎                           | 20079/27999 [00:27<00:17, 440.95 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▍                           | 20130/27999 [00:27<00:17, 451.95 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▊                           | 20230/27999 [00:27<00:15, 512.14 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████                           | 20304/27999 [00:27<00:13, 559.21 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▎                          | 20381/27999 [00:27<00:13, 546.96 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▌                          | 20451/27999 [00:28<00:13, 580.35 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▊                          | 20512/27999 [00:28<00:12, 586.86 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████                          | 20604/27999 [00:28<00:13, 536.59 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▍                         | 20679/27999 [00:28<00:15, 476.24 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▋                         | 20762/27999 [00:28<00:13, 549.41 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▏                        | 20903/27999 [00:28<00:10, 670.54 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▌                        | 21000/27999 [00:29<00:13, 514.89 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████▎                       | 21227/27999 [00:29<00:09, 699.55 examples/s]Map:  77%|███████████████████████████████████████████████████████████████████████████                       | 21459/27999 [00:29<00:07, 910.13 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▉                      | 21630/27999 [00:29<00:05, 1061.70 examples/s]Map:  78%|███████████████████████████████████████████████████████████████████████████▊                     | 21874/27999 [00:29<00:04, 1356.57 examples/s]Map:  80%|█████████████████████████████████████████████████████████████████████████████▎                   | 22321/27999 [00:29<00:03, 1868.88 examples/s]Map:  80%|██████████████████████████████████████████████████████████████████████████████                   | 22534/27999 [00:29<00:03, 1709.20 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▍                 | 22919/27999 [00:30<00:02, 1993.71 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████                 | 23127/27999 [00:30<00:02, 2012.40 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████▉                | 23370/27999 [00:30<00:02, 2113.68 examples/s]Map:  85%|██████████████████████████████████████████████████████████████████████████████████▏              | 23738/27999 [00:30<00:01, 2517.46 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▋             | 24174/27999 [00:30<00:01, 2149.03 examples/s]Map:  88%|████████████████████████████████████████████████████████████████████████████████████▉            | 24502/27999 [00:30<00:01, 2392.35 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▊           | 24777/27999 [00:30<00:01, 2475.34 examples/s]Map:  90%|███████████████████████████████████████████████████████████████████████████████████████▌         | 25285/27999 [00:31<00:00, 2775.32 examples/s]Map:  92%|█████████████████████████████████████████████████████████████████████████████████████████▎       | 25788/27999 [00:31<00:00, 2681.77 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████      | 26295/27999 [00:31<00:00, 2626.21 examples/s]Map:  95%|████████████████████████████████████████████████████████████████████████████████████████████▏    | 26623/27999 [00:31<00:00, 2755.66 examples/s]Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████▎   | 26949/27999 [00:31<00:00, 2585.04 examples/s]Map:  98%|██████████████████████████████████████████████████████████████████████████████████████████████▊  | 27369/27999 [00:31<00:00, 2649.40 examples/s]Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████▉| 27996/27999 [00:32<00:00, 2826.54 examples/s]Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:32<00:00, 873.02 examples/s]
TRAIN: cycle28  choice=A  data=/workspace/clean_data_norm/latest/A/science.txt  prev=/workspace/adapters/qlora_run27  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:06<20:51,  6.29s/it]  1%|█▏                                                                                                                   | 2/200 [00:10<15:56,  4.83s/it]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4071, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py", line 2848, in backward
    self.scaler.scale(loss).backward(**kwargs)
  File "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 65.75 MiB is free. Process 24845 has 1.63 GiB memory in use. Including non-PyTorch memory, this process has 8.19 GiB memory in use. Process 24929 has 5.57 GiB memory in use. Of the allocated memory 7.72 GiB is allocated by PyTorch, and 314.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  1%|█▏                                                                                                                   | 2/200 [00:12<21:08,  6.41s/it]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-26T22:32:25+00:00] ERROR rc=1 consec_fails=1
[2025-12-26T22:32:55+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12359
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:19,  6.66s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:13<00:13,  6.83s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:19<00:06,  6.53s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  5.76s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.09s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: random
ADAPTER: /workspace/adapters/qlora_run27
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:37:22+00:00] ERROR rc=1 consec_fails=1
[2025-12-26T22:37:52+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12360
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:20,  6.80s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:12<00:12,  6.27s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:18<00:06,  6.25s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:28<00:00,  7.50s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:28<00:00,  7.09s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:38:36+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: random
ADAPTER: /workspace/adapters/qlora_run27
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:07<00:22,  7.53s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:15<00:15,  7.92s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:25<00:08,  8.92s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:35<00:00,  9.34s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:35<00:00,  8.95s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
LOSSES: {'A': 2.4285958744585514, 'B': 2.605314848944545, 'C': 3.2203608863055706}
CHOICE: C
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = C | mode = random
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:24<01:13, 24.52s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:50<00:51, 25.60s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [01:24<00:29, 29.34s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:49<00:00, 27.63s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:49<00:00, 27.42s/it]
Map:   0%|                                                                                                               | 0/18000 [00:00<?, ? examples/s]Map:   0%|                                                                                                      | 11/18000 [00:00<05:43, 52.30 examples/s]Map:   0%|▏                                                                                                     | 27/18000 [00:00<04:04, 73.38 examples/s]Map:   0%|▏                                                                                                     | 37/18000 [00:00<03:48, 78.65 examples/s]Map:   0%|▎                                                                                                     | 59/18000 [00:00<03:07, 95.60 examples/s]Map:   0%|▍                                                                                                    | 77/18000 [00:00<02:42, 110.44 examples/s]Map:   1%|▌                                                                                                    | 99/18000 [00:00<02:38, 112.96 examples/s]Map:   1%|▋                                                                                                   | 114/18000 [00:01<02:57, 101.02 examples/s]Map:   1%|▊                                                                                                   | 148/18000 [00:01<02:22, 125.33 examples/s]Map:   1%|█▏                                                                                                  | 215/18000 [00:01<01:15, 234.57 examples/s]Map:   2%|█▉                                                                                                  | 340/18000 [00:01<00:42, 415.20 examples/s]Map:   2%|██▏                                                                                                 | 404/18000 [00:01<00:43, 404.83 examples/s]Map:   3%|██▊                                                                                                 | 501/18000 [00:02<00:53, 326.64 examples/s]Map:   3%|███                                                                                                 | 550/18000 [00:02<00:49, 352.88 examples/s]Map:   3%|███▎                                                                                                | 606/18000 [00:02<00:44, 389.91 examples/s]Map:   4%|███▉                                                                                                | 705/18000 [00:02<00:40, 428.65 examples/s]Map:   5%|████▋                                                                                               | 834/18000 [00:02<00:34, 500.45 examples/s]Map:   5%|█████▎                                                                                              | 958/18000 [00:02<00:31, 539.45 examples/s]Map:   6%|█████▌                                                                                             | 1015/18000 [00:03<00:48, 348.91 examples/s]Map:   6%|█████▉                                                                                             | 1069/18000 [00:03<00:48, 350.83 examples/s]Map:   6%|██████▏                                                                                            | 1127/18000 [00:03<00:50, 332.66 examples/s]Map:   7%|██████▍                                                                                            | 1174/18000 [00:03<00:47, 354.83 examples/s]Map:   7%|███████▍                                                                                           | 1345/18000 [00:03<00:29, 565.08 examples/s]Map:   8%|███████▊                                                                                           | 1414/18000 [00:04<00:33, 489.92 examples/s]Map:   8%|████████                                                                                           | 1474/18000 [00:04<00:38, 429.35 examples/s]Map:   9%|████████▍                                                                                          | 1543/18000 [00:04<00:40, 403.32 examples/s]Map:   9%|████████▊                                                                                          | 1599/18000 [00:04<00:45, 364.29 examples/s]Map:   9%|█████████                                                                                          | 1657/18000 [00:04<00:47, 342.01 examples/s]Map:  10%|█████████▍                                                                                         | 1716/18000 [00:05<00:42, 386.22 examples/s]Map:  10%|██████████▎                                                                                        | 1864/18000 [00:05<00:29, 553.60 examples/s]Map:  11%|██████████▋                                                                                        | 1938/18000 [00:05<00:29, 536.83 examples/s]Map:  11%|███████████                                                                                        | 2000/18000 [00:05<00:37, 430.49 examples/s]Map:  12%|███████████▍                                                                                       | 2078/18000 [00:05<00:32, 483.04 examples/s]Map:  12%|███████████▉                                                                                       | 2173/18000 [00:05<00:30, 525.55 examples/s]Map:  13%|████████████▌                                                                                      | 2281/18000 [00:06<00:29, 531.39 examples/s]Map:  13%|█████████████▏                                                                                     | 2393/18000 [00:06<00:26, 589.02 examples/s]Map:  14%|█████████████▌                                                                                     | 2471/18000 [00:06<00:32, 480.74 examples/s]Map:  14%|██████████████▏                                                                                    | 2579/18000 [00:06<00:30, 499.50 examples/s]Map:  15%|██████████████▌                                                                                    | 2638/18000 [00:06<00:29, 515.64 examples/s]Map:  15%|██████████████▉                                                                                    | 2706/18000 [00:06<00:27, 549.41 examples/s]Map:  16%|███████████████▌                                                                                   | 2833/18000 [00:07<00:26, 581.14 examples/s]Map:  16%|████████████████▎                                                                                  | 2967/18000 [00:07<00:24, 612.14 examples/s]Map:  17%|████████████████▊                                                                                  | 3057/18000 [00:07<00:31, 478.87 examples/s]Map:  17%|█████████████████                                                                                  | 3111/18000 [00:07<00:30, 488.67 examples/s]Map:  18%|█████████████████▋                                                                                 | 3210/18000 [00:07<00:30, 491.11 examples/s]Map:  18%|██████████████████                                                                                 | 3291/18000 [00:07<00:26, 549.26 examples/s]Map:  19%|██████████████████▋                                                                                | 3406/18000 [00:08<00:26, 558.11 examples/s]Map:  20%|███████████████████▎                                                                               | 3517/18000 [00:08<00:25, 558.75 examples/s]Map:  20%|███████████████████▉                                                                               | 3619/18000 [00:08<00:26, 542.84 examples/s]Map:  21%|████████████████████▍                                                                              | 3723/18000 [00:08<00:26, 535.34 examples/s]Map:  21%|████████████████████▉                                                                              | 3812/18000 [00:08<00:27, 507.78 examples/s]Map:  22%|█████████████████████▊                                                                             | 3964/18000 [00:09<00:22, 634.44 examples/s]Map:  22%|██████████████████████▏                                                                            | 4034/18000 [00:09<00:27, 502.34 examples/s]Map:  23%|██████████████████████▌                                                                            | 4112/18000 [00:09<00:29, 468.88 examples/s]Map:  23%|██████████████████████▉                                                                            | 4163/18000 [00:09<00:29, 475.26 examples/s]Map:  24%|███████████████████████▍                                                                           | 4268/18000 [00:09<00:25, 537.69 examples/s]Map:  24%|███████████████████████▊                                                                           | 4332/18000 [00:09<00:26, 506.56 examples/s]Map:  24%|████████████████████████▏                                                                          | 4389/18000 [00:10<00:26, 519.71 examples/s]Map:  25%|████████████████████████▌                                                                          | 4461/18000 [00:10<00:23, 564.24 examples/s]Map:  25%|█████████████████████████                                                                          | 4562/18000 [00:10<00:24, 542.35 examples/s]Map:  26%|█████████████████████████▊                                                                         | 4693/18000 [00:10<00:22, 582.18 examples/s]Map:  27%|██████████████████████████▎                                                                        | 4778/18000 [00:10<00:22, 578.19 examples/s]Map:  27%|██████████████████████████▋                                                                        | 4860/18000 [00:10<00:25, 519.75 examples/s]Map:  27%|███████████████████████████                                                                        | 4918/18000 [00:11<00:24, 529.55 examples/s]Map:  28%|███████████████████████████▍                                                                       | 4983/18000 [00:11<00:25, 503.08 examples/s]Map:  28%|███████████████████████████▋                                                                       | 5037/18000 [00:11<00:30, 418.93 examples/s]Map:  29%|████████████████████████████▎                                                                      | 5159/18000 [00:11<00:22, 582.09 examples/s]Map:  29%|█████████████████████████████                                                                      | 5277/18000 [00:11<00:21, 586.16 examples/s]Map:  30%|██████████████████████████████                                                                     | 5463/18000 [00:11<00:17, 706.23 examples/s]Map:  31%|██████████████████████████████▌                                                                    | 5562/18000 [00:11<00:16, 761.11 examples/s]Map:  32%|███████████████████████████████▎                                                                   | 5704/18000 [00:12<00:16, 743.11 examples/s]Map:  32%|████████████████████████████████▏                                                                  | 5848/18000 [00:12<00:16, 735.40 examples/s]Map:  33%|████████████████████████████████▋                                                                  | 5950/18000 [00:12<00:18, 661.80 examples/s]Map:  34%|█████████████████████████████████▎                                                                 | 6055/18000 [00:12<00:22, 531.29 examples/s]Map:  34%|█████████████████████████████████▊                                                                 | 6143/18000 [00:13<00:21, 545.58 examples/s]Map:  35%|██████████████████████████████████▏                                                                | 6211/18000 [00:13<00:20, 568.11 examples/s]Map:  35%|██████████████████████████████████▌                                                                | 6276/18000 [00:13<00:21, 533.25 examples/s]Map:  35%|██████████████████████████████████▉                                                                | 6343/18000 [00:13<00:22, 507.96 examples/s]Map:  36%|███████████████████████████████████▏                                                               | 6407/18000 [00:13<00:23, 485.07 examples/s]Map:  36%|███████████████████████████████████▋                                                               | 6495/18000 [00:13<00:24, 468.43 examples/s]Map:  36%|████████████████████████████████████▏                                                              | 6569/18000 [00:13<00:21, 522.16 examples/s]Map:  37%|████████████████████████████████████▌                                                              | 6646/18000 [00:13<00:19, 574.70 examples/s]Map:  37%|█████████████████████████████████████                                                              | 6741/18000 [00:14<00:25, 439.11 examples/s]Map:  38%|█████████████████████████████████████▍                                                             | 6810/18000 [00:14<00:26, 420.52 examples/s]Map:  39%|██████████████████████████████████████▎                                                            | 6957/18000 [00:14<00:21, 520.08 examples/s]Map:  39%|██████████████████████████████████████▋                                                            | 7023/18000 [00:14<00:23, 461.08 examples/s]Map:  40%|███████████████████████████████████████▋                                                           | 7214/18000 [00:14<00:14, 723.08 examples/s]Map:  41%|████████████████████████████████████████▎                                                          | 7340/18000 [00:15<00:15, 692.00 examples/s]Map:  41%|████████████████████████████████████████▉                                                          | 7433/18000 [00:15<00:17, 615.55 examples/s]Map:  42%|█████████████████████████████████████████▋                                                         | 7582/18000 [00:15<00:15, 659.24 examples/s]Map:  43%|██████████████████████████████████████████▏                                                        | 7669/18000 [00:15<00:14, 698.11 examples/s]Map:  43%|██████████████████████████████████████████▊                                                        | 7793/18000 [00:15<00:15, 670.52 examples/s]Map:  44%|███████████████████████████████████████████▍                                                       | 7900/18000 [00:16<00:16, 625.31 examples/s]Map:  44%|████████████████████████████████████████████                                                       | 8000/18000 [00:16<00:18, 555.35 examples/s]Map:  45%|████████████████████████████████████████████▌                                                      | 8093/18000 [00:16<00:16, 604.05 examples/s]Map:  45%|████████████████████████████████████████████▉                                                      | 8163/18000 [00:16<00:17, 567.94 examples/s]Map:  46%|█████████████████████████████████████████████▍                                                     | 8265/18000 [00:16<00:17, 547.14 examples/s]Map:  46%|█████████████████████████████████████████████▉                                                     | 8357/18000 [00:16<00:15, 619.72 examples/s]Map:  47%|██████████████████████████████████████████████▍                                                    | 8435/18000 [00:16<00:14, 654.56 examples/s]Map:  47%|██████████████████████████████████████████████▉                                                    | 8527/18000 [00:17<00:13, 714.52 examples/s]Map:  48%|███████████████████████████████████████████████▌                                                   | 8654/18000 [00:17<00:13, 687.06 examples/s]Map:  49%|████████████████████████████████████████████████▏                                                  | 8760/18000 [00:17<00:16, 575.18 examples/s]Map:  50%|█████████████████████████████████████████████████▍                                                 | 8980/18000 [00:17<00:11, 808.43 examples/s]Map:  50%|█████████████████████████████████████████████████▉                                                 | 9072/18000 [00:17<00:13, 639.96 examples/s]Map:  51%|██████████████████████████████████████████████████▍                                                | 9180/18000 [00:18<00:15, 567.54 examples/s]Map:  52%|███████████████████████████████████████████████████▏                                               | 9311/18000 [00:18<00:13, 638.86 examples/s]Map:  52%|███████████████████████████████████████████████████▋                                               | 9404/18000 [00:18<00:13, 633.54 examples/s]Map:  53%|████████████████████████████████████████████████████▎                                              | 9503/18000 [00:18<00:16, 507.41 examples/s]Map:  53%|████████████████████████████████████████████████████▊                                              | 9597/18000 [00:18<00:16, 495.94 examples/s]Map:  54%|█████████████████████████████████████████████████████▏                                             | 9668/18000 [00:19<00:18, 455.14 examples/s]Map:  54%|█████████████████████████████████████████████████████▋                                             | 9766/18000 [00:19<00:17, 466.34 examples/s]Map:  55%|██████████████████████████████████████████████████████                                             | 9838/18000 [00:19<00:16, 509.91 examples/s]Map:  55%|██████████████████████████████████████████████████████▍                                            | 9896/18000 [00:19<00:15, 522.94 examples/s]Map:  56%|██████████████████████████████████████████████████████▍                                           | 10000/18000 [00:19<00:16, 483.34 examples/s]Map:  56%|██████████████████████████████████████████████████████▊                                           | 10061/18000 [00:19<00:15, 502.65 examples/s]Map:  56%|███████████████████████████████████████████████████████▏                                          | 10129/18000 [00:20<00:16, 487.78 examples/s]Map:  57%|███████████████████████████████████████████████████████▉                                          | 10267/18000 [00:20<00:12, 614.65 examples/s]Map:  58%|████████████████████████████████████████████████████████▍                                         | 10359/18000 [00:20<00:13, 559.92 examples/s]Map:  59%|█████████████████████████████████████████████████████████▊                                        | 10630/18000 [00:20<00:07, 997.75 examples/s]Map:  60%|██████████████████████████████████████████████████████████▊                                       | 10797/18000 [00:20<00:08, 857.82 examples/s]Map:  61%|███████████████████████████████████████████████████████████▋                                      | 10972/18000 [00:20<00:08, 864.44 examples/s]Map:  62%|████████████████████████████████████████████████████████████▌                                     | 11123/18000 [00:21<00:10, 629.70 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▍                                    | 11287/18000 [00:21<00:09, 677.73 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▉                                    | 11382/18000 [00:21<00:10, 618.31 examples/s]Map:  64%|██████████████████████████████████████████████████████████████▍                                   | 11458/18000 [00:21<00:11, 556.71 examples/s]Map:  64%|██████████████████████████████████████████████████████████████▉                                   | 11567/18000 [00:22<00:11, 555.13 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▌                                  | 11686/18000 [00:22<00:10, 611.08 examples/s]Map:  65%|████████████████████████████████████████████████████████████████▏                                 | 11781/18000 [00:22<00:11, 528.11 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▍                                 | 11846/18000 [00:22<00:11, 548.28 examples/s]Map:  66%|█████████████████████████████████████████████████████████████████                                 | 11941/18000 [00:22<00:11, 525.21 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████▎                                | 12000/18000 [00:23<00:13, 449.88 examples/s]Map:  68%|███████████████████████████████████████████████████████████████████                               | 12314/18000 [00:23<00:06, 945.50 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████▉                              | 12487/18000 [00:23<00:08, 671.31 examples/s]Map:  70%|████████████████████████████████████████████████████████████████████▉                             | 12656/18000 [00:23<00:08, 608.71 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▍                            | 12762/18000 [00:24<00:09, 555.82 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▉                            | 12840/18000 [00:24<00:10, 514.95 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▎                           | 12907/18000 [00:24<00:10, 467.34 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████▊                           | 12997/18000 [00:24<00:10, 463.80 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████                           | 13053/18000 [00:24<00:12, 411.78 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▍                          | 13126/18000 [00:25<00:12, 398.98 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████▉                          | 13205/18000 [00:25<00:11, 428.85 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▏                         | 13257/18000 [00:25<00:10, 444.66 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▌                         | 13324/18000 [00:25<00:10, 444.40 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▏                        | 13435/18000 [00:25<00:08, 531.04 examples/s]Map:  75%|█████████████████████████████████████████████████████████████████████████▋                        | 13536/18000 [00:25<00:07, 630.64 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████                        | 13607/18000 [00:25<00:07, 583.85 examples/s]Map:  76%|██████████████████████████████████████████████████████████████████████████▊                       | 13735/18000 [00:26<00:07, 605.82 examples/s]Map:  78%|████████████████████████████████████████████████████████████████████████████                      | 13966/18000 [00:26<00:04, 966.30 examples/s]Map:  79%|████████████████████████████████████████████████████████████████████████████▌                    | 14216/18000 [00:26<00:02, 1321.24 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▍                  | 14550/18000 [00:26<00:01, 1821.57 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▉                 | 14835/18000 [00:26<00:01, 2090.15 examples/s]Map:  85%|██████████████████████████████████████████████████████████████████████████████████               | 15230/18000 [00:26<00:01, 2042.03 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▋             | 15538/18000 [00:26<00:01, 2283.89 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▌           | 15885/18000 [00:26<00:00, 2578.38 examples/s]Map:  91%|████████████████████████████████████████████████████████████████████████████████████████▍        | 16417/18000 [00:27<00:00, 2617.75 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████▌     | 17000/18000 [00:27<00:00, 2718.58 examples/s]Map:  97%|██████████████████████████████████████████████████████████████████████████████████████████████▍  | 17524/18000 [00:27<00:00, 2695.28 examples/s]Map:  99%|████████████████████████████████████████████████████████████████████████████████████████████████ | 17827/18000 [00:27<00:00, 2301.56 examples/s]Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 18000/18000 [00:28<00:00, 638.55 examples/s]
TRAIN: cycle28  choice=C  data=/workspace/clean_data_norm/latest/C/philosophy.txt  prev=/workspace/adapters/qlora_run27  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:12<41:30, 12.51s/it]  1%|█▏                                                                                                                   | 2/200 [00:23<38:58, 11.81s/it]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py", line 555, in forward
    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=quant_state).to(inp_dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 401, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 315, in forward
    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 259.75 MiB is free. Process 25078 has 5.57 GiB memory in use. Process 25197 has 2.09 GiB memory in use. Including non-PyTorch memory, this process has 7.55 GiB memory in use. Of the allocated memory 7.18 GiB is allocated by PyTorch, and 212.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  1%|█▏                                                                                                                   | 2/200 [00:28<46:58, 14.24s/it]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-26T22:47:33+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:18,  6.21s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:11<00:11,  5.91s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:17<00:05,  5.82s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.31s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.54s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:48:44+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:48:44+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.93s/it]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.42s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.40s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.30s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.36s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.30s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.08s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.13s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.17s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.25s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 350, in main
    subprocess.run(["python3", str(ROOT / "choose_source.py")], check=True, env=env_choose)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/choose_source.py']' died with <Signals.SIGKILL: 9>.
[2025-12-26T22:50:23+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:03<00:10,  3.51s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:11<00:12,  6.17s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:20<00:07,  7.38s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:27<00:00,  7.09s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:27<00:00,  6.75s/it]
MODE: loss
ADAPTER: /workspace/adapters/qlora_run27
LOSSES: {'A': 2.428990939632058, 'B': 2.605516716837883, 'C': 3.2204685360193253}
FORCED_CHOICE: B (was A )
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = B | mode = loss
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 107, in main
    base = load_bnb_model()
           ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5029, in from_pretrained
    device_map = _get_device_map(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 1365, in _get_device_map
    hf_quantizer.validate_environment(device_map=device_map)
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py", line 127, in validate_environment
    raise ValueError(
ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T01:54:27+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:04<00:12,  4.32s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:06<00:06,  3.27s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:09<00:02,  2.81s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:11<00:00,  2.65s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:11<00:00,  2.88s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run31
LOSSES: {'A': 2.428990939632058, 'B': 2.605516716837883, 'C': 3.2204685360193253}
FORCED_CHOICE: C (was A )
CHOICE: C
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 28 | choice = C | mode = loss
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 107, in main
    base = load_bnb_model()
           ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5029, in from_pretrained
    device_map = _get_device_map(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 1365, in _get_device_map
    hf_quantizer.validate_environment(device_map=device_map)
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py", line 127, in validate_environment
    raise ValueError(
ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T01:55:18+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.77s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:05,  2.70s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:10<00:03,  3.74s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.44s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.27s/it]
MODE: loss
ADAPTER: /workspace/adapters/qlora_run31
LOSSES: {'A': 2.4965546429157257, 'B': 2.363584393635392, 'C': 3.1093932054936886}
FORCED_CHOICE: C (was B )
CHOICE: C
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 32 | choice = C | mode = loss
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:19,  6.49s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:14<00:15,  7.67s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:19<00:06,  6.32s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  4.83s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.56s/it]
Map:   0%|                                                                                                               | 0/18000 [00:00<?, ? examples/s]Map:   2%|█▉                                                                                                 | 351/18000 [00:00<00:05, 3493.05 examples/s]Map:   5%|█████                                                                                              | 915/18000 [00:00<00:06, 2636.95 examples/s]Map:   7%|██████▋                                                                                           | 1233/18000 [00:00<00:08, 1898.83 examples/s]Map:  10%|██████████▏                                                                                       | 1872/18000 [00:00<00:05, 2949.45 examples/s]Map:  13%|████████████▎                                                                                     | 2254/18000 [00:00<00:04, 3164.71 examples/s]Map:  15%|██████████████▊                                                                                   | 2730/18000 [00:00<00:04, 3576.35 examples/s]Map:  18%|█████████████████▍                                                                                | 3203/18000 [00:01<00:06, 2263.57 examples/s]Map:  21%|█████████████████████                                                                             | 3863/18000 [00:01<00:04, 3063.95 examples/s]Map:  24%|███████████████████████▍                                                                          | 4297/18000 [00:01<00:04, 3116.60 examples/s]Map:  27%|██████████████████████████▋                                                                       | 4903/18000 [00:01<00:03, 3385.41 examples/s]Map:  31%|██████████████████████████████▌                                                                   | 5607/18000 [00:01<00:03, 3154.52 examples/s]Map:  33%|████████████████████████████████▊                                                                 | 6018/18000 [00:01<00:03, 3335.45 examples/s]Map:  36%|██████████████████████████████████▉                                                               | 6413/18000 [00:02<00:03, 3463.12 examples/s]Map:  38%|█████████████████████████████████████▎                                                            | 6850/18000 [00:02<00:03, 3673.88 examples/s]Map:  41%|████████████████████████████████████████▌                                                         | 7443/18000 [00:02<00:02, 3759.96 examples/s]Map:  44%|███████████████████████████████████████████                                                       | 7919/18000 [00:02<00:02, 3994.94 examples/s]Map:  48%|██████████████████████████████████████████████▉                                                   | 8610/18000 [00:02<00:02, 3741.74 examples/s]Map:  52%|██████████████████████████████████████████████████▉                                               | 9348/18000 [00:02<00:02, 3092.59 examples/s]Map:  54%|████████████████████████████████████████████████████▉                                             | 9718/18000 [00:03<00:02, 2790.29 examples/s]Map:  57%|██████████████████████████████████████████████████████▉                                          | 10183/18000 [00:03<00:02, 3127.01 examples/s]Map:  59%|█████████████████████████████████████████████████████████▋                                       | 10698/18000 [00:03<00:02, 3210.60 examples/s]Map:  61%|███████████████████████████████████████████████████████████▌                                     | 11051/18000 [00:03<00:02, 3277.13 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▌                                   | 11418/18000 [00:03<00:02, 2495.44 examples/s]Map:  66%|████████████████████████████████████████████████████████████████                                 | 11888/18000 [00:03<00:02, 2927.30 examples/s]Map:  69%|██████████████████████████████████████████████████████████████████▋                              | 12369/18000 [00:04<00:02, 2325.34 examples/s]Map:  72%|██████████████████████████████████████████████████████████████████████                           | 13000/18000 [00:04<00:01, 2999.40 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████▏                        | 13404/18000 [00:04<00:01, 2910.33 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▍                      | 13811/18000 [00:04<00:01, 3149.68 examples/s]Map:  80%|█████████████████████████████████████████████████████████████████████████████▎                   | 14337/18000 [00:04<00:01, 2872.58 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████▏                | 14880/18000 [00:04<00:00, 3236.64 examples/s]Map:  86%|██████████████████████████████████████████████████████████████████████████████████▉              | 15391/18000 [00:04<00:00, 3285.91 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▎           | 15834/18000 [00:05<00:00, 3185.14 examples/s]Map:  91%|████████████████████████████████████████████████████████████████████████████████████████▏        | 16364/18000 [00:05<00:00, 3585.43 examples/s]Map:  93%|██████████████████████████████████████████████████████████████████████████████████████████▍      | 16786/18000 [00:05<00:00, 3733.10 examples/s]Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████▏   | 17286/18000 [00:05<00:00, 3596.65 examples/s]Map:  99%|███████████████████████████████████████████████████████████████████████████████████████████████▌ | 17737/18000 [00:05<00:00, 3126.90 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 18000/18000 [00:05<00:00, 3084.90 examples/s]
TRAIN: cycle32  choice=C  data=/workspace/clean_data_norm/latest/C/philosophy.txt  prev=/workspace/adapters/qlora_run31  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]LOSSES: {'A': 2.4965546429157257, 'B': 2.363584393635392, 'C': 3.1093932054936886}
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 32 | choice = B | mode = loss
  0%|▌                                                                                                                    | 1/200 [00:04<16:02,  4.84s/it]  1%|█▏                                                                                                                   | 2/200 [00:08<13:12,  4.00s/it]Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.83s/it]  2%|█▊                                                                                                                   | 3/200 [00:11<12:42,  3.87s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.04s/it]  2%|██▎                                                                                                                  | 4/200 [00:15<12:15,  3.75s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.10s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.89s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.94s/it]
Map:   0%|                                                                                                               | 0/28107 [00:00<?, ? examples/s]  2%|██▉                                                                                                                  | 5/200 [00:18<11:43,  3.61s/it]Map:   3%|██▌                                                                                                | 733/28107 [00:00<00:03, 7293.06 examples/s]Map:   7%|██████▍                                                                                           | 1831/28107 [00:00<00:03, 7306.63 examples/s]Map:  11%|██████████▎                                                                                       | 2967/28107 [00:00<00:03, 7430.84 examples/s]Map:  13%|█████████████                                                                                     | 3755/28107 [00:00<00:03, 7568.34 examples/s]Map:  16%|███████████████▉                                                                                  | 4555/28107 [00:00<00:03, 7700.14 examples/s]Map:  19%|██████████████████▋                                                                               | 5363/28107 [00:00<00:02, 7811.89 examples/s]Map:  23%|██████████████████████▊                                                                           | 6525/28107 [00:00<00:02, 7780.25 examples/s]Map:  27%|██████████████████████████                                                                        | 7473/28107 [00:00<00:02, 8097.57 examples/s]Map:  31%|██████████████████████████████▎                                                                   | 8711/28107 [00:01<00:02, 8150.74 examples/s]Map:  35%|██████████████████████████████████▏                                                               | 9794/28107 [00:01<00:02, 7799.92 examples/s]Map:  39%|█████████████████████████████████████▊                                                           | 10965/28107 [00:01<00:02, 7797.00 examples/s]Map:  43%|█████████████████████████████████████████▍                                                       | 12000/28107 [00:01<00:02, 7405.25 examples/s]Map:  46%|████████████████████████████████████████████▊                                                    | 12983/28107 [00:01<00:01, 7962.65 examples/s]Map:  50%|████████████████████████████████████████████████▏                                                | 13960/28107 [00:01<00:01, 8409.22 examples/s]Map:  54%|████████████████████████████████████████████████████▍                                            | 15211/28107 [00:01<00:01, 8382.32 examples/s]Map:  58%|████████████████████████████████████████████████████████                                         | 16260/28107 [00:02<00:01, 7920.02 examples/s]Map:  62%|███████████████████████████████████████████████████████████▉                                     | 17381/28107 [00:02<00:01, 7746.67 examples/s]Map:  65%|██████████████████████████████████████████████████████████████▉                                  | 18249/28107 [00:02<00:01, 7963.44 examples/s]Map:  68%|██████████████████████████████████████████████████████████████████▎                              | 19210/28107 [00:02<00:01, 8374.31 examples/s]Map:  73%|██████████████████████████████████████████████████████████████████████▊                          | 20513/28107 [00:02<00:00, 8478.16 examples/s]Map:  76%|█████████████████████████████████████████████████████████████████████████▉                       | 21416/28107 [00:02<00:00, 8568.47 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▏                  | 22669/28107 [00:02<00:00, 8487.70 examples/s]Map:  85%|██████████████████████████████████████████████████████████████████████████████████▊              | 24000/28107 [00:02<00:00, 8519.38 examples/s]Map:  89%|██████████████████████████████████████████████████████████████████████████████████████▎          | 25014/28107 [00:03<00:00, 8903.90 examples/s]Map:  93%|██████████████████████████████████████████████████████████████████████████████████████████▌      | 26241/28107 [00:03<00:00, 8657.16 examples/s]Map:  97%|█████████████████████████████████████████████████████████████████████████████████████████████▉   | 27235/28107 [00:03<00:00, 8967.83 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:03<00:00, 8204.24 examples/s]
TRAIN: cycle32  choice=B  data=/workspace/clean_data_norm/latest/B/dialog.txt  prev=/workspace/adapters/qlora_run31  exclude=2000
  3%|███▌                                                                                                                 | 6/200 [00:22<11:29,  3.55s/it]  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py", line 555, in forward
    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=quant_state).to(inp_dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 401, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 315, in forward
    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 188.88 MiB is free. Process 26771 has 8.74 GiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.10 GiB is allocated by PyTorch, and 295.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T06:11:28+00:00] ERROR rc=1 consec_fails=1
  4%|████                                                                                                                 | 7/200 [00:26<11:43,  3.64s/it]  4%|████▋                                                                                                                | 8/200 [00:29<11:27,  3.58s/it]  4%|█████▎                                                                                                               | 9/200 [00:33<11:17,  3.55s/it]  5%|█████▊                                                                                                              | 10/200 [00:36<11:06,  3.51s/it]  6%|██████▍                                                                                                             | 11/200 [00:39<10:52,  3.45s/it]  6%|██████▉                                                                                                             | 12/200 [00:43<10:39,  3.40s/it]  6%|███████▌                                                                                                            | 13/200 [00:46<10:43,  3.44s/it]  7%|████████                                                                                                            | 14/200 [00:49<10:34,  3.41s/it]  8%|████████▋                                                                                                           | 15/200 [00:53<10:27,  3.39s/it][2025-12-27T06:11:58+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12364
  8%|█████████▎                                                                                                          | 16/200 [00:56<10:20,  3.37s/it]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:00<00:02,  1.12it/s]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:02<00:02,  1.24s/it]  8%|█████████▊                                                                                                          | 17/200 [01:00<11:01,  3.61s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:03<00:01,  1.23s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.17s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.17s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
  9%|██████████▍                                                                                                         | 18/200 [01:04<10:55,  3.60s/it]MODE: random
ADAPTER: /workspace/adapters/qlora_run36
 10%|███████████                                                                                                         | 19/200 [01:08<11:00,  3.65s/it] 10%|███████████▌                                                                                                        | 20/200 [01:11<10:54,  3.64s/it]                                                                                                                                                          {'loss': 1.5127, 'grad_norm': 3.5435538291931152, 'learning_rate': 0.000181, 'epoch': 0.01}
 10%|███████████▌                                                                                                        | 20/200 [01:11<10:54,  3.64s/it] 10%|████████████▏                                                                                                       | 21/200 [01:15<10:48,  3.62s/it] 11%|████████████▊                                                                                                       | 22/200 [01:19<10:53,  3.67s/it] 12%|█████████████▎                                                                                                      | 23/200 [01:23<11:20,  3.84s/it] 12%|█████████████▉                                                                                                      | 24/200 [01:27<11:34,  3.95s/it] 12%|██████████████▌                                                                                                     | 25/200 [01:31<11:28,  3.94s/it] 13%|███████████████                                                                                                     | 26/200 [01:35<11:32,  3.98s/it] 14%|███████████████▋                                                                                                    | 27/200 [01:39<11:19,  3.93s/it] 14%|████████████████▏                                                                                                   | 28/200 [01:43<11:23,  3.97s/it] 14%|████████████████▊                                                                                                   | 29/200 [01:47<11:16,  3.96s/it] 15%|█████████████████▍                                                                                                  | 30/200 [01:51<11:14,  3.97s/it] 16%|█████████████████▉                                                                                                  | 31/200 [01:55<11:25,  4.06s/it] 16%|██████████████████▌                                                                                                 | 32/200 [01:59<11:19,  4.05s/it] 16%|███████████████████▏                                                                                                | 33/200 [02:03<10:53,  3.92s/it] 17%|███████████████████▋                                                                                                | 34/200 [02:07<10:46,  3.89s/it] 18%|████████████████████▎                                                                                               | 35/200 [02:10<10:35,  3.85s/it] 18%|████████████████████▉                                                                                               | 36/200 [02:14<10:39,  3.90s/it] 18%|█████████████████████▍                                                                                              | 37/200 [02:18<10:34,  3.89s/it] 19%|██████████████████████                                                                                              | 38/200 [02:22<10:15,  3.80s/it] 20%|██████████████████████▌                                                                                             | 39/200 [02:26<10:18,  3.84s/it] 20%|███████████████████████▏                                                                                            | 40/200 [02:31<11:14,  4.22s/it]                                                                                                                                                          {'loss': 1.6209, 'grad_norm': 2.4544920921325684, 'learning_rate': 0.000161, 'epoch': 0.02}
 20%|███████████████████████▏                                                                                            | 40/200 [02:31<11:14,  4.22s/it] 20%|███████████████████████▊                                                                                            | 41/200 [02:35<11:22,  4.29s/it] 21%|████████████████████████▎                                                                                           | 42/200 [02:40<11:19,  4.30s/it] 22%|████████████████████████▉                                                                                           | 43/200 [02:44<11:21,  4.34s/it] 22%|█████████████████████████▌                                                                                          | 44/200 [02:48<10:59,  4.23s/it] 22%|██████████████████████████                                                                                          | 45/200 [02:52<10:49,  4.19s/it] 23%|██████████████████████████▋                                                                                         | 46/200 [02:56<10:30,  4.09s/it] 24%|███████████████████████████▎                                                                                        | 47/200 [03:00<10:08,  3.98s/it] 24%|███████████████████████████▊                                                                                        | 48/200 [03:03<09:47,  3.86s/it] 24%|████████████████████████████▍                                                                                       | 49/200 [03:07<09:41,  3.85s/it] 25%|█████████████████████████████                                                                                       | 50/200 [03:11<09:45,  3.90s/it] 26%|█████████████████████████████▌                                                                                      | 51/200 [03:15<09:27,  3.81s/it] 26%|██████████████████████████████▏                                                                                     | 52/200 [03:20<10:15,  4.16s/it] 26%|██████████████████████████████▋                                                                                     | 53/200 [03:23<09:49,  4.01s/it] 27%|███████████████████████████████▎                                                                                    | 54/200 [03:27<09:20,  3.84s/it] 28%|███████████████████████████████▉                                                                                    | 55/200 [03:31<09:10,  3.80s/it] 28%|████████████████████████████████▍                                                                                   | 56/200 [03:34<09:12,  3.84s/it] 28%|█████████████████████████████████                                                                                   | 57/200 [03:38<09:10,  3.85s/it] 29%|█████████████████████████████████▋                                                                                  | 58/200 [03:42<08:59,  3.80s/it] 30%|██████████████████████████████████▏                                                                                 | 59/200 [03:47<09:40,  4.12s/it] 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:51<09:41,  4.16s/it]                                                                                                                                                          {'loss': 1.7703, 'grad_norm': 1.8983073234558105, 'learning_rate': 0.000141, 'epoch': 0.03}
 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:51<09:41,  4.16s/it] 30%|███████████████████████████████████▍                                                                                | 61/200 [03:55<09:29,  4.09s/it] 31%|███████████████████████████████████▉                                                                                | 62/200 [03:59<09:03,  3.94s/it] 32%|████████████████████████████████████▌                                                                               | 63/200 [04:03<09:02,  3.96s/it] 32%|█████████████████████████████████████                                                                               | 64/200 [04:07<08:55,  3.94s/it] 32%|█████████████████████████████████████▋                                                                              | 65/200 [04:10<08:41,  3.86s/it] 33%|██████████████████████████████████████▎                                                                             | 66/200 [04:14<08:43,  3.90s/it] 34%|██████████████████████████████████████▊                                                                             | 67/200 [04:18<08:37,  3.89s/it] 34%|███████████████████████████████████████▍                                                                            | 68/200 [04:24<09:41,  4.41s/it] 34%|████████████████████████████████████████                                                                            | 69/200 [04:28<09:46,  4.48s/it] 35%|████████████████████████████████████████▌                                                                           | 70/200 [04:32<09:19,  4.30s/it] 36%|█████████████████████████████████████████▏                                                                          | 71/200 [04:36<09:07,  4.24s/it] 36%|█████████████████████████████████████████▊                                                                          | 72/200 [04:40<08:47,  4.12s/it] 36%|██████████████████████████████████████████▎                                                                         | 73/200 [04:44<08:45,  4.13s/it] 37%|██████████████████████████████████████████▉                                                                         | 74/200 [04:49<08:59,  4.28s/it] 38%|███████████████████████████████████████████▌                                                                        | 75/200 [04:53<08:48,  4.22s/it] 38%|████████████████████████████████████████████                                                                        | 76/200 [04:57<08:32,  4.13s/it] 38%|████████████████████████████████████████████▋                                                                       | 77/200 [05:01<08:18,  4.05s/it] 39%|█████████████████████████████████████████████▏                                                                      | 78/200 [05:04<07:57,  3.91s/it] 40%|█████████████████████████████████████████████▊                                                                      | 79/200 [05:09<08:06,  4.02s/it] 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [05:13<08:04,  4.04s/it]                                                                                                                                                          {'loss': 1.76, 'grad_norm': 2.784942150115967, 'learning_rate': 0.000121, 'epoch': 0.04}
 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [05:13<08:04,  4.04s/it] 40%|██████████████████████████████████████████████▉                                                                     | 81/200 [05:17<08:01,  4.05s/it] 41%|███████████████████████████████████████████████▌                                                                    | 82/200 [05:21<07:57,  4.05s/it] 42%|████████████████████████████████████████████████▏                                                                   | 83/200 [05:25<07:46,  3.99s/it] 42%|████████████████████████████████████████████████▋                                                                   | 84/200 [05:29<07:38,  3.95s/it] 42%|█████████████████████████████████████████████████▎                                                                  | 85/200 [05:33<07:32,  3.94s/it] 43%|█████████████████████████████████████████████████▉                                                                  | 86/200 [05:37<07:31,  3.96s/it] 44%|██████████████████████████████████████████████████▍                                                                 | 87/200 [05:41<07:39,  4.07s/it] 44%|███████████████████████████████████████████████████                                                                 | 88/200 [05:45<07:30,  4.02s/it] 44%|███████████████████████████████████████████████████▌                                                                | 89/200 [05:48<07:01,  3.79s/it] 45%|████████████████████████████████████████████████████▏                                                               | 90/200 [05:52<06:57,  3.80s/it] 46%|████████████████████████████████████████████████████▊                                                               | 91/200 [05:56<07:00,  3.86s/it] 46%|█████████████████████████████████████████████████████▎                                                              | 92/200 [06:00<06:54,  3.83s/it] 46%|█████████████████████████████████████████████████████▉                                                              | 93/200 [06:04<07:09,  4.01s/it] 47%|██████████████████████████████████████████████████████▌                                                             | 94/200 [06:08<07:01,  3.98s/it] 48%|███████████████████████████████████████████████████████                                                             | 95/200 [06:12<07:01,  4.02s/it] 48%|███████████████████████████████████████████████████████▋                                                            | 96/200 [06:16<06:48,  3.93s/it] 48%|████████████████████████████████████████████████████████▎                                                           | 97/200 [06:20<06:52,  4.01s/it] 49%|████████████████████████████████████████████████████████▊                                                           | 98/200 [06:24<06:54,  4.06s/it] 50%|█████████████████████████████████████████████████████████▍                                                          | 99/200 [06:28<06:37,  3.93s/it] 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [06:32<06:46,  4.06s/it]                                                                                                                                                          {'loss': 2.0186, 'grad_norm': 1.7915246486663818, 'learning_rate': 0.000101, 'epoch': 0.04}
 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [06:32<06:46,  4.06s/it] 50%|██████████████████████████████████████████████████████████                                                         | 101/200 [06:36<06:39,  4.04s/it] 51%|██████████████████████████████████████████████████████████▋                                                        | 102/200 [06:40<06:21,  3.89s/it] 52%|███████████████████████████████████████████████████████████▏                                                       | 103/200 [06:44<06:17,  3.89s/it] 52%|███████████████████████████████████████████████████████████▊                                                       | 104/200 [06:48<06:14,  3.90s/it] 52%|████████████████████████████████████████████████████████████▍                                                      | 105/200 [06:51<06:07,  3.87s/it] 53%|████████████████████████████████████████████████████████████▉                                                      | 106/200 [06:55<06:09,  3.93s/it] 54%|█████████████████████████████████████████████████████████████▌                                                     | 107/200 [07:00<06:17,  4.06s/it] 54%|██████████████████████████████████████████████████████████████                                                     | 108/200 [07:04<06:07,  3.99s/it] 55%|██████████████████████████████████████████████████████████████▋                                                    | 109/200 [07:08<06:03,  4.00s/it] 55%|███████████████████████████████████████████████████████████████▎                                                   | 110/200 [07:11<05:55,  3.95s/it] 56%|███████████████████████████████████████████████████████████████▊                                                   | 111/200 [07:15<05:39,  3.81s/it] 56%|████████████████████████████████████████████████████████████████▍                                                  | 112/200 [07:18<05:28,  3.73s/it] 56%|████████████████████████████████████████████████████████████████▉                                                  | 113/200 [07:22<05:26,  3.75s/it] 57%|█████████████████████████████████████████████████████████████████▌                                                 | 114/200 [07:26<05:10,  3.62s/it] 57%|██████████████████████████████████████████████████████████████████▏                                                | 115/200 [07:29<05:04,  3.59s/it] 58%|██████████████████████████████████████████████████████████████████▋                                                | 116/200 [07:33<05:11,  3.70s/it] 58%|███████████████████████████████████████████████████████████████████▎                                               | 117/200 [07:37<05:02,  3.65s/it] 59%|███████████████████████████████████████████████████████████████████▊                                               | 118/200 [07:40<04:55,  3.60s/it] 60%|████████████████████████████████████████████████████████████████████▍                                              | 119/200 [07:44<05:04,  3.76s/it] 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:48<05:04,  3.81s/it]                                                                                                                                                          {'loss': 2.0913, 'grad_norm': 2.0455400943756104, 'learning_rate': 8.1e-05, 'epoch': 0.05}
 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:48<05:04,  3.81s/it] 60%|█████████████████████████████████████████████████████████████████████▌                                             | 121/200 [07:52<05:04,  3.85s/it] 61%|██████████████████████████████████████████████████████████████████████▏                                            | 122/200 [07:56<04:57,  3.82s/it] 62%|██████████████████████████████████████████████████████████████████████▋                                            | 123/200 [08:00<04:59,  3.89s/it] 62%|███████████████████████████████████████████████████████████████████████▎                                           | 124/200 [08:04<05:05,  4.01s/it] 62%|███████████████████████████████████████████████████████████████████████▉                                           | 125/200 [08:08<04:58,  3.98s/it] 63%|████████████████████████████████████████████████████████████████████████▍                                          | 126/200 [08:12<04:45,  3.86s/it] 64%|█████████████████████████████████████████████████████████████████████████                                          | 127/200 [08:15<04:32,  3.73s/it] 64%|█████████████████████████████████████████████████████████████████████████▌                                         | 128/200 [08:19<04:23,  3.66s/it] 64%|██████████████████████████████████████████████████████████████████████████▏                                        | 129/200 [08:22<04:18,  3.64s/it] 65%|██████████████████████████████████████████████████████████████████████████▊                                        | 130/200 [08:26<04:10,  3.57s/it] 66%|███████████████████████████████████████████████████████████████████████████▎                                       | 131/200 [08:29<04:10,  3.63s/it] 66%|███████████████████████████████████████████████████████████████████████████▉                                       | 132/200 [08:33<04:07,  3.64s/it] 66%|████████████████████████████████████████████████████████████████████████████▍                                      | 133/200 [08:36<04:00,  3.59s/it] 67%|█████████████████████████████████████████████████████████████████████████████                                      | 134/200 [08:40<03:59,  3.63s/it] 68%|█████████████████████████████████████████████████████████████████████████████▋                                     | 135/200 [08:44<03:53,  3.59s/it] 68%|██████████████████████████████████████████████████████████████████████████████▏                                    | 136/200 [08:47<03:50,  3.61s/it] 68%|██████████████████████████████████████████████████████████████████████████████▊                                    | 137/200 [08:51<03:47,  3.60s/it] 69%|███████████████████████████████████████████████████████████████████████████████▎                                   | 138/200 [08:55<03:42,  3.59s/it] 70%|███████████████████████████████████████████████████████████████████████████████▉                                   | 139/200 [08:58<03:39,  3.59s/it] 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [09:02<03:38,  3.64s/it]                                                                                                                                                          {'loss': 2.0988, 'grad_norm': 1.8540669679641724, 'learning_rate': 6.1e-05, 'epoch': 0.06}
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [09:02<03:38,  3.64s/it] 70%|█████████████████████████████████████████████████████████████████████████████████                                  | 141/200 [09:05<03:34,  3.63s/it] 71%|█████████████████████████████████████████████████████████████████████████████████▋                                 | 142/200 [09:09<03:32,  3.66s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▏                                | 143/200 [09:13<03:29,  3.67s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▊                                | 144/200 [09:17<03:27,  3.70s/it] 72%|███████████████████████████████████████████████████████████████████████████████████▍                               | 145/200 [09:21<03:26,  3.75s/it] 73%|███████████████████████████████████████████████████████████████████████████████████▉                               | 146/200 [09:24<03:19,  3.69s/it] 74%|████████████████████████████████████████████████████████████████████████████████████▌                              | 147/200 [09:28<03:17,  3.73s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████                              | 148/200 [09:32<03:13,  3.72s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████▋                             | 149/200 [09:35<03:06,  3.66s/it] 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 150/200 [09:39<03:01,  3.62s/it] 76%|██████████████████████████████████████████████████████████████████████████████████████▊                            | 151/200 [09:42<02:55,  3.59s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▍                           | 152/200 [09:46<02:54,  3.64s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▉                           | 153/200 [09:50<02:50,  3.64s/it] 77%|████████████████████████████████████████████████████████████████████████████████████████▌                          | 154/200 [09:53<02:42,  3.54s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▏                         | 155/200 [09:56<02:38,  3.53s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▋                         | 156/200 [10:00<02:34,  3.52s/it] 78%|██████████████████████████████████████████████████████████████████████████████████████████▎                        | 157/200 [10:03<02:31,  3.51s/it] 79%|██████████████████████████████████████████████████████████████████████████████████████████▊                        | 158/200 [10:07<02:28,  3.54s/it] 80%|███████████████████████████████████████████████████████████████████████████████████████████▍                       | 159/200 [10:10<02:23,  3.50s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [10:14<02:17,  3.44s/it]                                                                                                                                                          {'loss': 2.1426, 'grad_norm': 2.9231059551239014, 'learning_rate': 4.1e-05, 'epoch': 0.07}
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [10:14<02:17,  3.44s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████▌                      | 161/200 [10:17<02:15,  3.48s/it] 81%|█████████████████████████████████████████████████████████████████████████████████████████████▏                     | 162/200 [10:21<02:15,  3.56s/it] 82%|█████████████████████████████████████████████████████████████████████████████████████████████▋                     | 163/200 [10:24<02:07,  3.45s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▎                    | 164/200 [10:28<02:05,  3.50s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▉                    | 165/200 [10:31<02:01,  3.46s/it] 83%|███████████████████████████████████████████████████████████████████████████████████████████████▍                   | 166/200 [10:35<01:57,  3.45s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████                   | 167/200 [10:38<01:56,  3.52s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 168/200 [10:42<01:53,  3.54s/it] 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 169/200 [10:45<01:48,  3.49s/it] 85%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 170/200 [10:49<01:46,  3.53s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                | 171/200 [10:52<01:42,  3.52s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                | 172/200 [10:56<01:37,  3.47s/it] 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 173/200 [10:59<01:33,  3.47s/it] 87%|████████████████████████████████████████████████████████████████████████████████████████████████████               | 174/200 [11:03<01:30,  3.49s/it] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 175/200 [11:06<01:28,  3.52s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 176/200 [11:10<01:25,  3.56s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 177/200 [11:13<01:20,  3.50s/it] 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 178/200 [11:17<01:18,  3.57s/it] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 179/200 [11:20<01:13,  3.49s/it] 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [11:24<01:11,  3.55s/it]                                                                                                                                                          {'loss': 2.2623, 'grad_norm': 1.5097335577011108, 'learning_rate': 2.1e-05, 'epoch': 0.08}
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [11:24<01:11,  3.55s/it] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████           | 181/200 [11:28<01:10,  3.72s/it] 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 182/200 [11:32<01:06,  3.69s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 183/200 [11:35<01:02,  3.66s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 184/200 [11:39<00:57,  3.58s/it] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 185/200 [11:42<00:53,  3.59s/it] 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 186/200 [11:46<00:49,  3.56s/it] 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 187/200 [11:49<00:45,  3.51s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 188/200 [11:53<00:41,  3.45s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 189/200 [11:56<00:37,  3.38s/it] 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 190/200 [11:59<00:34,  3.40s/it] 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 191/200 [12:03<00:32,  3.60s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 192/200 [12:07<00:28,  3.52s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 193/200 [12:10<00:24,  3.50s/it] 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 194/200 [12:14<00:21,  3.58s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 195/200 [12:17<00:17,  3.56s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 196/200 [12:21<00:14,  3.73s/it] 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 197/200 [12:25<00:11,  3.70s/it] 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 198/200 [12:29<00:07,  3.66s/it]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 199/200 [12:33<00:03,  3.71s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:36<00:00,  3.65s/it]                                                                                                                                                          {'loss': 2.3781, 'grad_norm': 2.1315088272094727, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:36<00:00,  3.65s/it]                                                                                                                                                          {'train_runtime': 757.4619, 'train_samples_per_second': 2.112, 'train_steps_per_second': 0.264, 'train_loss': 1.9655565738677978, 'epoch': 0.09}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:37<00:00,  3.65s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:37<00:00,  3.79s/it]
saved: /workspace/adapters/qlora_run32
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:06,  2.02s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.30s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.45s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.38s/it]
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 151, in main
    base2 = load_bnb_model()
            ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 748, in _load_state_dict_into_meta_model
    param = param[...]
            ~~~~~^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 936.88 MiB is free. Including non-PyTorch memory, this process has 9.85 GiB memory in use. Process 26893 has 4.70 GiB memory in use. Of the allocated memory 9.38 GiB is allocated by PyTorch, and 319.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T06:23:51+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE= RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.66s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:05,  2.57s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.27s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  1.97s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.15s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run36
LOSSES: {'A': 2.587486110627651, 'B': 2.462151175364852, 'C': 3.248752538114786}
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 37 | choice = B | mode = random
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.39s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:05,  2.69s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:09<00:03,  3.60s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.91s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.59s/it]
Map:   0%|                                                                                                               | 0/28107 [00:00<?, ? examples/s]Map:   2%|█▌                                                                                                 | 434/28107 [00:00<00:07, 3911.62 examples/s]Map:   3%|███                                                                                                | 866/28107 [00:00<00:06, 4136.49 examples/s]Map:   5%|████▌                                                                                             | 1315/28107 [00:00<00:06, 4291.83 examples/s]Map:   7%|██████▋                                                                                           | 1902/28107 [00:00<00:05, 4895.82 examples/s]Map:   9%|████████▌                                                                                         | 2459/28107 [00:00<00:05, 4354.65 examples/s]Map:  10%|██████████▏                                                                                       | 2938/28107 [00:00<00:05, 4484.89 examples/s]Map:  13%|████████████▎                                                                                     | 3516/28107 [00:00<00:05, 4232.64 examples/s]Map:  14%|██████████████                                                                                    | 4019/28107 [00:00<00:05, 4447.53 examples/s]Map:  16%|████████████████▏                                                                                 | 4633/28107 [00:01<00:05, 4308.43 examples/s]Map:  19%|██████████████████▊                                                                               | 5408/28107 [00:01<00:04, 4581.55 examples/s]Map:  21%|████████████████████▊                                                                             | 5963/28107 [00:01<00:04, 4818.17 examples/s]Map:  23%|██████████████████████▌                                                                           | 6469/28107 [00:01<00:05, 4308.31 examples/s]Map:  26%|█████████████████████████                                                                         | 7179/28107 [00:01<00:04, 4995.07 examples/s]Map:  28%|███████████████████████████▌                                                                      | 7917/28107 [00:01<00:03, 5611.59 examples/s]Map:  31%|██████████████████████████████▍                                                                   | 8713/28107 [00:01<00:03, 5501.83 examples/s]Map:  33%|████████████████████████████████▌                                                                 | 9351/28107 [00:01<00:03, 5076.63 examples/s]Map:  36%|██████████████████████████████████▌                                                              | 10000/28107 [00:02<00:03, 5326.32 examples/s]Map:  39%|█████████████████████████████████████▋                                                           | 10924/28107 [00:02<00:03, 5605.93 examples/s]Map:  41%|████████████████████████████████████████▏                                                        | 11628/28107 [00:02<00:03, 5304.22 examples/s]Map:  44%|██████████████████████████████████████████▉                                                      | 12429/28107 [00:02<00:02, 5463.71 examples/s]Map:  46%|████████████████████████████████████████████▊                                                    | 13003/28107 [00:02<00:02, 5526.93 examples/s]Map:  49%|███████████████████████████████████████████████▌                                                 | 13787/28107 [00:02<00:02, 6108.11 examples/s]Map:  52%|██████████████████████████████████████████████████▏                                              | 14543/28107 [00:02<00:02, 5721.79 examples/s]Map:  54%|████████████████████████████████████████████████████▊                                            | 15285/28107 [00:02<00:02, 6144.22 examples/s]Map:  57%|███████████████████████████████████████████████████████▏                                         | 16000/28107 [00:03<00:02, 5551.27 examples/s]Map:  59%|█████████████████████████████████████████████████████████▍                                       | 16630/28107 [00:03<00:02, 5731.95 examples/s]Map:  61%|███████████████████████████████████████████████████████████▍                                     | 17227/28107 [00:03<00:02, 5126.05 examples/s]Map:  64%|█████████████████████████████████████████████████████████████▌                                   | 17852/28107 [00:03<00:01, 5402.34 examples/s]Map:  66%|████████████████████████████████████████████████████████████████▍                                | 18656/28107 [00:03<00:01, 5384.56 examples/s]Map:  69%|██████████████████████████████████████████████████████████████████▊                              | 19372/28107 [00:03<00:01, 5179.37 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▏                           | 20039/28107 [00:03<00:01, 5533.61 examples/s]Map:  75%|████████████████████████████████████████████████████████████████████████▌                        | 21011/28107 [00:04<00:01, 5850.79 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▋                      | 21652/28107 [00:04<00:01, 5333.04 examples/s]Map:  80%|█████████████████████████████████████████████████████████████████████████████▏                   | 22373/28107 [00:04<00:00, 5776.62 examples/s]Map:  83%|████████████████████████████████████████████████████████████████████████████████▏                | 23219/28107 [00:04<00:00, 5727.81 examples/s]Map:  85%|██████████████████████████████████████████████████████████████████████████████████▌              | 23928/28107 [00:04<00:00, 6056.28 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████            | 24650/28107 [00:04<00:00, 5824.11 examples/s]Map:  91%|████████████████████████████████████████████████████████████████████████████████████████         | 25524/28107 [00:04<00:00, 5819.88 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████      | 26381/28107 [00:04<00:00, 5731.61 examples/s]Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████▏   | 27000/28107 [00:05<00:00, 5773.23 examples/s]Map:  99%|███████████████████████████████████████████████████████████████████████████████████████████████▉ | 27784/28107 [00:05<00:00, 6285.86 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:05<00:00, 5338.90 examples/s]
TRAIN: cycle37  choice=B  data=/workspace/clean_data_norm/latest/B/dialog.txt  prev=/workspace/adapters/qlora_run36  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 234, in forward
    hidden_states, _ = self.self_attn(
                       ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 158, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 79, in apply_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
                           ~~~~~~~~~~~~~~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 896.00 KiB is free. Process 26957 has 8.60 GiB memory in use. Including non-PyTorch memory, this process has 6.86 GiB memory in use. Of the allocated memory 6.20 GiB is allocated by PyTorch, and 517.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T07:25:02+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.55s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.34s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.18s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  1.83s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.01s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run36
LOSSES: {'A': 2.587486110627651, 'B': 2.462151175364852, 'C': 3.248752538114786}
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 37 | choice = B | mode = loss
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:06<00:18,  6.29s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:10<00:09,  4.94s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:14<00:04,  4.74s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:19<00:00,  4.71s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:19<00:00,  4.86s/it]
Map:   0%|                                                                                                               | 0/28107 [00:00<?, ? examples/s]Map:   0%|▏                                                                                                    | 58/28107 [00:00<00:54, 512.84 examples/s]Map:   1%|▌                                                                                                   | 156/28107 [00:00<00:36, 772.38 examples/s]Map:   3%|██▋                                                                                                | 747/28107 [00:00<00:08, 3045.48 examples/s]Map:   5%|████▊                                                                                             | 1381/28107 [00:00<00:06, 4143.37 examples/s]Map:   7%|██████▌                                                                                           | 1889/28107 [00:00<00:06, 3798.72 examples/s]Map:   9%|████████▍                                                                                         | 2408/28107 [00:00<00:06, 4208.75 examples/s]Map:  10%|██████████                                                                                        | 2898/28107 [00:00<00:05, 4410.79 examples/s]Map:  12%|███████████▊                                                                                      | 3377/28107 [00:00<00:05, 4392.70 examples/s]Map:  14%|█████████████▉                                                                                    | 4000/28107 [00:00<00:04, 4881.98 examples/s]Map:  16%|███████████████▊                                                                                  | 4545/28107 [00:01<00:06, 3707.05 examples/s]Map:  18%|█████████████████▍                                                                                | 5000/28107 [00:01<00:10, 2225.14 examples/s]Map:  20%|███████████████████▏                                                                              | 5514/28107 [00:01<00:08, 2691.14 examples/s]Map:  22%|█████████████████████▌                                                                            | 6180/28107 [00:01<00:06, 3264.48 examples/s]Map:  24%|███████████████████████▍                                                                          | 6734/28107 [00:02<00:06, 3095.74 examples/s]Map:  27%|██████████████████████████                                                                        | 7487/28107 [00:02<00:05, 3953.51 examples/s]Map:  28%|███████████████████████████▉                                                                      | 8000/28107 [00:02<00:04, 4053.36 examples/s]Map:  30%|█████████████████████████████▊                                                                    | 8533/28107 [00:02<00:04, 4345.29 examples/s]Map:  32%|███████████████████████████████▋                                                                  | 9071/28107 [00:02<00:04, 4597.65 examples/s]Map:  34%|█████████████████████████████████▋                                                                | 9657/28107 [00:02<00:05, 3660.40 examples/s]Map:  36%|██████████████████████████████████▉                                                              | 10117/28107 [00:03<00:08, 2186.73 examples/s]Map:  38%|█████████████████████████████████████▏                                                           | 10789/28107 [00:03<00:06, 2861.49 examples/s]Map:  40%|██████████████████████████████████████▊                                                          | 11264/28107 [00:03<00:05, 2933.51 examples/s]Map:  42%|████████████████████████████████████████▋                                                        | 11786/28107 [00:03<00:04, 3361.29 examples/s]Map:  45%|███████████████████████████████████████████▌                                                     | 12611/28107 [00:03<00:03, 4391.22 examples/s]Map:  48%|██████████████████████████████████████████████▎                                                  | 13432/28107 [00:03<00:03, 3824.68 examples/s]Map:  50%|████████████████████████████████████████████████▊                                                | 14158/28107 [00:04<00:03, 4147.11 examples/s]Map:  52%|██████████████████████████████████████████████████▊                                              | 14722/28107 [00:04<00:04, 3217.23 examples/s]Map:  54%|████████████████████████████████████████████████████▋                                            | 15268/28107 [00:04<00:05, 2509.70 examples/s]Map:  57%|██████████████████████████████████████████████████████▉                                          | 15925/28107 [00:04<00:03, 3106.36 examples/s]Map:  58%|████████████████████████████████████████████████████████▌                                        | 16374/28107 [00:04<00:03, 3345.36 examples/s]Map:  60%|██████████████████████████████████████████████████████████▎                                      | 16880/28107 [00:05<00:03, 3350.46 examples/s]Map:  63%|████████████████████████████████████████████████████████████▋                                    | 17571/28107 [00:05<00:02, 4078.22 examples/s]Map:  66%|███████████████████████████████████████████████████████████████▌                                 | 18411/28107 [00:05<00:02, 3425.51 examples/s]Map:  69%|██████████████████████████████████████████████████████████████████▋                              | 19309/28107 [00:05<00:01, 4422.73 examples/s]Map:  71%|████████████████████████████████████████████████████████████████████▌                            | 19880/28107 [00:05<00:01, 4246.26 examples/s]Map:  73%|██████████████████████████████████████████████████████████████████████▍                          | 20406/28107 [00:05<00:02, 3782.67 examples/s]Map:  74%|████████████████████████████████████████████████████████████████████████                         | 20867/28107 [00:05<00:01, 3948.88 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▍                      | 21584/28107 [00:06<00:01, 4670.14 examples/s]Map:  79%|████████████████████████████████████████████████████████████████████████████▍                    | 22133/28107 [00:06<00:01, 4806.56 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▎                 | 22990/28107 [00:06<00:01, 5111.25 examples/s]Map:  84%|█████████████████████████████████████████████████████████████████████████████████▍               | 23584/28107 [00:06<00:01, 3881.16 examples/s]Map:  87%|████████████████████████████████████████████████████████████████████████████████████             | 24351/28107 [00:06<00:00, 4648.37 examples/s]Map:  89%|█████████████████████████████████████████████████████████████████████████████████████▉           | 24903/28107 [00:06<00:00, 4834.89 examples/s]Map:  91%|███████████████████████████████████████████████████████████████████████████████████████▊         | 25460/28107 [00:07<00:00, 2722.06 examples/s]Map:  92%|█████████████████████████████████████████████████████████████████████████████████████████▍       | 25914/28107 [00:07<00:01, 2035.10 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████▏     | 26407/28107 [00:07<00:00, 2418.72 examples/s]Map:  97%|██████████████████████████████████████████████████████████████████████████████████████████████▍  | 27380/28107 [00:07<00:00, 3583.25 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:08<00:00, 3699.46 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:08<00:00, 3511.66 examples/s]
TRAIN: cycle37  choice=B  data=/workspace/clean_data_norm/latest/B/dialog.txt  prev=/workspace/adapters/qlora_run36  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:05<16:55,  5.10s/it]  1%|█▏                                                                                                                   | 2/200 [00:08<14:24,  4.36s/it]  2%|█▊                                                                                                                   | 3/200 [00:12<13:40,  4.17s/it]  2%|██▎                                                                                                                  | 4/200 [00:16<12:55,  3.96s/it]  2%|██▉                                                                                                                  | 5/200 [00:21<14:28,  4.45s/it]  3%|███▌                                                                                                                 | 6/200 [00:25<13:59,  4.33s/it]  4%|████                                                                                                                 | 7/200 [00:29<13:30,  4.20s/it]  4%|████▋                                                                                                                | 8/200 [00:33<13:06,  4.09s/it]  4%|█████▎                                                                                                               | 9/200 [00:37<12:46,  4.02s/it]  5%|█████▊                                                                                                              | 10/200 [00:41<12:26,  3.93s/it]  6%|██████▍                                                                                                             | 11/200 [00:45<12:28,  3.96s/it]  6%|██████▉                                                                                                             | 12/200 [00:49<12:31,  4.00s/it]  6%|███████▌                                                                                                            | 13/200 [00:53<12:22,  3.97s/it]  7%|████████                                                                                                            | 14/200 [00:56<11:48,  3.81s/it]  8%|████████▋                                                                                                           | 15/200 [01:01<12:51,  4.17s/it]  8%|█████████▎                                                                                                          | 16/200 [01:05<12:02,  3.93s/it]  8%|█████████▊                                                                                                          | 17/200 [01:08<11:46,  3.86s/it]  9%|██████████▍                                                                                                         | 18/200 [01:12<11:31,  3.80s/it] 10%|███████████                                                                                                         | 19/200 [01:16<11:11,  3.71s/it] 10%|███████████▌                                                                                                        | 20/200 [01:19<11:04,  3.69s/it]                                                                                                                                                          {'loss': 0.1338, 'grad_norm': 3.091718912124634, 'learning_rate': 0.000181, 'epoch': 0.01}
 10%|███████████▌                                                                                                        | 20/200 [01:19<11:04,  3.69s/it] 10%|████████████▏                                                                                                       | 21/200 [01:23<11:00,  3.69s/it] 11%|████████████▊                                                                                                       | 22/200 [01:27<11:28,  3.87s/it] 12%|█████████████▎                                                                                                      | 23/200 [01:31<11:19,  3.84s/it] 12%|█████████████▉                                                                                                      | 24/200 [01:35<11:11,  3.81s/it] 12%|██████████████▌                                                                                                     | 25/200 [01:39<11:11,  3.84s/it] 13%|███████████████                                                                                                     | 26/200 [01:43<11:14,  3.88s/it] 14%|███████████████▋                                                                                                    | 27/200 [01:46<10:52,  3.77s/it] 14%|████████████████▏                                                                                                   | 28/200 [01:50<10:50,  3.78s/it] 14%|████████████████▊                                                                                                   | 29/200 [01:54<10:57,  3.85s/it] 15%|█████████████████▍                                                                                                  | 30/200 [01:58<10:50,  3.83s/it] 16%|█████████████████▉                                                                                                  | 31/200 [02:02<10:57,  3.89s/it] 16%|██████████████████▌                                                                                                 | 32/200 [02:06<10:52,  3.88s/it] 16%|███████████████████▏                                                                                                | 33/200 [02:09<10:49,  3.89s/it] 17%|███████████████████▋                                                                                                | 34/200 [02:14<11:38,  4.21s/it] 18%|████████████████████▎                                                                                               | 35/200 [02:18<11:07,  4.04s/it] 18%|████████████████████▉                                                                                               | 36/200 [02:22<10:46,  3.94s/it] 18%|█████████████████████▍                                                                                              | 37/200 [02:25<10:19,  3.80s/it] 19%|██████████████████████                                                                                              | 38/200 [02:29<09:53,  3.67s/it] 20%|██████████████████████▌                                                                                             | 39/200 [02:32<09:55,  3.70s/it] 20%|███████████████████████▏                                                                                            | 40/200 [02:36<09:58,  3.74s/it]                                                                                                                                                          {'loss': 0.1354, 'grad_norm': 2.8206169605255127, 'learning_rate': 0.000161, 'epoch': 0.01}
 20%|███████████████████████▏                                                                                            | 40/200 [02:36<09:58,  3.74s/it] 20%|███████████████████████▊                                                                                            | 41/200 [02:40<09:58,  3.77s/it] 21%|████████████████████████▎                                                                                           | 42/200 [02:44<10:18,  3.92s/it] 22%|████████████████████████▉                                                                                           | 43/200 [02:48<10:08,  3.88s/it] 22%|█████████████████████████▌                                                                                          | 44/200 [02:52<10:09,  3.91s/it] 22%|██████████████████████████                                                                                          | 45/200 [02:56<09:52,  3.82s/it] 23%|██████████████████████████▋                                                                                         | 46/200 [03:00<09:57,  3.88s/it] 24%|███████████████████████████▎                                                                                        | 47/200 [03:04<09:52,  3.88s/it] 24%|███████████████████████████▊                                                                                        | 48/200 [03:07<09:40,  3.82s/it] 24%|████████████████████████████▍                                                                                       | 49/200 [03:11<09:27,  3.76s/it] 25%|█████████████████████████████                                                                                       | 50/200 [03:15<09:31,  3.81s/it] 26%|█████████████████████████████▌                                                                                      | 51/200 [03:19<09:45,  3.93s/it] 26%|██████████████████████████████▏                                                                                     | 52/200 [03:23<09:57,  4.04s/it] 26%|██████████████████████████████▋                                                                                     | 53/200 [03:27<09:33,  3.90s/it] 27%|███████████████████████████████▎                                                                                    | 54/200 [03:30<09:16,  3.81s/it] 28%|███████████████████████████████▉                                                                                    | 55/200 [03:34<09:19,  3.86s/it] 28%|████████████████████████████████▍                                                                                   | 56/200 [03:38<09:18,  3.88s/it] 28%|█████████████████████████████████                                                                                   | 57/200 [03:43<09:44,  4.09s/it] 29%|█████████████████████████████████▋                                                                                  | 58/200 [03:48<10:24,  4.40s/it] 30%|██████████████████████████████████▏                                                                                 | 59/200 [03:52<09:47,  4.17s/it] 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:55<09:17,  3.98s/it]                                                                                                                                                          {'loss': 0.1523, 'grad_norm': 2.756152868270874, 'learning_rate': 0.000141, 'epoch': 0.02}
 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:55<09:17,  3.98s/it] 30%|███████████████████████████████████▍                                                                                | 61/200 [03:59<09:11,  3.97s/it] 31%|███████████████████████████████████▉                                                                                | 62/200 [04:03<08:58,  3.91s/it] 32%|████████████████████████████████████▌                                                                               | 63/200 [04:07<09:05,  3.98s/it] 32%|█████████████████████████████████████                                                                               | 64/200 [04:11<08:52,  3.91s/it] 32%|█████████████████████████████████████▋                                                                              | 65/200 [04:15<08:56,  3.97s/it] 33%|██████████████████████████████████████▎                                                                             | 66/200 [04:19<08:42,  3.90s/it] 34%|██████████████████████████████████████▊                                                                             | 67/200 [04:24<09:23,  4.24s/it] 34%|███████████████████████████████████████▍                                                                            | 68/200 [04:27<08:52,  4.03s/it] 34%|████████████████████████████████████████                                                                            | 69/200 [04:31<08:52,  4.06s/it] 35%|████████████████████████████████████████▌                                                                           | 70/200 [04:35<08:36,  3.98s/it] 36%|█████████████████████████████████████████▏                                                                          | 71/200 [04:39<08:30,  3.95s/it] 36%|█████████████████████████████████████████▊                                                                          | 72/200 [04:43<08:25,  3.95s/it] 36%|██████████████████████████████████████████▎                                                                         | 73/200 [04:47<08:18,  3.92s/it] 37%|██████████████████████████████████████████▉                                                                         | 74/200 [04:51<08:03,  3.84s/it] 38%|███████████████████████████████████████████▌                                                                        | 75/200 [04:54<07:43,  3.71s/it] 38%|████████████████████████████████████████████                                                                        | 76/200 [04:58<07:51,  3.81s/it] 38%|████████████████████████████████████████████▋                                                                       | 77/200 [05:02<07:47,  3.80s/it] 39%|█████████████████████████████████████████████▏                                                                      | 78/200 [05:05<07:40,  3.78s/it] 40%|█████████████████████████████████████████████▊                                                                      | 79/200 [05:09<07:44,  3.84s/it] 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [05:14<07:50,  3.92s/it]                                                                                                                                                          {'loss': 0.1858, 'grad_norm': 5.108291149139404, 'learning_rate': 0.000121, 'epoch': 0.02}
 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [05:14<07:50,  3.92s/it] 40%|██████████████████████████████████████████████▉                                                                     | 81/200 [05:19<08:33,  4.31s/it] 41%|███████████████████████████████████████████████▌                                                                    | 82/200 [05:22<07:59,  4.06s/it] 42%|████████████████████████████████████████████████▏                                                                   | 83/200 [05:26<07:43,  3.96s/it] 42%|████████████████████████████████████████████████▋                                                                   | 84/200 [05:30<07:33,  3.91s/it] 42%|█████████████████████████████████████████████████▎                                                                  | 85/200 [05:34<07:32,  3.94s/it] 43%|█████████████████████████████████████████████████▉                                                                  | 86/200 [05:38<07:21,  3.88s/it] 44%|██████████████████████████████████████████████████▍                                                                 | 87/200 [05:41<07:07,  3.78s/it] 44%|███████████████████████████████████████████████████                                                                 | 88/200 [05:45<07:08,  3.83s/it] 44%|███████████████████████████████████████████████████▌                                                                | 89/200 [05:49<06:58,  3.77s/it] 45%|████████████████████████████████████████████████████▏                                                               | 90/200 [05:53<07:02,  3.84s/it] 46%|████████████████████████████████████████████████████▊                                                               | 91/200 [05:56<06:58,  3.84s/it] 46%|█████████████████████████████████████████████████████▎                                                              | 92/200 [06:00<06:40,  3.71s/it] 46%|█████████████████████████████████████████████████████▉                                                              | 93/200 [06:03<06:28,  3.63s/it] 47%|██████████████████████████████████████████████████████▌                                                             | 94/200 [06:07<06:15,  3.54s/it] 48%|███████████████████████████████████████████████████████                                                             | 95/200 [06:10<06:13,  3.56s/it] 48%|███████████████████████████████████████████████████████▋                                                            | 96/200 [06:14<06:01,  3.48s/it] 48%|████████████████████████████████████████████████████████▎                                                           | 97/200 [06:17<05:53,  3.43s/it] 49%|████████████████████████████████████████████████████████▊                                                           | 98/200 [06:20<05:53,  3.47s/it] 50%|█████████████████████████████████████████████████████████▍                                                          | 99/200 [06:24<05:56,  3.53s/it] 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [06:28<05:55,  3.55s/it]                                                                                                                                                          {'loss': 0.2236, 'grad_norm': 3.0107390880584717, 'learning_rate': 0.000101, 'epoch': 0.03}
 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [06:28<05:55,  3.55s/it] 50%|██████████████████████████████████████████████████████████                                                         | 101/200 [06:31<05:42,  3.46s/it] 51%|██████████████████████████████████████████████████████████▋                                                        | 102/200 [06:34<05:31,  3.38s/it] 52%|███████████████████████████████████████████████████████████▏                                                       | 103/200 [06:38<05:30,  3.40s/it] 52%|███████████████████████████████████████████████████████████▊                                                       | 104/200 [06:41<05:29,  3.43s/it] 52%|████████████████████████████████████████████████████████████▍                                                      | 105/200 [06:45<05:31,  3.48s/it] 53%|████████████████████████████████████████████████████████████▉                                                      | 106/200 [06:48<05:25,  3.47s/it] 54%|█████████████████████████████████████████████████████████████▌                                                     | 107/200 [06:52<05:19,  3.44s/it] 54%|██████████████████████████████████████████████████████████████                                                     | 108/200 [06:55<05:19,  3.47s/it] 55%|██████████████████████████████████████████████████████████████▋                                                    | 109/200 [06:58<05:10,  3.41s/it] 55%|███████████████████████████████████████████████████████████████▎                                                   | 110/200 [07:02<05:03,  3.37s/it] 56%|███████████████████████████████████████████████████████████████▊                                                   | 111/200 [07:05<05:01,  3.38s/it] 56%|████████████████████████████████████████████████████████████████▍                                                  | 112/200 [07:09<05:11,  3.54s/it] 56%|████████████████████████████████████████████████████████████████▉                                                  | 113/200 [07:13<05:09,  3.56s/it] 57%|█████████████████████████████████████████████████████████████████▌                                                 | 114/200 [07:16<05:03,  3.52s/it] 57%|██████████████████████████████████████████████████████████████████▏                                                | 115/200 [07:20<05:00,  3.53s/it] 58%|██████████████████████████████████████████████████████████████████▋                                                | 116/200 [07:23<05:03,  3.61s/it] 58%|███████████████████████████████████████████████████████████████████▎                                               | 117/200 [07:27<04:51,  3.52s/it] 59%|███████████████████████████████████████████████████████████████████▊                                               | 118/200 [07:30<04:47,  3.51s/it] 60%|████████████████████████████████████████████████████████████████████▍                                              | 119/200 [07:34<04:41,  3.48s/it] 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:37<04:35,  3.44s/it]                                                                                                                                                          {'loss': 0.3135, 'grad_norm': 4.948784828186035, 'learning_rate': 8.1e-05, 'epoch': 0.03}
 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:37<04:35,  3.44s/it] 60%|█████████████████████████████████████████████████████████████████████▌                                             | 121/200 [07:40<04:29,  3.41s/it] 61%|██████████████████████████████████████████████████████████████████████▏                                            | 122/200 [07:44<04:29,  3.46s/it] 62%|██████████████████████████████████████████████████████████████████████▋                                            | 123/200 [07:47<04:25,  3.45s/it] 62%|███████████████████████████████████████████████████████████████████████▎                                           | 124/200 [07:51<04:21,  3.44s/it] 62%|███████████████████████████████████████████████████████████████████████▉                                           | 125/200 [07:54<04:16,  3.42s/it] 63%|████████████████████████████████████████████████████████████████████████▍                                          | 126/200 [07:58<04:17,  3.48s/it] 64%|█████████████████████████████████████████████████████████████████████████                                          | 127/200 [08:01<04:16,  3.51s/it] 64%|█████████████████████████████████████████████████████████████████████████▌                                         | 128/200 [08:05<04:10,  3.48s/it] 64%|██████████████████████████████████████████████████████████████████████████▏                                        | 129/200 [08:08<04:03,  3.43s/it] 65%|██████████████████████████████████████████████████████████████████████████▊                                        | 130/200 [08:11<03:56,  3.38s/it] 66%|███████████████████████████████████████████████████████████████████████████▎                                       | 131/200 [08:15<03:56,  3.43s/it] 66%|███████████████████████████████████████████████████████████████████████████▉                                       | 132/200 [08:18<03:58,  3.51s/it] 66%|████████████████████████████████████████████████████████████████████████████▍                                      | 133/200 [08:22<03:55,  3.51s/it] 67%|█████████████████████████████████████████████████████████████████████████████                                      | 134/200 [08:25<03:48,  3.46s/it] 68%|█████████████████████████████████████████████████████████████████████████████▋                                     | 135/200 [08:29<03:48,  3.52s/it] 68%|██████████████████████████████████████████████████████████████████████████████▏                                    | 136/200 [08:33<03:45,  3.53s/it] 68%|██████████████████████████████████████████████████████████████████████████████▊                                    | 137/200 [08:36<03:41,  3.52s/it] 69%|███████████████████████████████████████████████████████████████████████████████▎                                   | 138/200 [08:39<03:33,  3.44s/it] 70%|███████████████████████████████████████████████████████████████████████████████▉                                   | 139/200 [08:42<03:24,  3.35s/it] 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [08:46<03:25,  3.43s/it]                                                                                                                                                          {'loss': 0.4019, 'grad_norm': 3.613298177719116, 'learning_rate': 6.1e-05, 'epoch': 0.04}
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [08:46<03:25,  3.43s/it] 70%|█████████████████████████████████████████████████████████████████████████████████                                  | 141/200 [08:49<03:21,  3.42s/it] 71%|█████████████████████████████████████████████████████████████████████████████████▋                                 | 142/200 [08:53<03:16,  3.39s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▏                                | 143/200 [08:56<03:13,  3.39s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▊                                | 144/200 [09:00<03:11,  3.41s/it] 72%|███████████████████████████████████████████████████████████████████████████████████▍                               | 145/200 [09:03<03:06,  3.38s/it] 73%|███████████████████████████████████████████████████████████████████████████████████▉                               | 146/200 [09:07<03:09,  3.51s/it] 74%|████████████████████████████████████████████████████████████████████████████████████▌                              | 147/200 [09:10<03:02,  3.45s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████                              | 148/200 [09:14<03:04,  3.56s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████▋                             | 149/200 [09:17<03:01,  3.57s/it] 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 150/200 [09:21<02:57,  3.54s/it] 76%|██████████████████████████████████████████████████████████████████████████████████████▊                            | 151/200 [09:24<02:50,  3.47s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▍                           | 152/200 [09:27<02:43,  3.41s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▉                           | 153/200 [09:31<02:43,  3.47s/it] 77%|████████████████████████████████████████████████████████████████████████████████████████▌                          | 154/200 [09:34<02:36,  3.40s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▏                         | 155/200 [09:38<02:34,  3.43s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▋                         | 156/200 [09:41<02:27,  3.36s/it] 78%|██████████████████████████████████████████████████████████████████████████████████████████▎                        | 157/200 [09:44<02:25,  3.38s/it] 79%|██████████████████████████████████████████████████████████████████████████████████████████▊                        | 158/200 [09:48<02:20,  3.35s/it] 80%|███████████████████████████████████████████████████████████████████████████████████████████▍                       | 159/200 [09:51<02:18,  3.37s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [09:55<02:18,  3.46s/it]                                                                                                                                                          {'loss': 0.6521, 'grad_norm': 4.186509132385254, 'learning_rate': 4.1e-05, 'epoch': 0.05}
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [09:55<02:18,  3.46s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████▌                      | 161/200 [09:58<02:14,  3.44s/it] 81%|█████████████████████████████████████████████████████████████████████████████████████████████▏                     | 162/200 [10:02<02:11,  3.46s/it] 82%|█████████████████████████████████████████████████████████████████████████████████████████████▋                     | 163/200 [10:05<02:09,  3.50s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▎                    | 164/200 [10:09<02:07,  3.53s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▉                    | 165/200 [10:12<02:00,  3.44s/it] 83%|███████████████████████████████████████████████████████████████████████████████████████████████▍                   | 166/200 [10:15<01:55,  3.39s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████                   | 167/200 [10:19<01:52,  3.42s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 168/200 [10:22<01:48,  3.39s/it] 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 169/200 [10:25<01:43,  3.33s/it] 85%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 170/200 [10:29<01:41,  3.37s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                | 171/200 [10:33<01:39,  3.45s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                | 172/200 [10:36<01:35,  3.42s/it] 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 173/200 [10:39<01:31,  3.40s/it] 87%|████████████████████████████████████████████████████████████████████████████████████████████████████               | 174/200 [10:43<01:30,  3.50s/it] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 175/200 [10:46<01:27,  3.51s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 176/200 [10:50<01:23,  3.46s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 177/200 [10:53<01:18,  3.42s/it] 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 178/200 [10:57<01:19,  3.62s/it] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 179/200 [11:01<01:14,  3.54s/it] 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [11:04<01:09,  3.49s/it]                                                                                                                                                          {'loss': 1.066, 'grad_norm': 6.208493232727051, 'learning_rate': 2.1e-05, 'epoch': 0.05}
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [11:04<01:09,  3.49s/it] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████           | 181/200 [11:08<01:06,  3.51s/it] 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 182/200 [11:11<01:03,  3.53s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 183/200 [11:14<00:59,  3.48s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 184/200 [11:18<00:54,  3.42s/it] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 185/200 [11:21<00:51,  3.42s/it] 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 186/200 [11:25<00:47,  3.41s/it] 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 187/200 [11:28<00:43,  3.38s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 188/200 [11:31<00:40,  3.36s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 189/200 [11:35<00:37,  3.40s/it] 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 190/200 [11:38<00:34,  3.41s/it] 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 191/200 [11:42<00:30,  3.42s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 192/200 [11:45<00:27,  3.39s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 193/200 [11:48<00:23,  3.34s/it] 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 194/200 [11:51<00:20,  3.35s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 195/200 [11:55<00:16,  3.40s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 196/200 [11:58<00:13,  3.36s/it] 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 197/200 [12:02<00:10,  3.45s/it] 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 198/200 [12:06<00:07,  3.51s/it]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 199/200 [12:09<00:03,  3.51s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:12<00:00,  3.49s/it]                                                                                                                                                          {'loss': 1.7035, 'grad_norm': 6.540396690368652, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:12<00:00,  3.49s/it]                                                                                                                                                          {'train_runtime': 733.8519, 'train_samples_per_second': 2.18, 'train_steps_per_second': 0.273, 'train_loss': 0.4967900550365448, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:13<00:00,  3.49s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [12:13<00:00,  3.67s/it]
saved: /workspace/adapters/qlora_run37
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:06,  2.14s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.39s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.49s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.44s/it]
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 151, in main
    base2 = load_bnb_model()
            ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 748, in _load_state_dict_into_meta_model
    param = param[...]
            ~~~~~^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 532.94 MiB is free. Process 27106 has 5.12 GiB memory in use. Including non-PyTorch memory, this process has 9.83 GiB memory in use. Of the allocated memory 9.38 GiB is allocated by PyTorch, and 295.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T08:06:54+00:00] ERROR rc=1 consec_fails=1
[2025-12-27T08:07:24+00:00] RUN: CHOOSE_MODE=random FORCE_CHOICE= RANDOM_SEED=12365
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:03<00:09,  3.13s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:05,  2.91s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:08<00:02,  2.95s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.38s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.60s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: random
ADAPTER: /workspace/adapters/qlora_run37
LOSSES: {'A': 2.587486110627651, 'B': 2.462151175364852, 'C': 3.248752538114786}
FORCED_CHOICE: A (was B )
CHOICE: A
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 37 | choice = A | mode = loss
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:03<00:09,  3.26s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:08<00:09,  4.65s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:11<00:03,  3.90s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.08s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.42s/it]
Map:   0%|                                                                                                               | 0/27999 [00:00<?, ? examples/s]Map:   1%|█▎                                                                                                 | 364/27999 [00:00<00:07, 3607.32 examples/s]Map:   3%|██▋                                                                                                | 776/27999 [00:00<00:09, 3012.86 examples/s]Map:   4%|███▊                                                                                              | 1091/27999 [00:00<00:08, 3064.15 examples/s]Map:   6%|█████▋                                                                                            | 1634/27999 [00:00<00:06, 3911.84 examples/s]Map:   8%|███████▍                                                                                          | 2113/27999 [00:00<00:07, 3534.67 examples/s]Map:  10%|█████████▋                                                                                        | 2775/27999 [00:00<00:05, 4424.72 examples/s]Map:  12%|███████████▉                                                                                      | 3426/27999 [00:00<00:05, 4385.89 examples/s]Map:  14%|██████████████                                                                                    | 4001/27999 [00:01<00:05, 4185.68 examples/s]Map:  17%|████████████████▎                                                                                 | 4652/27999 [00:01<00:05, 4234.85 examples/s]Map:  19%|██████████████████▎                                                                               | 5242/27999 [00:01<00:06, 3494.31 examples/s]Map:  21%|████████████████████▍                                                                             | 5847/27999 [00:01<00:05, 4021.25 examples/s]Map:  23%|██████████████████████▍                                                                           | 6419/27999 [00:01<00:05, 3950.04 examples/s]Map:  25%|████████████████████████                                                                          | 6888/27999 [00:01<00:05, 4115.42 examples/s]Map:  26%|█████████████████████████▉                                                                        | 7397/27999 [00:01<00:05, 3877.67 examples/s]Map:  29%|████████████████████████████                                                                      | 8017/27999 [00:02<00:05, 3954.78 examples/s]Map:  31%|██████████████████████████████▍                                                                   | 8693/27999 [00:02<00:04, 4605.42 examples/s]Map:  33%|████████████████████████████████▏                                                                 | 9200/27999 [00:02<00:04, 4194.38 examples/s]Map:  35%|██████████████████████████████████▊                                                               | 9934/27999 [00:02<00:04, 4418.84 examples/s]Map:  38%|████████████████████████████████████▍                                                            | 10511/27999 [00:02<00:03, 4733.29 examples/s]Map:  41%|███████████████████████████████████████▎                                                         | 11358/27999 [00:02<00:03, 4495.95 examples/s]Map:  43%|█████████████████████████████████████████▌                                                       | 12000/27999 [00:02<00:03, 4439.35 examples/s]Map:  45%|███████████████████████████████████████████▎                                                     | 12506/27999 [00:03<00:03, 4574.47 examples/s]Map:  46%|█████████████████████████████████████████████                                                    | 13000/27999 [00:03<00:03, 4567.20 examples/s]Map:  49%|███████████████████████████████████████████████▋                                                 | 13752/27999 [00:03<00:03, 4371.89 examples/s]Map:  52%|██████████████████████████████████████████████████▍                                              | 14541/27999 [00:03<00:02, 4641.89 examples/s]Map:  54%|████████████████████████████████████████████████████▌                                            | 15188/27999 [00:03<00:02, 5055.33 examples/s]Map:  56%|██████████████████████████████████████████████████████▋                                          | 15783/27999 [00:03<00:02, 4697.01 examples/s]Map:  59%|█████████████████████████████████████████████████████████                                        | 16475/27999 [00:03<00:02, 4667.57 examples/s]Map:  61%|███████████████████████████████████████████████████████████▏                                     | 17075/27999 [00:03<00:02, 4454.12 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▏                                   | 17674/27999 [00:04<00:02, 4307.93 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▍                                 | 18322/27999 [00:04<00:02, 3859.82 examples/s]Map:  67%|████████████████████████████████████████████████████████████████▉                                | 18755/27999 [00:04<00:02, 3954.14 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████▎                             | 19446/27999 [00:04<00:02, 3764.46 examples/s]Map:  71%|█████████████████████████████████████████████████████████████████████▎                           | 20000/27999 [00:04<00:02, 3758.87 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████                          | 20498/27999 [00:04<00:01, 4017.91 examples/s]Map:  75%|████████████████████████████████████████████████████████████████████████▊                        | 21010/27999 [00:05<00:01, 4272.80 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▍                      | 21477/27999 [00:05<00:01, 3884.21 examples/s]Map:  79%|████████████████████████████████████████████████████████████████████████████▏                    | 21996/27999 [00:05<00:01, 3745.12 examples/s]Map:  80%|█████████████████████████████████████████████████████████████████████████████▊                   | 22466/27999 [00:05<00:01, 3967.97 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▊                 | 23054/27999 [00:05<00:01, 3949.55 examples/s]Map:  84%|█████████████████████████████████████████████████████████████████████████████████▋               | 23589/27999 [00:05<00:01, 4283.97 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▎             | 24061/27999 [00:05<00:00, 4392.70 examples/s]Map:  88%|████████████████████████████████████████████████████████████████████████████████████▉            | 24522/27999 [00:05<00:00, 4449.10 examples/s]Map:  89%|██████████████████████████████████████████████████████████████████████████████████████▌          | 25001/27999 [00:05<00:00, 4537.32 examples/s]Map:  91%|████████████████████████████████████████████████████████████████████████████████████████▎        | 25475/27999 [00:06<00:00, 3296.11 examples/s]Map:  93%|█████████████████████████████████████████████████████████████████████████████████████████▉       | 25944/27999 [00:06<00:00, 3609.03 examples/s]Map:  94%|███████████████████████████████████████████████████████████████████████████████████████████▍     | 26400/27999 [00:06<00:00, 3837.89 examples/s]Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████▌   | 27000/27999 [00:06<00:00, 3800.75 examples/s]Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████▏ | 27478/27999 [00:06<00:00, 4035.19 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:06<00:00, 3865.29 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:06<00:00, 4114.50 examples/s]
TRAIN: cycle37  choice=A  data=/workspace/clean_data_norm/latest/A/science.txt  prev=/workspace/adapters/qlora_run36  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py", line 555, in forward
    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=quant_state).to(inp_dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 401, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 315, in forward
    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 252.88 MiB is free. Process 27225 has 8.18 GiB memory in use. Including non-PyTorch memory, this process has 7.04 GiB memory in use. Of the allocated memory 6.62 GiB is allocated by PyTorch, and 262.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|                                                                                                                             | 0/200 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T08:29:48+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=B RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:08,  2.71s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:05,  2.52s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.24s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.16s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.26s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run37
LOSSES: {'A': 2.662859581410885, 'B': 2.537343753501773, 'C': 3.325831323862076}
CHOICE: A
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 38 | choice = A | mode = random
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.42s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:06,  3.02s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:11<00:04,  4.14s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.30s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.34s/it]
Map:   0%|                                                                                                               | 0/27999 [00:00<?, ? examples/s]Map:   2%|█▌                                                                                                 | 454/27999 [00:00<00:06, 4519.06 examples/s]Map:   4%|███▌                                                                                              | 1000/27999 [00:00<00:07, 3842.61 examples/s]Map:   6%|█████▊                                                                                            | 1674/27999 [00:00<00:07, 3568.91 examples/s]Map:   7%|███████▏                                                                                          | 2070/27999 [00:00<00:07, 3679.03 examples/s]Map:   9%|████████▉                                                                                         | 2537/27999 [00:00<00:06, 3961.06 examples/s]Map:  11%|██████████▌                                                                                       | 3000/27999 [00:00<00:06, 4116.35 examples/s]Map:  12%|████████████                                                                                      | 3449/27999 [00:00<00:05, 4223.92 examples/s]Map:  14%|█████████████▊                                                                                    | 3953/27999 [00:01<00:06, 3887.14 examples/s]Map:  16%|███████████████▉                                                                                  | 4565/27999 [00:01<00:05, 3949.90 examples/s]Map:  18%|█████████████████▌                                                                                | 5000/27999 [00:01<00:06, 3589.11 examples/s]Map:  19%|██████████████████▉                                                                               | 5419/27999 [00:01<00:06, 3732.68 examples/s]Map:  21%|████████████████████▋                                                                             | 5899/27999 [00:01<00:05, 4003.82 examples/s]Map:  23%|██████████████████████▍                                                                           | 6415/27999 [00:01<00:05, 3801.50 examples/s]Map:  25%|████████████████████████▎                                                                         | 6939/27999 [00:01<00:05, 3691.80 examples/s]Map:  26%|█████████████████████████▋                                                                        | 7344/27999 [00:01<00:05, 3778.21 examples/s]Map:  28%|███████████████████████████▊                                                                      | 7935/27999 [00:02<00:05, 3831.72 examples/s]Map:  30%|█████████████████████████████▍                                                                    | 8415/27999 [00:02<00:05, 3588.24 examples/s]Map:  32%|██████████████████████████████▉                                                                   | 8854/27999 [00:02<00:05, 3773.37 examples/s]Map:  33%|████████████████████████████████▌                                                                 | 9318/27999 [00:02<00:05, 3329.83 examples/s]Map:  35%|█████████████████████████████████▉                                                                | 9706/27999 [00:02<00:05, 3451.18 examples/s]Map:  37%|███████████████████████████████████▌                                                             | 10279/27999 [00:02<00:04, 3557.95 examples/s]Map:  39%|█████████████████████████████████████▊                                                           | 10920/27999 [00:02<00:04, 3417.22 examples/s]Map:  40%|███████████████████████████████████████▎                                                         | 11338/27999 [00:03<00:05, 3173.92 examples/s]Map:  42%|████████████████████████████████████████▉                                                        | 11828/27999 [00:03<00:04, 3542.22 examples/s]Map:  44%|██████████████████████████████████████████▍                                                      | 12254/27999 [00:03<00:05, 3082.36 examples/s]Map:  45%|███████████████████████████████████████████▋                                                     | 12621/27999 [00:03<00:04, 3209.26 examples/s]Map:  46%|████████████████████████████████████████████▉                                                    | 12982/27999 [00:03<00:04, 3300.98 examples/s]Map:  48%|██████████████████████████████████████████████▋                                                  | 13484/27999 [00:03<00:04, 3314.54 examples/s]Map:  50%|████████████████████████████████████████████████▍                                                | 13968/27999 [00:03<00:03, 3683.01 examples/s]Map:  51%|█████████████████████████████████████████████████▊                                               | 14361/27999 [00:03<00:03, 3743.00 examples/s]Map:  53%|███████████████████████████████████████████████████                                              | 14753/27999 [00:04<00:03, 3786.87 examples/s]Map:  54%|████████████████████████████████████████████████████▍                                            | 15153/27999 [00:04<00:03, 3842.20 examples/s]Map:  56%|██████████████████████████████████████████████████████                                           | 15600/27999 [00:04<00:03, 4019.31 examples/s]Map:  57%|███████████████████████████████████████████████████████▌                                         | 16034/27999 [00:04<00:03, 3590.88 examples/s]Map:  59%|█████████████████████████████████████████████████████████▍                                       | 16576/27999 [00:04<00:03, 3596.25 examples/s]Map:  61%|██████████████████████████████████████████████████████████▊                                      | 16959/27999 [00:04<00:03, 3651.26 examples/s]Map:  62%|████████████████████████████████████████████████████████████                                     | 17345/27999 [00:04<00:02, 3658.52 examples/s]Map:  63%|█████████████████████████████████████████████████████████████▌                                   | 17770/27999 [00:04<00:02, 3817.00 examples/s]Map:  65%|███████████████████████████████████████████████████████████████▏                                 | 18235/27999 [00:05<00:02, 3549.16 examples/s]Map:  67%|█████████████████████████████████████████████████████████████████                                | 18792/27999 [00:05<00:02, 3599.03 examples/s]Map:  69%|██████████████████████████████████████████████████████████████████▉                              | 19339/27999 [00:05<00:02, 3321.61 examples/s]Map:  71%|████████████████████████████████████████████████████████████████████▍                            | 19754/27999 [00:05<00:02, 3504.68 examples/s]Map:  72%|█████████████████████████████████████████████████████████████████████▊                           | 20150/27999 [00:05<00:02, 3219.81 examples/s]Map:  73%|███████████████████████████████████████████████████████████████████████                          | 20514/27999 [00:05<00:02, 3317.22 examples/s]Map:  75%|████████████████████████████████████████████████████████████████████████▊                        | 21000/27999 [00:05<00:01, 3615.12 examples/s]Map:  77%|██████████████████████████████████████████████████████████████████████████▊                      | 21588/27999 [00:05<00:01, 3712.87 examples/s]Map:  79%|████████████████████████████████████████████████████████████████████████████▋                    | 22131/27999 [00:06<00:01, 3398.57 examples/s]Map:  81%|██████████████████████████████████████████████████████████████████████████████▏                  | 22581/27999 [00:06<00:01, 3276.02 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▋                 | 23000/27999 [00:06<00:01, 3398.58 examples/s]Map:  84%|█████████████████████████████████████████████████████████████████████████████████▉               | 23654/27999 [00:06<00:01, 3794.65 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▌             | 24103/27999 [00:06<00:00, 3959.29 examples/s]Map:  88%|█████████████████████████████████████████████████████████████████████████████████████▎           | 24638/27999 [00:06<00:00, 4310.21 examples/s]Map:  90%|███████████████████████████████████████████████████████████████████████████████████████▋         | 25325/27999 [00:06<00:00, 3930.19 examples/s]Map:  92%|█████████████████████████████████████████████████████████████████████████████████████████▌       | 25850/27999 [00:07<00:00, 3794.37 examples/s]Map:  95%|███████████████████████████████████████████████████████████████████████████████████████████▉     | 26548/27999 [00:07<00:00, 4054.07 examples/s]Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████▌   | 27000/27999 [00:07<00:00, 4069.85 examples/s]Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████▎ | 27499/27999 [00:07<00:00, 3828.23 examples/s]Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████▉| 27975/27999 [00:07<00:00, 4042.72 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 27999/27999 [00:07<00:00, 3650.20 examples/s]
TRAIN: cycle38  choice=A  data=/workspace/clean_data_norm/latest/A/science.txt  prev=/workspace/adapters/qlora_run37  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]  0%|▌                                                                                                                    | 1/200 [00:04<13:39,  4.12s/it]  1%|█▏                                                                                                                   | 2/200 [00:07<12:20,  3.74s/it]  2%|█▊                                                                                                                   | 3/200 [00:11<12:11,  3.71s/it]  2%|██▎                                                                                                                  | 4/200 [00:14<12:00,  3.68s/it]  2%|██▉                                                                                                                  | 5/200 [00:18<11:43,  3.61s/it]  3%|███▌                                                                                                                 | 6/200 [00:21<11:33,  3.57s/it]  4%|████                                                                                                                 | 7/200 [00:25<11:43,  3.65s/it]  4%|████▋                                                                                                                | 8/200 [00:29<11:24,  3.57s/it]  4%|█████▎                                                                                                               | 9/200 [00:32<10:59,  3.45s/it]  5%|█████▊                                                                                                              | 10/200 [00:35<11:04,  3.50s/it]  6%|██████▍                                                                                                             | 11/200 [00:39<11:12,  3.56s/it]  6%|██████▉                                                                                                             | 12/200 [00:43<11:17,  3.61s/it]  6%|███████▌                                                                                                            | 13/200 [00:46<11:13,  3.60s/it]  7%|████████                                                                                                            | 14/200 [00:50<10:58,  3.54s/it]  8%|████████▋                                                                                                           | 15/200 [00:53<10:52,  3.53s/it]  8%|█████████▎                                                                                                          | 16/200 [00:57<10:46,  3.51s/it]  8%|█████████▊                                                                                                          | 17/200 [01:00<10:50,  3.56s/it]  9%|██████████▍                                                                                                         | 18/200 [01:04<10:49,  3.57s/it] 10%|███████████                                                                                                         | 19/200 [01:08<11:03,  3.66s/it] 10%|███████████▌                                                                                                        | 20/200 [01:11<10:46,  3.59s/it]                                                                                                                                                          {'loss': 0.1346, 'grad_norm': 1.8944684267044067, 'learning_rate': 0.000181, 'epoch': 0.01}
 10%|███████████▌                                                                                                        | 20/200 [01:11<10:46,  3.59s/it] 10%|████████████▏                                                                                                       | 21/200 [01:15<10:35,  3.55s/it] 11%|████████████▊                                                                                                       | 22/200 [01:18<10:29,  3.54s/it] 12%|█████████████▎                                                                                                      | 23/200 [01:22<10:16,  3.48s/it] 12%|█████████████▉                                                                                                      | 24/200 [01:25<10:23,  3.54s/it] 12%|██████████████▌                                                                                                     | 25/200 [01:30<10:57,  3.76s/it] 13%|███████████████                                                                                                     | 26/200 [01:33<10:34,  3.65s/it] 14%|███████████████▋                                                                                                    | 27/200 [01:36<10:23,  3.60s/it] 14%|████████████████▏                                                                                                   | 28/200 [01:40<10:15,  3.58s/it] 14%|████████████████▊                                                                                                   | 29/200 [01:43<10:04,  3.54s/it] 15%|█████████████████▍                                                                                                  | 30/200 [01:47<10:11,  3.60s/it] 16%|█████████████████▉                                                                                                  | 31/200 [01:51<09:58,  3.54s/it] 16%|██████████████████▌                                                                                                 | 32/200 [01:54<09:49,  3.51s/it] 16%|███████████████████▏                                                                                                | 33/200 [01:57<09:43,  3.49s/it] 17%|███████████████████▋                                                                                                | 34/200 [02:01<09:36,  3.47s/it] 18%|████████████████████▎                                                                                               | 35/200 [02:04<09:27,  3.44s/it] 18%|████████████████████▉                                                                                               | 36/200 [02:08<09:23,  3.43s/it] 18%|█████████████████████▍                                                                                              | 37/200 [02:11<09:23,  3.46s/it] 19%|██████████████████████                                                                                              | 38/200 [02:15<09:19,  3.45s/it] 20%|██████████████████████▌                                                                                             | 39/200 [02:18<09:22,  3.49s/it] 20%|███████████████████████▏                                                                                            | 40/200 [02:22<09:13,  3.46s/it]                                                                                                                                                          {'loss': 0.1604, 'grad_norm': 2.0144059658050537, 'learning_rate': 0.000161, 'epoch': 0.01}
 20%|███████████████████████▏                                                                                            | 40/200 [02:22<09:13,  3.46s/it] 20%|███████████████████████▊                                                                                            | 41/200 [02:25<09:01,  3.40s/it] 21%|████████████████████████▎                                                                                           | 42/200 [02:28<09:01,  3.43s/it] 22%|████████████████████████▉                                                                                           | 43/200 [02:32<08:57,  3.42s/it] 22%|█████████████████████████▌                                                                                          | 44/200 [02:35<08:53,  3.42s/it] 22%|██████████████████████████                                                                                          | 45/200 [02:39<08:48,  3.41s/it] 23%|██████████████████████████▋                                                                                         | 46/200 [02:42<08:55,  3.48s/it] 24%|███████████████████████████▎                                                                                        | 47/200 [02:46<08:50,  3.47s/it] 24%|███████████████████████████▊                                                                                        | 48/200 [02:50<09:28,  3.74s/it] 24%|████████████████████████████▍                                                                                       | 49/200 [02:53<09:06,  3.62s/it] 25%|█████████████████████████████                                                                                       | 50/200 [02:57<09:02,  3.62s/it] 26%|█████████████████████████████▌                                                                                      | 51/200 [03:00<08:48,  3.55s/it] 26%|██████████████████████████████▏                                                                                     | 52/200 [03:04<08:39,  3.51s/it] 26%|██████████████████████████████▋                                                                                     | 53/200 [03:07<08:28,  3.46s/it] 27%|███████████████████████████████▎                                                                                    | 54/200 [03:11<08:23,  3.45s/it] 28%|███████████████████████████████▉                                                                                    | 55/200 [03:14<08:26,  3.50s/it] 28%|████████████████████████████████▍                                                                                   | 56/200 [03:18<08:31,  3.56s/it] 28%|█████████████████████████████████                                                                                   | 57/200 [03:21<08:14,  3.46s/it] 29%|█████████████████████████████████▋                                                                                  | 58/200 [03:24<08:07,  3.43s/it] 30%|██████████████████████████████████▏                                                                                 | 59/200 [03:28<08:02,  3.42s/it] 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:32<08:10,  3.50s/it]                                                                                                                                                          {'loss': 0.184, 'grad_norm': 4.5630388259887695, 'learning_rate': 0.000141, 'epoch': 0.02}
 30%|██████████████████████████████████▊                                                                                 | 60/200 [03:32<08:10,  3.50s/it] 30%|███████████████████████████████████▍                                                                                | 61/200 [03:35<08:11,  3.53s/it] 31%|███████████████████████████████████▉                                                                                | 62/200 [03:39<08:14,  3.58s/it] 32%|████████████████████████████████████▌                                                                               | 63/200 [03:42<07:56,  3.48s/it] 32%|█████████████████████████████████████                                                                               | 64/200 [03:46<07:53,  3.48s/it] 32%|█████████████████████████████████████▋                                                                              | 65/200 [03:49<08:01,  3.56s/it] 33%|██████████████████████████████████████▎                                                                             | 66/200 [03:53<08:02,  3.60s/it] 34%|██████████████████████████████████████▊                                                                             | 67/200 [03:57<08:04,  3.64s/it] 34%|███████████████████████████████████████▍                                                                            | 68/200 [04:00<07:59,  3.63s/it] 34%|████████████████████████████████████████                                                                            | 69/200 [04:04<07:54,  3.62s/it] 35%|████████████████████████████████████████▌                                                                           | 70/200 [04:07<07:46,  3.59s/it] 36%|█████████████████████████████████████████▏                                                                          | 71/200 [04:11<07:46,  3.62s/it] 36%|█████████████████████████████████████████▊                                                                          | 72/200 [04:15<07:34,  3.55s/it] 36%|██████████████████████████████████████████▎                                                                         | 73/200 [04:18<07:34,  3.58s/it] 37%|██████████████████████████████████████████▉                                                                         | 74/200 [04:22<07:23,  3.52s/it] 38%|███████████████████████████████████████████▌                                                                        | 75/200 [04:25<07:29,  3.60s/it] 38%|████████████████████████████████████████████                                                                        | 76/200 [04:29<07:15,  3.51s/it] 38%|████████████████████████████████████████████▋                                                                       | 77/200 [04:32<07:20,  3.58s/it] 39%|█████████████████████████████████████████████▏                                                                      | 78/200 [04:36<07:10,  3.53s/it] 40%|█████████████████████████████████████████████▊                                                                      | 79/200 [04:40<07:14,  3.59s/it] 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [04:43<07:00,  3.51s/it]                                                                                                                                                          {'loss': 0.2248, 'grad_norm': 7.160460472106934, 'learning_rate': 0.000121, 'epoch': 0.02}
 40%|██████████████████████████████████████████████▍                                                                     | 80/200 [04:43<07:00,  3.51s/it] 40%|██████████████████████████████████████████████▉                                                                     | 81/200 [04:46<06:51,  3.45s/it] 41%|███████████████████████████████████████████████▌                                                                    | 82/200 [04:50<06:56,  3.53s/it] 42%|████████████████████████████████████████████████▏                                                                   | 83/200 [04:54<07:04,  3.63s/it] 42%|████████████████████████████████████████████████▋                                                                   | 84/200 [04:57<06:56,  3.59s/it] 42%|█████████████████████████████████████████████████▎                                                                  | 85/200 [05:01<07:03,  3.68s/it] 43%|█████████████████████████████████████████████████▉                                                                  | 86/200 [05:05<06:57,  3.66s/it] 44%|██████████████████████████████████████████████████▍                                                                 | 87/200 [05:08<06:44,  3.58s/it] 44%|███████████████████████████████████████████████████                                                                 | 88/200 [05:12<06:45,  3.62s/it] 44%|███████████████████████████████████████████████████▌                                                                | 89/200 [05:15<06:34,  3.56s/it] 45%|████████████████████████████████████████████████████▏                                                               | 90/200 [05:19<06:28,  3.53s/it] 46%|████████████████████████████████████████████████████▊                                                               | 91/200 [05:22<06:24,  3.53s/it] 46%|█████████████████████████████████████████████████████▎                                                              | 92/200 [05:26<06:23,  3.55s/it] 46%|█████████████████████████████████████████████████████▉                                                              | 93/200 [05:30<06:27,  3.62s/it] 47%|██████████████████████████████████████████████████████▌                                                             | 94/200 [05:33<06:30,  3.68s/it] 48%|███████████████████████████████████████████████████████                                                             | 95/200 [05:37<06:24,  3.66s/it] 48%|███████████████████████████████████████████████████████▋                                                            | 96/200 [05:41<06:18,  3.64s/it] 48%|████████████████████████████████████████████████████████▎                                                           | 97/200 [05:44<06:10,  3.60s/it] 49%|████████████████████████████████████████████████████████▊                                                           | 98/200 [05:48<06:06,  3.59s/it] 50%|█████████████████████████████████████████████████████████▍                                                          | 99/200 [05:51<06:00,  3.57s/it] 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [05:55<05:55,  3.55s/it]                                                                                                                                                          {'loss': 0.2627, 'grad_norm': 6.069680690765381, 'learning_rate': 0.000101, 'epoch': 0.03}
 50%|█████████████████████████████████████████████████████████▌                                                         | 100/200 [05:55<05:55,  3.55s/it] 50%|██████████████████████████████████████████████████████████                                                         | 101/200 [05:59<05:55,  3.59s/it] 51%|██████████████████████████████████████████████████████████▋                                                        | 102/200 [06:02<05:49,  3.57s/it] 52%|███████████████████████████████████████████████████████████▏                                                       | 103/200 [06:05<05:43,  3.54s/it] 52%|███████████████████████████████████████████████████████████▊                                                       | 104/200 [06:09<05:39,  3.54s/it] 52%|████████████████████████████████████████████████████████████▍                                                      | 105/200 [06:13<05:37,  3.55s/it] 53%|████████████████████████████████████████████████████████████▉                                                      | 106/200 [06:17<05:44,  3.66s/it] 54%|█████████████████████████████████████████████████████████████▌                                                     | 107/200 [06:20<05:29,  3.54s/it] 54%|██████████████████████████████████████████████████████████████                                                     | 108/200 [06:23<05:25,  3.53s/it] 55%|██████████████████████████████████████████████████████████████▋                                                    | 109/200 [06:27<05:18,  3.50s/it] 55%|███████████████████████████████████████████████████████████████▎                                                   | 110/200 [06:30<05:09,  3.44s/it] 56%|███████████████████████████████████████████████████████████████▊                                                   | 111/200 [06:33<05:07,  3.45s/it] 56%|████████████████████████████████████████████████████████████████▍                                                  | 112/200 [06:37<05:02,  3.43s/it] 56%|████████████████████████████████████████████████████████████████▉                                                  | 113/200 [06:40<04:58,  3.44s/it] 57%|█████████████████████████████████████████████████████████████████▌                                                 | 114/200 [06:44<04:52,  3.40s/it] 57%|██████████████████████████████████████████████████████████████████▏                                                | 115/200 [06:47<04:52,  3.44s/it] 58%|██████████████████████████████████████████████████████████████████▋                                                | 116/200 [06:51<04:53,  3.49s/it] 58%|███████████████████████████████████████████████████████████████████▎                                               | 117/200 [06:54<04:48,  3.48s/it] 59%|███████████████████████████████████████████████████████████████████▊                                               | 118/200 [06:58<04:42,  3.44s/it] 60%|████████████████████████████████████████████████████████████████████▍                                              | 119/200 [07:01<04:32,  3.37s/it] 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:04<04:34,  3.44s/it]                                                                                                                                                          {'loss': 0.3496, 'grad_norm': 5.7857818603515625, 'learning_rate': 8.1e-05, 'epoch': 0.03}
 60%|█████████████████████████████████████████████████████████████████████                                              | 120/200 [07:04<04:34,  3.44s/it] 60%|█████████████████████████████████████████████████████████████████████▌                                             | 121/200 [07:08<04:38,  3.52s/it] 61%|██████████████████████████████████████████████████████████████████████▏                                            | 122/200 [07:12<04:33,  3.51s/it] 62%|██████████████████████████████████████████████████████████████████████▋                                            | 123/200 [07:15<04:26,  3.46s/it] 62%|███████████████████████████████████████████████████████████████████████▎                                           | 124/200 [07:18<04:25,  3.49s/it] 62%|███████████████████████████████████████████████████████████████████████▉                                           | 125/200 [07:23<04:35,  3.67s/it] 63%|████████████████████████████████████████████████████████████████████████▍                                          | 126/200 [07:26<04:29,  3.64s/it] 64%|█████████████████████████████████████████████████████████████████████████                                          | 127/200 [07:30<04:22,  3.60s/it] 64%|█████████████████████████████████████████████████████████████████████████▌                                         | 128/200 [07:33<04:11,  3.50s/it] 64%|██████████████████████████████████████████████████████████████████████████▏                                        | 129/200 [07:36<04:08,  3.50s/it] 65%|██████████████████████████████████████████████████████████████████████████▊                                        | 130/200 [07:40<04:04,  3.49s/it] 66%|███████████████████████████████████████████████████████████████████████████▎                                       | 131/200 [07:43<03:59,  3.47s/it] 66%|███████████████████████████████████████████████████████████████████████████▉                                       | 132/200 [07:47<03:52,  3.41s/it] 66%|████████████████████████████████████████████████████████████████████████████▍                                      | 133/200 [07:50<03:50,  3.44s/it] 67%|█████████████████████████████████████████████████████████████████████████████                                      | 134/200 [07:54<03:52,  3.52s/it] 68%|█████████████████████████████████████████████████████████████████████████████▋                                     | 135/200 [07:57<03:50,  3.55s/it] 68%|██████████████████████████████████████████████████████████████████████████████▏                                    | 136/200 [08:01<03:45,  3.53s/it] 68%|██████████████████████████████████████████████████████████████████████████████▊                                    | 137/200 [08:04<03:40,  3.50s/it] 69%|███████████████████████████████████████████████████████████████████████████████▎                                   | 138/200 [08:08<03:42,  3.58s/it] 70%|███████████████████████████████████████████████████████████████████████████████▉                                   | 139/200 [08:12<03:37,  3.57s/it] 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [08:15<03:30,  3.51s/it]                                                                                                                                                          {'loss': 0.5341, 'grad_norm': 6.5234246253967285, 'learning_rate': 6.1e-05, 'epoch': 0.04}
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 140/200 [08:15<03:30,  3.51s/it] 70%|█████████████████████████████████████████████████████████████████████████████████                                  | 141/200 [08:18<03:25,  3.48s/it]LOSSES: {'A': 2.662859581410885, 'B': 2.537343753501773, 'C': 3.325831323862076}
FORCED_CHOICE: B (was B )
CHOICE: B
WROTE: /workspace/choice.txt
orchestrator: cycle_next = 38 | choice = B | mode = loss
 71%|█████████████████████████████████████████████████████████████████████████████████▋                                 | 142/200 [08:22<03:23,  3.51s/it]Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s] 72%|██████████████████████████████████████████████████████████████████████████████████▏                                | 143/200 [08:25<03:18,  3.49s/it]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:01<00:05,  1.89s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:04,  2.11s/it] 72%|██████████████████████████████████████████████████████████████████████████████████▊                                | 144/200 [08:29<03:20,  3.58s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:06<00:02,  2.19s/it] 72%|███████████████████████████████████████████████████████████████████████████████████▍                               | 145/200 [08:33<03:15,  3.55s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.94s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  2.00s/it]
Map:   0%|                                                                                                               | 0/28107 [00:00<?, ? examples/s]Map:   3%|██▌                                                                                                | 717/28107 [00:00<00:03, 7132.68 examples/s]Map:   6%|██████▎                                                                                           | 1803/28107 [00:00<00:03, 7156.17 examples/s]Map:  10%|██████████▏                                                                                       | 2922/28107 [00:00<00:03, 7296.43 examples/s]Map:  13%|████████████▉                                                                                     | 3695/28107 [00:00<00:03, 7428.86 examples/s]Map:  16%|███████████████▌                                                                                  | 4473/28107 [00:00<00:03, 7537.75 examples/s]Map:  19%|██████████████████▎                                                                               | 5255/28107 [00:00<00:02, 7620.45 examples/s]Map:  23%|██████████████████████▎                                                                           | 6391/28107 [00:00<00:02, 7541.80 examples/s]Map:  26%|█████████████████████████▎                                                                        | 7253/28107 [00:00<00:02, 7832.98 examples/s]Map:  30%|█████████████████████████████▍                                                                    | 8455/28107 [00:01<00:02, 7897.78 examples/s]Map:  34%|█████████████████████████████████▎                                                                | 9550/28107 [00:01<00:02, 7687.71 examples/s]Map:  38%|████████████████████████████████████▊                                                            | 10685/28107 [00:01<00:02, 7643.17 examples/s]Map:  42%|████████████████████████████████████████▎                                                        | 11696/28107 [00:01<00:02, 7351.83 examples/s]Map:  44%|███████████████████████████████████████████                                                      | 12494/28107 [00:01<00:02, 7495.96 examples/s]Map:  47%|██████████████████████████████████████████████                                                   | 13336/28107 [00:01<00:01, 7724.14 examples/s]Map:  51%|█████████████████████████████████████████████████▍                                               | 14314/28107 [00:01<00:01, 8260.93 examples/s]Map:  55%|█████████████████████████████████████████████████████▌                                           | 15532/28107 [00:02<00:01, 8205.10 examples/s]Map:  59%|█████████████████████████████████████████████████████████                                        | 16552/28107 [00:02<00:01, 7723.82 examples/s] 73%|███████████████████████████████████████████████████████████████████████████████████▉                               | 146/200 [08:36<03:08,  3.49s/it]Map:  63%|████████████████████████████████████████████████████████████▊                                    | 17611/28107 [00:02<00:01, 7502.18 examples/s]Map:  66%|███████████████████████████████████████████████████████████████▉                                 | 18523/28107 [00:02<00:01, 7884.86 examples/s]Map:  69%|███████████████████████████████████████████████████████████████████                              | 19448/28107 [00:02<00:01, 8128.70 examples/s]Map:  74%|███████████████████████████████████████████████████████████████████████▋                         | 20774/28107 [00:02<00:00, 8372.80 examples/s]Map:  78%|███████████████████████████████████████████████████████████████████████████▉                     | 22000/28107 [00:02<00:00, 8233.84 examples/s]Map:  82%|███████████████████████████████████████████████████████████████████████████████▉                 | 23176/28107 [00:02<00:00, 8106.53 examples/s]Map:  86%|███████████████████████████████████████████████████████████████████████████████████▏             | 24091/28107 [00:03<00:00, 8348.84 examples/s]Map:  89%|██████████████████████████████████████████████████████████████████████████████████████▍          | 25061/28107 [00:03<00:00, 8681.56 examples/s]Map:  93%|██████████████████████████████████████████████████████████████████████████████████████████▌      | 26235/28107 [00:03<00:00, 8372.90 examples/s]Map:  97%|█████████████████████████████████████████████████████████████████████████████████████████████▊   | 27182/28107 [00:03<00:00, 8644.46 examples/s]Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████▊| 28065/28107 [00:03<00:00, 8687.82 examples/s]Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 28107/28107 [00:03<00:00, 7971.18 examples/s]
TRAIN: cycle38  choice=B  data=/workspace/clean_data_norm/latest/B/dialog.txt  prev=/workspace/adapters/qlora_run37  exclude=2000
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 145, in main
    trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py", line 1923, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py", line 555, in forward
    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=quant_state).to(inp_dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 401, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py", line 315, in forward
    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 15.48 GiB of which 152.88 MiB is free. Process 27394 has 8.81 GiB memory in use. Including non-PyTorch memory, this process has 6.51 GiB memory in use. Of the allocated memory 6.04 GiB is allocated by PyTorch, and 315.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T09:41:46+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=C RANDOM_SEED=
 74%|████████████████████████████████████████████████████████████████████████████████████▌                              | 147/200 [08:39<03:03,  3.46s/it] 74%|█████████████████████████████████████████████████████████████████████████████████████                              | 148/200 [08:43<02:57,  3.42s/it]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:00<00:02,  1.10it/s]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:01<00:01,  1.39it/s]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:01<00:00,  1.62it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.85it/s]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.66it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
 74%|█████████████████████████████████████████████████████████████████████████████████████▋                             | 149/200 [08:46<02:55,  3.44s/it]MODE: loss
ADAPTER: /workspace/adapters/qlora_run37
 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 150/200 [08:49<02:49,  3.38s/it] 76%|██████████████████████████████████████████████████████████████████████████████████████▊                            | 151/200 [08:53<02:48,  3.43s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▍                           | 152/200 [08:56<02:44,  3.43s/it] 76%|███████████████████████████████████████████████████████████████████████████████████████▉                           | 153/200 [09:00<02:42,  3.46s/it] 77%|████████████████████████████████████████████████████████████████████████████████████████▌                          | 154/200 [09:03<02:39,  3.47s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▏                         | 155/200 [09:07<02:41,  3.60s/it] 78%|█████████████████████████████████████████████████████████████████████████████████████████▋                         | 156/200 [09:11<02:38,  3.60s/it] 78%|██████████████████████████████████████████████████████████████████████████████████████████▎                        | 157/200 [09:15<02:35,  3.63s/it] 79%|██████████████████████████████████████████████████████████████████████████████████████████▊                        | 158/200 [09:18<02:29,  3.57s/it] 80%|███████████████████████████████████████████████████████████████████████████████████████████▍                       | 159/200 [09:21<02:23,  3.49s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [09:25<02:18,  3.45s/it]                                                                                                                                                          {'loss': 0.7395, 'grad_norm': 9.78435230255127, 'learning_rate': 4.1e-05, 'epoch': 0.05}
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 160/200 [09:25<02:18,  3.45s/it] 80%|████████████████████████████████████████████████████████████████████████████████████████████▌                      | 161/200 [09:28<02:15,  3.48s/it] 81%|█████████████████████████████████████████████████████████████████████████████████████████████▏                     | 162/200 [09:32<02:14,  3.53s/it] 82%|█████████████████████████████████████████████████████████████████████████████████████████████▋                     | 163/200 [09:35<02:09,  3.50s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▎                    | 164/200 [09:39<02:05,  3.49s/it] 82%|██████████████████████████████████████████████████████████████████████████████████████████████▉                    | 165/200 [09:42<02:02,  3.50s/it] 83%|███████████████████████████████████████████████████████████████████████████████████████████████▍                   | 166/200 [09:46<01:57,  3.45s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████                   | 167/200 [09:49<01:52,  3.42s/it] 84%|████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 168/200 [09:52<01:49,  3.42s/it] 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 169/200 [09:56<01:46,  3.44s/it] 85%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 170/200 [09:59<01:41,  3.39s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                | 171/200 [10:03<01:40,  3.46s/it] 86%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                | 172/200 [10:06<01:37,  3.47s/it] 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 173/200 [10:10<01:33,  3.47s/it] 87%|████████████████████████████████████████████████████████████████████████████████████████████████████               | 174/200 [10:13<01:30,  3.50s/it] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 175/200 [10:17<01:27,  3.50s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 176/200 [10:20<01:23,  3.47s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 177/200 [10:24<01:19,  3.47s/it] 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 178/200 [10:27<01:16,  3.49s/it] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 179/200 [10:31<01:15,  3.58s/it] 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [10:34<01:10,  3.52s/it]                                                                                                                                                          {'loss': 1.2751, 'grad_norm': 6.493361949920654, 'learning_rate': 2.1e-05, 'epoch': 0.05}
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 180/200 [10:34<01:10,  3.52s/it] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████           | 181/200 [10:38<01:07,  3.57s/it] 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 182/200 [10:42<01:04,  3.61s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 183/200 [10:45<01:01,  3.60s/it] 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 184/200 [10:49<00:58,  3.65s/it] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 185/200 [10:53<00:54,  3.64s/it] 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 186/200 [10:56<00:49,  3.56s/it] 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 187/200 [11:00<00:46,  3.58s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 188/200 [11:03<00:42,  3.51s/it] 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 189/200 [11:07<00:38,  3.45s/it] 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 190/200 [11:10<00:35,  3.52s/it] 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 191/200 [11:14<00:31,  3.49s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 192/200 [11:17<00:27,  3.46s/it] 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 193/200 [11:20<00:24,  3.44s/it] 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 194/200 [11:24<00:20,  3.43s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 195/200 [11:27<00:17,  3.48s/it] 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 196/200 [11:31<00:13,  3.49s/it] 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 197/200 [11:34<00:10,  3.43s/it] 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 198/200 [11:38<00:06,  3.48s/it]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 199/200 [11:41<00:03,  3.46s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:45<00:00,  3.53s/it]                                                                                                                                                          {'loss': 2.2868, 'grad_norm': 8.034944534301758, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:45<00:00,  3.53s/it]                                                                                                                                                          {'train_runtime': 706.3936, 'train_samples_per_second': 2.265, 'train_steps_per_second': 0.283, 'train_loss': 0.6151696014404296, 'epoch': 0.06}
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:46<00:00,  3.53s/it]100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:46<00:00,  3.53s/it]
saved: /workspace/adapters/qlora_run38
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:06,  2.27s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:04<00:05,  2.52s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.55s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.57s/it]
Traceback (most recent call last):
  File "/workspace/run_cycle.py", line 169, in <module>
    main()
  File "/workspace/run_cycle.py", line 151, in main
    base2 = load_bnb_model()
            ^^^^^^^^^^^^^^^^
  File "/workspace/run_cycle.py", line 48, in load_bnb_model
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=bnb, device_map="auto")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 750, in _load_state_dict_into_meta_model
    param = param.to(casting_dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 15.48 GiB of which 12.88 MiB is free. Including non-PyTorch memory, this process has 10.75 GiB memory in use. Process 27527 has 4.70 GiB memory in use. Of the allocated memory 10.39 GiB is allocated by PyTorch, and 204.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/orchestrate_cycle.py", line 404, in <module>
    main()
  File "/workspace/orchestrate_cycle.py", line 369, in main
    subprocess.run(["python3", str(ROOT / "run_cycle.py")], check=True, env=env_train)
  File "/usr/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['python3', '/workspace/run_cycle.py']' returned non-zero exit status 1.
[2025-12-27T09:45:03+00:00] RUN: CHOOSE_MODE=loss FORCE_CHOICE=A RANDOM_SEED=
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|███████████████████████                                                                     | 1/4 [00:02<00:07,  2.34s/it]Loading checkpoint shards:  50%|██████████████████████████████████████████████                                              | 2/4 [00:05<00:06,  3.05s/it]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████████                       | 3/4 [00:07<00:02,  2.54s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.09s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.31s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
MODE: loss
ADAPTER: /workspace/adapters/qlora_run38
